---------读书战略：自顶向下，从应用层到底层细节。先熟悉的常用的，后底层的不常用的。精读好书---《深入理解系列》
--------es的处理思想都对应有 相应的“某种举动 及其导致 的问题”
>需求背景-痛点陈述：现实开发中遇到了什么痛点导致XXX的开发？  
>那么痛点的原因、产生的条件：分析是什么环境、什么动作 什么效果什么目的 等精准形容词的事实描述 导致了痛点的必然发生，难以避免？。条件-痛点。原因-结果。
>则可以消除痛点的最简单的精准事实陈述是什么：修改“条件-痛点”陈述的哪一部分就可以导致没有痛点产生。 要做的根本事情是什么：
>那么新陈述表明的解决动作是什么：
>新情况的新痛点是什么：新举动、新环境会产生的新痛点描述出来， 继续上述4条操作。
>学习要有战略和格局：过于零散、孤立、末支、叶子的知识点就没必要化太多时间，懂得放弃。聚焦在根节点、枢纽节点、产生分支的节点、主干知识点、枢纽知识点、关联到很多知识点的知识点上。
 >对于主干知识点：要有全新的认识视角和进行精细的描述，大量的提问和好奇和进行必要的实验以获取支撑观点/导出观点的数据。
 >规范是工程最独特的特征.
 >慢慢读：
>一种新技术的学习：
 >它面对的情况和问题、它的世界观、它的方案、它的方案验证/论证/能处理的解决的所有情况及能成功处理的理由/功能边界
  >所有的软件：都可以看作是向上封装一层接口，根据自己的世界观封装底层而向上/对外提供统一的(统一的更简单的更直观的更业务的更少底层信息的)接口，底层包含一系列的第三方的插件/构件/组件；内部则去做兼容和调用(对底层)(对上层则做逻辑分解和底层实现)。
>知识混乱就是因为没有组织：
	>组织就是关键字树：几个单词就是每层上的每个节点的内容；
	>组织也可以看作逻辑树：有逻辑关系，逻辑顺序，逻辑联系的关键字的层层集合。层层囊括更精细的范围，层层划分范围。
>推进理解的属性发展拓展、问题延展：重要方式；
>什么是架构：架构也是从抽象到具体的考虑和描述；树形延展开来，可以写满非常大的黑板和巨大的脑图！！sharding-jdbc,dubbo,spring都可以这样方式来展现它的架构！！它的抽象到具体的考虑---本身才是架构！！！而不是什么模块、模式之类！！
>抽象设计：则某一层就不管上一层的含义和下一层的含义，即更抽象的含义或者更具体的含义；而是实现本层的含义；完成本层的含义指定的功能；。如网络协议的架构设计；	
>面向设计来理解，面向架构设计来理解，面向架构问题一层一层来理解它：面向设计来理解，所以按照面向对象设计的方式，看其中的对象、行为属性、流程环节逻辑。	
>找不到知识/描述 所对应的问题 ， 那么看书将没有条理纲领，变得零散琐碎没有组织。	
>不是按概念方式组织，而是按架构、问题方式来组织 笔记，书本内容。架构顺序，问题层次顺序。	
>架构不是设计出来的，也不是演进出来的(甚至不是迭代出来的--尽可能避免迭代)：而是问出来的。	
>每个方法方案都从属于一颗树，所以找到一个方法巧妙方法仅仅是第一步--找到从属的层次树 有更大的价值；(无论是谁想到的方法/概念，都要这样更进一步)
>解决问题的办法就是提出问题：类似递归和动态规划；。。权衡就是线性规划；	优势劣势在一定场景下也是劣势优势；
>一个词，到一句话，两句话，一段话，一篇文章；这个就是抽象总结，层次总结；越简洁，站得越高
--在网络、搜索引擎、推荐系统 三方面的专家；作为系统方面的独特优势/拔高优势；(网络-查询-推荐)
	
----有且只有响应，通信端才知道连接是否成功；。浏览器自动扩展。
----维持连接，并发连接，都是软件的实现，物理上看都是一条出口；从响应就是维护连接的角度看，不存在需要维护什么连接，维护就是维护连接数据而已；只要发送响应，连接就活了；在网络端口出口，可以连续发送不同目的地的响应报文，这就是并行；所以完全可以用队列来接收请求数据包；而用队列缓存发送响应数据包；多核使用起来，来并行大批量的发送和接收；不存在要维护和持续占用“端口”网络出口这种概念---完全没必要，用完即走 就可；	
	>或者不存在连接这个概念：所有的事情就是接收数据包和发送数据包(接送/发送缓冲区)。(连接 是 软件臆造出来的概念，不要和物理对应；和物理对应就会束缚思想，就会很多事情理解不了不知道原因)
	>连接的状态转移图；
	>应用的固定端口：实际上是建立新TCP连接的请求的处理的端口，请求到达这个端口--后面建立一个独立的TCP连接---来负责和客户端通信-交互数据；
----UML：为什么类继承关系图---因为这就是具体到一般的概念对象抽象过程。自上而下是能力顺序，能力组合；	
----说话和介绍：语速不要快，快就是掩盖问题，掩盖过程步骤；直接导致别人认为思路不清晰，表达不清楚，东拉西扯；也不利于自己思路的成长和扩展和自己主动发现问题，且必然导致不简洁--废话很多；
	>介绍需要先纲目后具体：抽象到具体；而不是张口就是罗列枚举---内容没有结构--全是线性结构；
	>描述更精简：一个字一个词，一句话，两句话，一段话；
----大事和吏治：大事 就像西天取经；吏治就像管理四人；


--计划：nginx/tomcat-->计算机系统-->架构-->自己的系统架构方案:专题研究、大提问、大总结。大简化/模型图化；
>一个进程看作一个消息，代码计划/任务计划；；都是异步隔离；	
	>程序启动点/执行点：可以多个，看作是并行的；(一个机器上，多个程序文件里)；可以留下执行点/新增执行点；可以删除执行点/减少执行点；
	>函数式编程为什么好：因为每个精细环节清晰描述确定了下来；使得充分配置和指明动作；
	>如何看待对象的方法：所有的对象都是被动的；主动的只有cpu/并行点；
	>程序的执行要想象为人在执行；多线程则是交接执行权给其他人执行；
	
----未知和迷惑的地方：痛点	；
----关键和核心的地方：要点

--混乱的答案，宁可不说；只回答真正掌握的；。没有逻辑，因为没有进行抽象；没有找到所在的流程环节、模型中的位置
--系统、中间件的介绍，不是一来就是组成结构；这层次已经太细了太具体了太里面了，必须要从最简洁最抽象最上层开始；最表面最近开始；务实，不僵硬，不突然，要自然，不要忽视和没注意没意识和跳过很多步；而是从问题出发、从困难出发、从疑惑出发
	>从问题出发：先明确问题；先明确表达出问题、疑惑点、黑箱、痛点、矛盾点、难点，表述的范围可以很大(完全不知道是什么怎么办)后面逐渐具体问；无论多少问题，先明确下来；尤其要全部且完整的描述下来；
		>问题的提出：先明确背景，自然衍生、过渡、转折、演化，逻辑关系上，什么时候什么事情什么人，事情什么阶段遇到的什么问题、阻碍、阻挠、缺陷、瓶颈、不够简洁、不够简便、不够方便、不够优雅、离目标远、离理想情况远、离期望/极限效果远；不够抽象的地方；把它们充分描述完整叙述结构式组织起来。
			>问题抽象：归结为一类问题；去除具体和细节而明确问题模型；
		>问题产生原因：过程；条件；	
		>问题导致的恶果：阻碍、损失；
		>理想的方案特征/效果/必做必不做的动作&事情/应当改变的环节: 
			>这种特征/必做必不做的前提、必要条件、必然要求、必然说明、必然指示、必然可以确定的更多的事情/结论：
				>一系列结论、约束得到之后(结合条件/问题/情况本身)逐渐可以清晰看到/归结出该具体问题符合的/满足的通用/一般的/一类的问题模型/函数模型/服务模型/IO模型/请求响应模型的轮廓：若干个具体模型
					>方案的装饰/补充: 补充可靠性/稳定性/高性能(从而高可用/高并发)：因为暂时只是一个裸机、容易受到伤害、有功能但没有抵抗力(仅为打火机的火而不是熊熊大火)
							>方案的用法规则：在请求缓存前使用
		>能将具体方案进行分类的维度/情况/模型/环节/流程/抽象表述 的确定：然后使用 抽象-具体 的方法来得到新方案；					
		>普通的方案：已有的方案；方案的抽象，方案的取值选择评价；方案的表象缺陷、劣势；。。模型、数据结构和算法、协议约定分担 维度 上考虑；

--大总结：含义包括：重新 深刻理解：
--通用的建模架构能力+Flink深度强化学习的推荐系统。。。。而不是做简单的业务逻辑开发；用深度强化学习来做应用/解决实际问题(用户的识别问题和抉择问题)；用抽象建模架构出逻辑完整的方案(工具方案/服务方案)；
--一体两翼的发展模型：底座：增强操作系统、网络、搜索、推荐能力； 两翼：普通项目：则架构建模；特殊项目：则深度强化学习；。。四大基础+两大实践(应用/使用)。。基础：是为了解决自己的问题；实践：为了解决别人的问题(用户的问题/大众)；
--一次彻底弄懂，而不是 反复低温加热

>介绍：概括
	>过程：十大过程；过程篇；
		>协议类：
			>RPC调用过程：
				>Dubbo调用过程：
					>服务端<->注册中心：注册、心跳
					>客户端<->注册中心：订阅、推送
					>客户端<->服务端：选调、限流+鉴权、降级+熔断
			>HTTPS一次过程：TLS一次过程：
				>目标：1.确定(所处)会话(id) + (协商采用的)加密套件 ；--> 2. 确定对方身份； --> 3. 确定对称加密密钥
				>过程： 
					>协商加密套件和会话：
						>客户端发送ClientHello: 包里包含： 一组加密套件编号 + 会话ID + 建议的加密套件编号 + 密钥交换需要协商的g-n-p 。
						>服务端响应：选择的加密套件编号 + 会话ID +(下一阶段使用的) 证书 +  密钥交换需要的B(协商gnp,发送A和B)
					>验证对方身份：
						>客户端：验证证书：用CA公钥解开(证明CA颁发)--->用证书里面的服务端公钥解开里面的数字签名(得到的为证书的指纹)--->用证书里面的指纹算法+密钥 对 证书生成一个指纹--->两个指纹比较，如果相等则证明公钥有效+证书完整性未被破坏。。从而公钥就是服务端的公钥。也包含域名验证、证书有效期验证；
					>确定对称加密密钥： 
						>客户端：利用收到的密钥交换算法需要的g-n-p, 利用自己的私有a生成A，发送给对方；(同时内部利用B-a-gnp生成密钥K), 为了证明K的准确性，还需要用K+随机数+对称密钥算法 处理 一个信息，生成结果 ，连带随机数 发送给服务端；
						>服务端： 服务端收到A后，结合g-n-p-b，可以生成密钥K', 然后用发来的随机数一起 对称加密 得到结果，看和发来的结果是否一致，一致则说明K是对的(或者直接看是否能解开)；密钥交换成功；
			>TCP三次握手/四次挥手过程：确定链路双向通畅
			>SQL解析处理过程：连接池(连接客户端)-->查询缓存(结果缓存)-->解析器(语法-句法-抽象语法树)-->优化器(执行计划)-->执行引擎-->存储引擎
				>连接：半双工。查询有状态--show full processlist 可以查看
				>查询缓存：使用场景局限。
				>解析器：生成语法树：关键字+取值 
				>预处理：表名、列名是否存在；表是否有权限；
				>优化器：选择最优的执行计划：执行计划是数据结构；(指令构成的数据结构)
				>执行引擎：根据明确的执行计划，调用存储引擎完成；
				--sql查询执行：from-->where-->group by-->select-->having-->order by -->limit  。。从临时表的变化来看很直观：https://www.cnblogs.com/fanguangdexiaoyuer/p/10268570.html
					>from: 加载数据库的表文件到内存
					>where: 应用过滤条件 到 表，生成一张临时表
					>group by: 应用拆分分组，会切分表为多个临时表。然后的select 就是取各个临时表的第一条，组成一张新的临时表
					>having: 应用 过滤条件(select后面的字段) 于 临时表，生成新的临时表
					>order by: 对临时表 排序 
					>limit 0,2: 取排序后的几个数据
			>DNS解析过程：用户程序-->本地域名服务器-->根服务器(回答.com找谁)-->顶级域名服务器(回答163.com找谁)-->权威域名服务器。共8个UDP报文。三类顶级域名(国家cn、通用com、基础结构arpa)。。逻辑根域名服务器13台：a.root-servers.net 实际中国17台，全球937台；副本；
		>算法类：各种系统使用；
			>负载均衡算法：静态、动态。实现：基于反向代理、NAT、DNS域名解析；
				>轮询：
				>最小连接：服务端实时当前连接数
				>源IPhash: 同一个ip的走同一个服务器
				>随机：
			>垃圾回收算法：步骤；判断；动作；。。复制；标记-整理；标记-清除；
				>G1算法：分代逻辑上连续。标记-复制；(充分利用多核、大内存)
					>分配：
						>巨型/大对象分配：依次尝试：Young中每个线程独享的TLAB区(无需同步机制即可分配)-->(不足)Eden区分配(需要线程同步机制)-->(无法容纳)old中Humongous区分配
						>Region中分配新对象：top值增加即可；bump-the-pointer, top就是已分配区域和未分配区域的界限的值；。
						>给每个线程分配：一个Buffer,类似TLAB； 需要扩容时，线程用CAS方式更新Region的top来获取新的空间；
						>Region的Remember Set: 是Region的集合，即外部的引用了这个Region中对象的对象所在的Region的集合；则initial mark 时找根：这些RS就是--因为存着外部引用
							>RS的实现：若干个Hash Table，每个Hash Table 都是线程独享--从而线程安全的；每个Hash Table存的：key=Card,val=引用的Region集合；参考：https://www.jianshu.com/p/aef0f4765098
						>Region的Card Table: 一个Reion, 划分为若干个Card,每个Card对应一个Byte来记录是否被修改过。(可能因为byte比bit并发性更好)
					>回收：两种模式：都是 “标记-复制-回收”
						>Young GC(STW):
							>触发时机：Eden区耗尽时。整个堆的使用率达到 -XX:InitiatingHeapOccupancyPercent=45默认的百分比：45%  。可调参数之三：-XX:ConcGCThreads=n (标记线程数)
							>过程：存活对象-->S0区-->多余部分和大对象和年龄超限部分晋升到Old区-->清空Eden+S1-->GC停止，用户线程继续
								>大过程：标记-迁移(一部分region中的活对象复制到空region中)-回收(被迁移region)
									>Marking cycle phase: 根标记-->根引用标记+s0中指向了old的对象的标记-->使用SATB的并发标记(bitmap+TAMS)-->重新标记(扫描SATB,处理新产生的对象)-->清除(统计存活对象)
										>基本变量：
											>Marking bitmap: 标记地址上的对象是否存活；
											>TAMS: 标记阶段 新分配对象的起止地址的变量
											>top: 类似position, 标记region已被使用的最大地址,即region未分配区域和已分配区域的临界点；
										>三大过程：简化描述：先行预知：1.region由card顺序组成 2.每个card对应一个起止地址(内部若干个存活/非存活对象)
											>初始标记：Initial Marking : 1. nextTams=top; 2.nextBitmap=bit[top](bottom到top长度)的空bitmap。。。(置空，置top)
												>确定标记起点的过程：扫出根， 扫Survivor里指向Old中对象的引用(作为老年代的根)。。。(扫根扫survivor)
											>重新标记：Remark: 1.扫region的bottom到nextTams之间的存活对象的起止地址，标记到nextBitmap;(此时top可能已经因为继续分配而移动到的更大的位置)。。。(标记存活)
												>存活对象的确定过程：并发标记：从 marking stack 里弹出引用，后扫堆的对象图，再标记到bitmap。(期间出现了引用修改，则原来的值被写屏障记录到log)
													>记录存活对象的快照：SATB：snapshot at the begining；并发标记阶段可能有修改原本的引用，则写屏障记录到log(两级：共享和独享)。。最终标记时，使用这些log来修正SATB
											>清除：1.prevBitmap=nextBitmap; 2.将prevBitmap对应标记的region中的存活对象起止地址之间的间隙地址上的垃圾对象 标记为清除。2.prevTams=nextTams;nextTams=bottom;。。。。(统计存活)(排序region,从而确定CSet)
									>Evacuation:  选出若干个Region进行回收-->其中存活的对象(扫描根+RS来确定)复制到空闲的Region里去--->回收Region放到空闲Region列表里
										>两大过程：
											>选择Region: 根据标记阶段 排序的region+最大暂停时间限制考虑, 选择若干个(按模式是否要选择Old region)。形成CSet
											>迁移存活对象：将CSet里的region中的存活对象复制到空闲的region里；(有的提升到老年代里)
							>回收单元：Region, 每次n个；
								>回收Region链表：每次GC回收的Region都加入到链表；
							>记录对象被标记：bitmap 	
						>Mixed GC(STW): Young + old 
						--待回收Region集合：Collect Set 。fully-young模式下集合里全是Young region; partially-young模式下集合里大部分是young region,一部分是old region;----选择依据是 存活对象计数 最少的；
				>CMS算法：内存整理时间太长--所以G1产生了；
					>分配：
					>回收：
						>目标：降低每次垃圾回收的时间；最小影响可用性；
						>阶段：根标记-->并发标记-->并发预处理-->重新标记-->并发清除-->重置。
							>过程：确定gc root直接关联的对象(new/old)-->出发所有可达的对象-->(重新标记的预备工作)三大对象的标记(新晋升/新分配/新修改),并发进行一次MinorGC, 老年代分块(之前标记脏，现阶段扫描标记可达)-->并发清除-->重置，清除内部状态；
								>gc root的确定之一：old区有remember set记录了指向新生代的引用(从而不用扫old全部)(Point-out类型) 
						>触发时机：5种；老年代使用率：92%；(使用率未超过)大对象担保失败(未先到Young)、晋升失败(晋升量太大)、并发模式失败(CMS GC过程中新产生的浮动垃圾多而装不下)、MetaSpace空间不足、手动System.gc(显式gc)(直接内存分配或者回收时)
						>备案：老年代设置太高，启动SerialOld
						>内存碎片整理：1.默认开启；FullGC前STW；2.配置k次不压缩的FullGC后执行1次压缩的FullGC(即FullGC后)
				>复制算法：存活对象不多，可以直接复制出, 自动压缩；
					>判断存活：可达性分析。(java没使用对象计数法)
				--决定是否进行MinorGC: 空间分配担保： 如果 Old最大可用连续空间>min(历次晋升量,Young全部)，直接MinorGC, 否则先FullGC	
			>动态规划算法：确认有递推关系；建立递推关系；字符串相似度算法；
			>Diskt最短路径算法：KMP算法
			>限流算法：
				>计数器算法：无需额外线程；一个请求累加1，达到N则限流；和上次更新时间的差达到了T,则清空计数器,从0开始。问题在：清空，意味不再计算刚才涌入的数据(导致最高短时间deltaT涌入2N而没被限住)；
				>漏桶算法：
					>不用额外线程：每个请求到，如果自旋等待线程数过限，则直接失败返回；否则计算上个请求通过的时间，没到deltaT则等待余时，到了则竞争取锁，成功则开始执行，失败则自旋，且自增等待线程数，等待时间超过限定则失败返回。从而几乎每个请求都会等，且等n个deltaT。
					>用额外线程：每个请求到，先入队等待,队列满则退出，等待时间超时也退出返回；独立线程请求队列首元素，唤醒它；唤醒之后，等待deltaT。。队列容量=容忍在队列中的等待时间*1/deltaT
				>令牌桶算法：无需额外线程：需一个令牌量计数器；每个请求到，令牌量为0则返回，否则令牌量减1；当前时间距离上个请求的时间的差*1/deltaT 为增量，加到令牌量计数器里；总量达到N则为上限；。令牌就是缓冲突发的大量请求而都能处理；
				>滑动窗口算法：无需额外线程；k个累加器,1个当前累加器指针,总量达到N则限流；和上次更新时间的差达到了T/k,则更新当前累加器指针为下一个累加器；要考虑刚才的计数，不是清空为0，而只清空最近T时间内的最早T/k内的统计量(从而被忽略的时间内的量对计算的时间内的量相比，因为忽略的比例很低，所以更准确)，则实际最大2N涌入而没有被统计出来，需要分布的时长>= T*(k-1)/k + deltaT ,如果时间更短，则会被统计出来；。。从而瞬间N的两个突发至少要间隔T, 才不会被发现；
			>一致性算法：
				>paxos算法：
				>zk选举算法：
				>raft算法：
			>加解密算法：
				>公钥加密算法：用公钥计算私钥加密的结果 还原出原信息；用私钥计算公钥加密的结果 也能还原出原信息;公私钥不相等；
					>RSA：1.基于欧拉定理：互指的两个数a,n,满足：a^Φ(n)≡1 (mod n) 2.基于模反元素：an互质,则存在b,使得 ab mod n = 1；b为a的模反元素， 很明显a^(Φ(n)-1)就是一个；3.希望有加密还原过程，所以基于欧拉定理进行加工转换等值操作--试图再次得出a：利用数模等值公式得出：a^(k*Φ(n))≡1^k (mod n)≡1 (mod n), 利用两边同乘一个数等式成立，自然乘a,就会出现还原过程：m^(Φ(n)*k+1)≡m (mod n) 。显然信息m经过Φ(n)*k+1处理后对n取模又还原为m了，而处理如果分为中间过程，分为两步，则第一步的结果可以当作加密，后一步当作解密计算；自然的令e*d=Φ(n)*k+1, 那么 m^e mod n作为加密结果传递，则(m^e mod n)^d mod n = m mod n 就还原了m; ed就是公钥和私钥；在二进制位数一定情况下，则还原的m是唯一的；。e的计算，e和Φ(n)互质,找出一个很大的质数就可以，d则通过模反数来计算--也方便；					
				>密钥交换算法：双方互传部分信息，利用对方和自己的私有信息生成的K是一样的。但单用互传的那部分信息无法得出K。
					>DH密钥交换算法：1.基于难题 g^k ≡ n mod p ,已知gnp,难算k (所以k当作私有,gnp互传)(指数私有,结果互传).  2.利用关系：a次方的模等于模的a次方的模：m^a mod n = (m mod n)^a mod n 3.设计收到的+私有的生成相同K: 看到m nod n 则认为是收到的，则它的a次方的a是私有的，则结果(m mod n)^a mod n 就应该用作K;  则我方要传递什么结果，对方也能得出K,则从形式上，对方(c mod n)^b mod n = K , 即收到c mod n, 私有b, 则必要求  (c mod n)^b mod n = (m mod n) ^a mod n ,很明显，就是要c^b mod n=m^a mod n,显然mc表示为指数形式，则可以增加约束条件/具体条件c=g^a,m=g^b; 这样就可以保证生成的K相等；增加的条件的等价含义就是：分别发送 g^a mod n和 g^b mod n给对方；根据难题，知道这两个结果也难以猜测a,b的值；双方利用来生成K就安全了。 
				>用户认证算法：
				>对称加密算法：
				>信息摘要算法：
			>TCP初始化启动和拥塞控制算法：
		>方案类：
			>分布式事务：
				>二阶段提交方案：
				>事务消息方案：
				>实际过程：
					>开启：
					>执行：
					>提交：
					>回退：
					>补偿：
				>CAP定理：问题驱动确定的典范。
					>最开始系统要解决的问题/任务：网络分区的容错(产生了网络分区，是问题；之后怎么处理可以不影响正常服务?什么处理是最佳的--直接去解决这个问题-立即恢复显然现实很难做到；直接解决问题的要达到的目标目的---可用性--达到相同目标下此场景下有无更好的做法)--->理想方案最简单最好方案显然是直接切换到另一个节点即要求有副本(部署在其他节点上)(主节点故障时立即切换过来),多副本则带来的新任务/新事情/运行起来的前提/必要条件是：副本是一致的，否则读取不同节点上的同一个变量结果会可能不一样，副本如何一致这个问题的解法，无论如何肯定不会是同时立刻可以实现的事情，需要节点间进行数据同步，所以同步期间肯定就不一致；如果同步期间不提供外部服务，则访问成功的数据肯定一致；如果同步期间也堆外提供服务，则访问成功的数据也可能不一致；
						>即：分区容错-->要求有副本(但运行良好的前提条件苛刻)-->条件就是副本要一致(降低了一致性)-->要求有同步时期(补偿方案)(弥补方案)--->带来可用性问题(降低了可用性)(没有补偿方案)。(是个trade-off,权衡)
			>分库分表：
			>数据同步：
			>缓存：
			>监控：
			>消息：
			>可靠性方案：所有意外情况/取值的事先考虑和处理;所有异常的兼容和都有处理分支；n个维度的意外特殊取值；n个条件的满足才能正常工作；m个条件满足则超长工作；
				>可靠性-数据方面：因缓存在内存未刷磁盘导致丢失的比例；
				>备用方案选择流程：出问题前：预防而不易出问题；出问题/摧垮后：补救措施；备用方案；灾害降低到最小；快速恢复(满血复活)(自我修复、自愈能力)；损失降到最低--所以可靠/放心；
			>稳定性方案：单节点各项指标(使用率：cpu/mem/disk)随流量和各种故障因素的加入都变化很慢而不是变化幅度很大；
				>增加缓冲：避免超过处理极限；。小波动。
					>使用分布式缓存：
					>三级缓存：
				>增加检测和预备：大波动；
					>统计和扩容/缩容：统计单位时间内的变化量，估计变化时间；估计短时间内需要的总量，弥补差额；。
						>垂直扩容：
						>水平扩容：
					>检测故障和切换节点：心跳检测、指标检测；可用节点切换到对等服务/冗余节点、节点摘除；
						>消除单点故障：keepalived虚ip方案；冗余+心跳+切换 方案；
				>增加保护措施: 超大波动。在超过处理极限时；避免崩溃而完全丧失处理能力,舍弃无法顾及的；避免压力传递到后面的服务。
					>限流：仅提供降级服务
					>鉴权：
					>熔断和降级：就是服务调用的自动切断和自动恢复。切断后的替代服务。
						>熔断：服务判定不可用-->不再耗费来尝试调用/调用切断-->服务状态周期性试探(间隔15s/5s)-->限流逐渐放开/10%幅度/30%/50%/80%/100%
					>灾备：同城灾备/异地灾备。5种集群：主备/主从/多主/对等集群/非对等集群
						>多机热备：运行 keepalived 的节点 被 设置虚ip，有仅一个被设置，其他未设置；节点故障时立刻其他节点设置虚ip 实现故障转移。keepalived(心跳+选主策略)
						>一主多备：
						>冗余：双电源、双网卡、多机房；
						>隔离：物理隔离
				>增加补偿措施：限流的部分，先记录到日志 或者 记录到消息中心 存储起来，如果业务可以--则等待消费而补偿；否则也可以进行统计。	
				---业务逻辑实现方面：代码方面：享元模式、消除冗余、消除重量级操作；(通过codereview,单机压测，全链路压测发现问题: 内存泄露、死循环、死锁、线程文件使用)
				---微服务问题：还有更多。类似服务下了,ip未在客户端下。
			>可用性方案：可用性是表象(已发生的统计；未发生的承诺：不可服务的时间的比例<)；稳定性是性质，可提高可用性；
				>稳定性说明一年内崩溃的次数，可靠性说明每次崩溃的时间：一年只崩一次(稳定)，一次只需30s恢复(可靠)。。可用性是不可用时间：崩的次数*平均恢复时间。
				>影响可用性的因素：
					>不利因素：大流量(压垮服务器/动态无法正常工作/指标打满)、电源/网卡/机房故障/硬件故障(服务器直接物理性无法正常工作)
						>指标超阈值：(cpu/mem/io/disk/call)超过额定值。因素：大流量、软件bug、病毒攻击
						>物理损坏：电源老化、网线切断、机房火灾/水灾、元件功能异常。(单点问题,必须要后备/)
				>影响一致性因素：
					>不利因素： 副本太多、副本相隔太远、副本太大、同步太久；
			>高并发方案：高并发是表象(吞吐量)(网站/服务/单机吞吐量的提高的优化措施；瓶颈确定、替代方案)；高性能是性质，可提高并发度；
				>减少阻塞：
					>网络IO方面：异步非阻塞，主从多线程Reactor线程模型
					>磁盘IO方面：零拷贝、直接内存、页缓存
					>服务调用方面：超时断开/重试-->熔断降级；(依次更重,熔断后返回降级结果)
				>减少同步：
					>CAS无锁操作：
				>减少串行：增加并行
					>异步：消息队列、事件监听+回调
					>多线程：线程池
					>请求级并行：多实例部署
				>减少临时才做：增加预备、减少性能损耗、代价耗费，增加使用效率
					>内存预分配：减少分配和回收的消耗；
				>减少专门去做：增加复用 
					>线程复用：
					>连接复用：tcp连接复用/jdbc连接复用/rpc调用复用(聚合服务)
					>数据复用：缓存；
				>减少流量压力：增加分流、增加冗余节点、无状态对等节点
					>集群部署：
				--以上总结：模型：链式调用模型来展示：三处优化：1.缩短请求和返回的路径--异步；2.多个连续步的并行--多线程并行；3.某个步的消除--复用(数据/连接/线程)
			>高性能方案：
			>安全方案：加密套件
			>升级方案：流量切换(摘掉节点(配置))、流量排空、节点服务升级更换、节点重启、加入节点(配置)、服务检测、版本回滚；灰度升级；
			>容量规划方案：
			>测试方案：
				>流量复制：
				>单机压测：
				>全链路压测：
			>灾备方案：	
			>优化方案：因势利导；看情况而针对开药；望闻问切(而不是稀里糊涂不知病因而直接上猛药)；
				>jvm调优：
				>mysql优化：
					>痛点：瓶颈；
						>扫描行数太多：分库分表；索引没使用到/索引不好：索引优化(匹配查询)；
						>查询结果太多：利用覆盖索引；查询缓存开启；ICP/MRR优化；页缓冲池预热；业务方面：分页查询、先不排序、减少连表；
		>选型类：各个选型判断逻辑流程；
			>数据存储方案选择：
			>数据索引方案选择：
			>数据缓存方案选择：
			>微服务RPC框架选择：
			>微服务治理方案选择：
			>微服务监控方案选择：
			>微服务管理方案选择：
		>对象变化类：变化过程
			>锁膨胀过程：
				>偏向锁-->轻量级锁：
				>轻量级锁-->重量级锁：
			>锁粗化和锁消除过程：
			>申请锁和释放锁过程：	
		>周期阶段类：	
			>类的生命周期：7 加载、验证、准备、解析、初始化、使用、卸载
			>对象的生命周期：7 新建、使用、不可视、不可达、可收集、终结、释放
			>线程生命周期：6 new->running->blocked-->waiting-->time_waiting->terminated
	>组成：模型；架构；。基于模型谈过程，则过程显得清晰明白简洁；
		>领域模型：
		>概念结构模型：
		>JVM内存模型：
		>线程模型：
			>线程本地：ThreadLocal 
				>线程的私有背包：t.threadlocals = new ThreaddLocalMap()	用户线程无法访问。
				>线程的私有背包的对外接口：只能通过任何ThreadLocal 实例来访问到, 且实例不同，访问到的是背包的不同包包。
				>ThreadLocalMap:
					>expungeStaleEntry(index): 将index位置清空，且将它后面相邻的清空(key=null) 或者搬开到右边空位(key!=null)；
					>cleanSomeSlots(int i, int n): 从i开始找空key，找到则调上述方法进行清空且相邻清空或搬开。总共进行log2(n)轮，所以对于空key-null-空key-null...这样的数据布局，就不会清完毕。
					>rehash()：执行条件：i+1位开始连续log2(n)位上都没发现过空key--为null或者非空key, 且体积达到阈值。处理：先遍历entry[],处理掉所有的空key,如果此时size>=3/4阈值，则开始resize()扩容。
						>扩容过程：先2倍长新Enry[],后逐个迁移：如果此时变为了一个空key, 则清空它，否则hash定新位--有元素则右找至非空位。遍历完成后，新阈值=新len*2/3, 新数组替换原数组；
					>set(): 用key的hash定位,如有元素了，key同则替换值，空key则@replaceStaleEntry()即可能替换可能设置；如果没元素 则直接new Entry(key,v)替换；然后判定是否需要rehash需要则做。	
						>@replaceStaleEntry(slot,key,v): 寻找slot的非空左相邻中最左的空key位--s1，寻找非空右相邻i, 如果它是空key 且 s1==slot,则s1设置为i, 否则它不是空key且其k==key,则更其value=v,且交换元素i和元素slot, 如果slot==s1,那么s1=i；无论如何，接着都会：清空搬开s1开始的元素@expungeStaleEntry(),后开始清扫这一位开始的空key:@cleanSomeSlots(),清扫完成则返回。如果右找中遇到了null位了则直接将slot位置设置为新的Entry(key,v),如果s1 != slot则 清空搬开s1开始元素后开始清扫。
					>get(): 用key的hash定位，如果有元素且key同，则返回v; 如果没元素则没元素；如果有元素但是空key, 则顺便清空和搬开一下@expungeStaleEntry(); 如果有元素但是key不相同，则继续寻找下一个元素--看key同/空key/key不同，直到找到或者遇到空元素才退出--返回Null:@getEntryAfterMiss()
						>没有先set()而get(): 则会设置一个初始v=null进去。创建map也设置null进去。k就是调用ThreadLocal
			>线程池：Thread/ThreadLocal/ThreadPoolExecutor
				>数据结构：1 queue + n worker......status
				>状态：running->shutdown->tinying->terminated; 第二种：running->stop->tinying->terminated
					>可入队列可取任务：running  
						>此时提任务-->(增worker->入队列->增worker->拒绝策略(默认抛异常))
						>此时worker刚刚区得任务：消费一次中断interrupted，后执行任务。
						>此时worker正在执行任务：完后去拉取任务
						>此时worker正在拉取任务的阻塞中：
						>此时worker去拉取任务：总可以到poll()/take()方法
					>禁入队列可取任务：shutdown 
						>此时提任务-->(拒绝策略)。  如果提空任务-->(任务队列非空则新增worker，否则拒绝策略)
						>此时worker刚刚区得任务：消费一次中断interrupted，后执行任务。
						>此时worker正在执行任务：完后去拉取任务
						>此时worker正在拉取任务的阻塞中：
						>此时worker去拉取任务：队列非空可以到poll()/take()方法，否则返回null导致worker退出
					>禁入队列不取任务：stop 
						>此时提任务-->(拒绝策略)。提空任务-->拒绝策略
						>此时worker刚刚取得任务：调它的线程的中断,后执行任务。
						>此时worker正在执行任务：完后去拉取任务
						>此时worker正在拉取任务的阻塞中：
						>此时worker去拉取任务：直接返回null导致woker退出
					>tinying
						>此时提任务-->(拒绝策略)。提空任务-->拒绝策略
						>此时worker刚刚取得任务：调它的线程的中断
						>此时worker正在执行任务：完后去拉取任务
						>此时worker正在拉取任务的阻塞中：
						>此时worker去拉取任务：直接返回null导致woker退出
					>terminated
						>此时提任务-->(拒绝策略)。提空任务-->拒绝策略
						>此时worker刚刚取得任务：调它的线程的中断
						>此时worker正在执行任务：完后去拉取任务
						>此时worker正在拉取任务的阻塞中：
						>此时worker去拉取任务：直接返回null导致woker退出
					--注：队列take/poll底层都是条件对象的await()	
					--注：线程中断后执行sleep/轻量级锁的条件对象await()时都直接抛中断异常,但Object.wait()则继续阻塞
					--注：正在lock()中的线程被中断了，则park()唤醒，但还是继续排队继续park(),只是lock()退出前最后一步更新当前线程是已中断状态/自中断。
				>关闭：shutdown()：更新状态为shutdown-->调每个非lock()<非重入锁>中的 worker的中断-->尝试终止：若队列非空则返回,若还有worker则中断一个后返回，否则就更新状态为tidying-0，成功后设置为terminated-0
				>立即关闭：shutdownNow(): 更新状态为stop-->调每个worker的中断-->强行提取队列中任务-->尝试终止：若还有worker则中断一个后返回，否则就更新状态为tidying-0，成功后设置为terminated-0
				>拒绝策略：1.poll一个后再提交当前任务；2.默认：抛拒绝异常
				>引入技巧：简化措施、简便方法、高效手段
					>原子的更新2个小整数：将这两个小整数放在一个long整数的高低位；然后同时对这个long整数进行cas 的位运算即可。ctl:运行状态和worker数
				>常见问题：
					>线程中断方法的调用：Thread::interrupt() 主线程/兄弟线程都有权限调用。最后都会调用interrupt0()本地方法来执行实际的线程中断抛异常。
						>效果：#wait()类型：抛出中断异常；#Channel类型：抛出通道被中断关闭异常；#selector类型：直接唤醒；#park()类型：直接唤醒； #synchronized无用--但是线程状态已经改变(为interrupted,所以后面只要调#sleep()都会直接抛出异常)。
					>将线程状态改为未中断相当于处理了中断"中断过了"：Thread.interrupted() 返回原状态，后改变线程中断状态为 未中断。导致sleep()执行时不会抛异常。
					>测试线程是否中断不改状态：Thread::isInterrupted()
					>线程池中提交的任务抛出异常：捕获异常，处理(尝试终止-->未成则新增worker)，后继续外抛-->最终到Thread.run()方法抛出异常-->从而线程退出结束。
					>线程池调参：corePoolsize = qps * task_time; maxPoolsize = qps * task_count * task_time, queue_size = qps * (task_count - 1) * task_time 可能导致等待任务太多；因此可以：corePoolsize=maxPoolsize, maxPoolsize = 2*maxPoolsize, queue_size=minPoolsize。另外，队列不要太长，就算直接用主线程来执行;所以可以固定：queue_size=minPoolSize---这样相当于每个core worker只有一个备份任务。
						>cpu核数参考：
						>自动调参：实时监控-动态调参-线程池监控/服务监控
						>一般规律：核心来处理到达的所有请求：corePoolsize=qps * task_count * task_time, 队列来缓冲小部分请求，但队列里的请求不能等待太久，< 1个请求处理的时间，如=0.5*1个请求处理的时间(系数必须<1才能使得排队不比串行执行慢)，则 queue_size=0.5*corePoolsize, 而最大worker数则是直接处理的最大线程数，应该和cpu核数有关，经过模型推导(等待时间+切换时间+执行时间)，得到 进行并发更快的极限并发数=k*t1*(n-1)/((k-1)*t2), t2是线程上线文切换耗时：大约2ms, t1是单个task执行耗时如20ms, k是一个请求分解的并行任务数如4,n是cpu核心数如8；得出并行请求数为93，即 maxPoolsiz=93*4=372, 而在此极限时并行执行时间约等于串行执行的时间，一个请求的串行执行时间=20ms*4=80ms,加上其他处理20ms，则100ms,所以1s内可以串行10批，从而可以支撑的qps=93*10=930。。而如果采用串行方案，则支撑的qps=8*10=80,所以充分利用并行，在不输串行时间条件下，qps可以暴涨10倍。而如果要并行时的耗时降低为40ms即为降低一半或者到2/3,则推导出统一公式m=k*t1*(n-q)/(t2*(qk-1)+k*t1*(q-1)),q就是一次请求的串行时间是并行时间的倍数；可以发现，此时qps基本不变。即说明8核的效果可以要么提高qps到11倍但是响应时间为串行时间，或者响应时间为一半但qps不变。两个好处可以得其一：因为q大则m小,m小则q大
			>用户线程和内核线程的映射：一对一，多对一，多对多
			>调度方式：java线程：强占式调度---由系统分配执行时间	
		>网络IO模型：阻塞/非阻塞(手动api查结果)，同步/异步(回调通知结果)：
			
		>java并发模型：
		>锁：锁的代码。01->00->10。。线程锁：资源是代码；访问者是线程；访问者获取到锁才能访问对应的资源；
			>entryList: 阻塞队列
			>waitSet:等待队列
			>count: 重入次数
			>owner: 锁拥有者
			>是否可中断：
			>是否能超时：
			>并发场景：1.多个线程，取锁释放，交叉并行；2.多个线程，取锁释放，但先后串行，之间甚至有间隔deltaT;3.一个线程，先后k次取锁释放；
				>针对设计：场景1则重量级锁，处理竞争；场景2无需阻塞则轻量级锁避免上下文切换开销；场景3无需切换则初始化一次获取锁避免反复获取锁释放锁的CAS开销(判断owner是自己)；
				>竞争处理：场景1则到entrylist阻塞；场景2先立即失败重试即自旋k次后面失败则升级锁即修改锁状态+新建一个锁对象owner设置为占锁线程并将当前线程加入entrylist阻塞；场景3先立即升级锁更新锁状态创建锁记录放到占锁线程里,竞争线程开始自旋k次尝试；
			>锁的内存语义：锁的获取和释放；数据的加载和保存；
		>事务锁：资源是记录；访问者是事务；访问者获取锁的并发控制策略(只能串行：独占锁；可以并行：共享锁);	(当资源是一条记录时：行锁；一个范围但不包括里面已有记录时：间隙锁；一个范围且包括里面已有记录时：next-key锁)
			>资源：
			>访问者：
			>访问者获取锁的并发控制策略：
			--案例：select .. for update X锁；select ... lock in share mode; S锁
			>使用事务锁产生的问题：
				>死锁问题：解法：超时机制+等待图
		>事务：操作记录的过程：1.加锁；2.看隔离级别；0.备份到日志(undo)；3.操作记录/提交成功；4.防丢到日志(redo);5.逻辑备份(binlog)
			>基本属性：
				>原子性：1.事务的所有操作 要么都是成功的，要么都是失败的；(不能成功部分，而失败部分--尽管失败的这部分回滚且成功了)(保证整体一致，全局一致)
				>隔离性：1.事务A在操作资源R的时候B不能操作B必须阻塞等待
					>隔离级别：
				>一致性：1.做之前的数据 和 做了但失败而回滚后的数据 一致(单条记录的一致)；2.一致变化：原子式的 事务的每个操作 都是成功的或者都是失败的；(不能成功部分，而失败部分--尽管失败的这部分回滚且成功了)
				>永久性：1.t时刻成功的事务，所做的修改即便立即崩溃 服务器启动后还是事务成功后的数据(版本)；
			>使用事务也会产生的隔离性问题：
				>脏读：
				>不可重复读：
				>丢失更新：
				>幻读：
			>使用锁的画面：开启一个事务 到 提交/回滚一个事务 期间，可能使用了多个锁(每个锁什么类型跟语句有关)(加了独占锁可以再加共享锁，加了共享锁也可以再加共享锁)；
		>索引: B+树索引、全文索引、哈希索引
			>数据结构和算法： 
				>B+树： (二叉查找树：左子<中<右子)(平衡二叉树：子树高度差<=1; 从所有叶节点向上到根 得到n条路径，每条路径每个节点标记已走步数；所有路径相交处的已走步数差<=1)
					>叶子节点：主键+数据页；数据行所在的页-完整行记录；页读取到内存，再从内存页中查找；。互相指向，前后首尾；。。辅助索引节点：(key1,keys,若干个主键值(所以需要回表，但不用维护到数据页的偏移量))；(rows:预估行数)
					>构建过程：分裂/合并(多时少时都可能和兄弟节点合并,减少消耗大的拆分) 
					>索引页中有叶子数据：是(叶子节点中有索引数据) ；高扇出：是(且指针k,扇出k+1)
					>树高和耗时：16KB页，14Bbigint+pointer, 每页加载耗时10ms
			>建立时机：选择性>0.5；记录总数>2000；	
			>优化器选择哪个索引：
				>走联合索引：count(*)统计时；(a,b,c)用a,b列查询而c排序 且只查a,b,c,primarykey时(查全部列则不会--因为回聚集索引会导致离散读磁盘--代价大)；
		>mysql日志：
			>undo:
				>组织结构：格式
				>单条内容：含义。逻辑日志(但非SQL)，每行记录；
				>写入方式：随机写；数据库内，共享表空间中，非独立文件；
				>写入时机：事务执行中(因为insert/update的undo log行记录不同)；事务提交时将undo log行记录放入链表中(purge线程判断是否删除,删除后就减少了链表长度)
				>读取时机：使用场景/用途；mvcc;回滚/失败;
			>redo:
				>单条含义：每页的物理更改情况；
				>单条结构：(innodb)头部(redo log type + space + page no)12B + 主体(若干个事务的变更内容，字节长度为LSN) + 尾块()8B： 一个重做日志块(512B)大小同磁盘扇区大小，从而无需doublewrite
					>redo log file: 前2KB: log file header + cp1 + null + cp2; 后面则是 日志块log block1 ,lock block2.... 。两个cp 交替写入(提高可靠性)(用于恢复操作中)；
				>写入方式：顺序写。先写入重做日志缓冲buffer 后 调用fsync强刷到磁盘(事务提交时)；重做日志文件中。
				>写入时机： 事务进行中不断的写入(从而T1T2T1T3分块分布)(按事务开启顺序而非提交顺序)
				>读取时机： 数据库恢复(重启)时，读取redo各个事务块应用到对应的page上(比较了LSN,从checkpoint LSN开始应用日志块)；
			>binlog:
				>单条内容：逻辑日志；SQL
				>写入时机：事务提交后一次写入(按事务提交顺序而非开启顺序)
				>读取时机： 主从复制；POINT-IN-TIME恢复；
		>mysql页：内存中的页(存储到磁盘上也存有LSN)
			>首部：FIL_PAGE_LEN 值为所有事务在该页上引起的变更的内容描述的字节总长(对应redo中该页的事务日志块记录的LSN)
		>存储引擎：
			>是否支持事务：
			>锁粒度：
			>支持索引类型：
			>单表数据：
			>sql性能：
	>模式：
		>23种设计模式：
		>8种架构模式：
	>策略：
		>缓存过期策略：redis
			>LRU:
		>负载均衡策略：nginx
		>服务调用策略：client
		>jvm调优策略：
		>sql优化策略：
		>故障恢复策略：failover, failsafe,failback,failfast
		>MVCC: 是一种事务访问多个版本的记录的策略(访问哪一个)，入参一个：隔离级别；访问动作：读、写；
	>系统：中间件
		>redis: 数据怎么组织、存储、查询、变更；是否支持索引、是否支持事务；统一架构模型；
			>一致性hash:
			>分片：
		>mysql:
		>dubbo: x个过程+y个策略+z个算法
		>消息系统：架构过程
			>背景/痛点/阻碍/瓶颈：直接调用太耗时、事件发送/推送/广播不支持；
			>基本需求明确：一个高性能的高可靠的事件发送、推送、拉取系统
				>领域明确：事件、发送方(生产者)、事件中心、接收方(消费者)
					>各领域的基本属性和基本行为：
						>事件：事件类型、事件内容、事件所属的目的地名称(topic)
						>生产者：构造事件、发送事件给事件中心、收取响应
						>事件中心：接收事件、发送响应、管理事件(分派到它要求的目的地--某队列)、接收消费者注册请求、响应注册请求、管理注册的消费者、推送事件给消费者、接收响应、回应拉取事件请求
						>消费者：发送注册请求到事件中心(感兴趣的事件类型/带某标签)、接收注册回应、接收事件、回应本次接收体验、拉取某类型/标签/主题的事件、回应拉取后的体验
					>若干项服务流程：设计的高性能、高稳定、高可靠；开发者使用简便、扩展简便(替换某组件)；
						>消费者注册：
							>流程环节：
								>构造请求：模板/建造者
									>实现方案的确定：
										>理想方案的特征：约束
											>特征进一步确定的必然：
												>归结出一般的函数模型/服务模型：
													>方案的装饰/补充：
													>方案的使用方法：
								>请求序列化：+编码+压缩？
								>使用通信框架承载发送：netty/nio/bio/http
									>理想方案的特征：约束。直接调tcp/ip发送；无阻塞；异步获取结果；通信安全；
											>特征进一步确定的必然：多端口单线程监听，epoll事件回调；TLS使用；
												>归结出一般的函数模型/服务模型：异步非阻塞IO模型
													>方案的装饰/补充：补充使用便利性：对象的序列化放在通信框架上(过滤链上)
													>方案的使用方法：直接入参：对象；回调：发送成功/收到处理结果成功；
								>获取结果：同步/异步 
						>消费者拉取：
						>生产者发送：
						>事件中心推送/响应：
		>传输层协议：
			>TCP: 单播
				>连接建立：3次握手，确定双向链路通畅。
					>同时打开：则4个数据包
					>半开：客户端在ESTABLISHED时崩溃；重启后新建连接；原来那个在服务端还存在--是个半开连接；
					>连接建立超时：指数回退 方式 重试 
				>发送数据包格式：
					>包内容：序列号+端口+置位+校验和; 窗口大小+确认号。置位：SYN+ACK+FIN,RST(连接取消而重置/端口没有进程监听)+CWR(拥塞窗口减)
					>包大小：不固定长度(包里有长度)
				>包异常的处理：丢失、重复、差错、乱序时分别的处理
					>丢失：缓冲区滑动窗口内有数据没收到ack，超时(RTT估计而确定)重发(重传计时器)
					>重复：丢弃 
					>差错：验证出错则丢弃
					>乱序：数据首字节在原数据中的字节偏移量+长度，先缓冲；发送SACK 告知重传；
				>包异常的预防：
					>拥塞控制：初始阶段，滑动窗口根据返回ACK而指数增大；超过阈值而减半后线性增长；
				>结束连接：4次挥手，双方独立停止连接；
				--TCP状态转换：
					>连接：客户端3：CLOSED->SYN_SENT->ESTABLISHED; 服务端3：LISTEN->SYN_RCVD:->ESTABLISHED 
					>关闭：客户端3：FIN_WAIT_1->FIN_WAIT_2/CLOSING->TIME_WAIT(2MSL)/TIME_WAIT ; 服务端3：CLOSE_WAIT->LAST_ACK->CLOSED 
				--TCP保活：2h没收到报文,发9次保活报文，每次间隔75s; 都失败则发送重置报文；	
			>UDP:	
		>日志：
			>日志系统的领域驱动设计：
				>目标：本质上是一个日志数据存储系统；
					>理想形态：要求支持并发调用、非阻塞返回。
						>具体实现：则先对环节精细的明确，定为：先缓存、格式化 后再批量存储到磁盘的 日志存储系统。
			>log4j2: 在架构和环节上的优化：LMAX Disruptor的使用(无锁的线程间通信库)。
				>Append的过程：追加event的过程：
					>RollingFileAppender: 编码之后写入了 ByteBufferDestination，具体过程是调用后者的write方法，内部以synchronized方式写mmap或者FileOutputStream(具体走哪个看ByteBufferDestination实现类型)。
					>MemoryMappedFileAppender: 写入 manager内的ByteBuffer，也或是写入 FileOutputStream (具体看是否设置立即刷 或者 LogEvent是批的最后一个)
					>AsyncAppender: 事件转Log4jLogEvent，内部有queue,可能是由DisruptorBlockingQueueFactory创建DisruptorBlockingQueue，或普通的ArrayBlockingQueueFactory创建的ArrayBlockingQueue
						>事件落地路由策略：
							>异步：logMessageInBackgroundThread()-->则先 queue.put(logEvent)  (一个AsyncAppender只有一个后台线程)
								>建立后台线程和后台线程处理queue时机：配置类设置/工厂设置时调用了@start()方法：启动了后台线程AsyncThread, run里：循环中queue.take()然后调用appender来消耗callAppenders(event)，queue为空则event的批为最后一个--就会刷到FileOutputStream；
							>同步：logMessageInCurrentThread()->则直接调同步的appender开始刷入缓存ByteBufer或者磁盘：thread.callAppenders(logEvent)-->appender.append(event)
						>Disruptor的使用: 写：抢位(条件为tail-head<size)->成功则设置值+增加tail-->失败自旋。读：抢位(条件为head<tail)-->成功则读取值后置空+增加head-->失败自旋。模型： 一条整数线, head --- tail 各自增长变化/忽近忽远。
							>LongAdder 的使用：提高并发更新度和降低冲突概率。而采用的内部数组分散存各个值。总和才是真正的值。tail/head的值。
							>ContendedAtomicLong 的使用：消除伪共享，先内部新建长度为16的long数组整体对象--AtomicLongArray,而把要存的long放在index=8的位置，则前7后8个元素，则它不会受到其他变量更新的影响而重新加载所在缓存行--因为一定独享/确保了独享一个缓存行。 tailCursor/headCursor的值。
							>新值设置位号slot的确定：tailSeq & mask 因为tailSeq虽然不断增大，但是对于低32位来看,是周期的自增的--到最大后下次为0.。前提：数组长度：2^n。前提2：tailSeq为long,从0开始；100w/s，用3w年。
							--写抢位对tailCursor cas,而用headCache当作条件。读抢位对headCursor cas,而用tailCache当作条件。
							--真正实现类：MultithreadConcurrentQueue 非 DisruptorBlockingQueue---后者是在前者基础上做了 非空非满的激活和读空写满的阻塞。
						>LMAX Disruptor的使用：
							>生产者：调序号器cas自增值-当作占位--->调RingBuffer获取该位的LongEvent,设置生产值-->调RingBuffer发布事件(该位可读了)
							>消费者：建立Disruptor时，调用了它的handleEventsWith()方法---就提交了封装了handler的任务processor到线程池--->processor从而循环拉取RingBuffer中可读位，后调handler来处理，处理后sequece设置为读到的最后一位。
								>发布事件：tryPublishEvents()则更新了sequencer
								>发布序号：仅仅更新了设置了availableBuffer: int[] 可读的index位置也是sequence & indexMask 得来；存放的int值是：sequence>>log2(size) 的低32位--是标记；存放之后processorNotifyCondition.signalAll()唤醒读取；而如果要读的序号值>可读的序号值：就条件等待processorNotifyCondition.await()
								>处理事件：是更新了自己的sequence
								>数组里的元素逐个字节进行操作：取得偏移量：UNSAFE.arrayBaseOffset(int[].class) 和元素大小：UNSAFE.arrayIndexScale(int[].class) 和取某对象的某偏移量开始的int值：UNSAFE.getIntVolatile(availableBuffer, bufferAddress)
						>log4j2中对Disruptor的使用：processor维护自己的sequence--标记读到的位置；RingBuffer.Sequencer则维护自己的cursor来标记写到的位置；当cur<process_seq就会读线程就会等待；当不可写则写线程LockSupport.parkNanos(1)稍微停车而继续自旋。
							>从 handleEventsWith()开始；
								>Ringbuffer用序号器新建一个SequenceBarrier：被多个BatchEventProcessor共用，同时共用一个RingBuffer,内部自有新建且初始化的一个sequence，且dependentSequence=handle方法透传的Sequence(序号器未存)--->但是更新到了ringBuffer.sequencer.gatingSequences。
									>BatchEventProcessor被多线程执行起来之后：取自己内部的sequence的值并加1，传调给sequenceBarrier.waitFor(nextSequence)，等待。作为期望的sequence，当读取了下一轮可读的event后，sequence被设置为最后读取索引+1，继续waitFor()
									>SequenceBarrier的等待：转调内部策略来等待可用序号waitStrategy.waitFor()。然后调序号器来获取最大已发布序号：@sequencer.getHighestPublishedSequence()这时就会查序号器 内部 自己的 availableBuffer 设置位，比较看哪个位可读了--显然这没问题--直接读无cas。
									>BlockingWaitStrategy策略的等待：条件等待，条件为 从序号器 透传过来的cursor<期望的sequence。一旦条件被激活，则cursor值肯定变了，透传过来的dependentSequence也肯定变了---且是>=期望的sequence的值(从而从期望sequence到dependentSequence都是可读的)；
								>一个Disruptor: 内部一个RingBuffer。一次创建后的创建事件处理器，只创建一个SequenceBarrier
								>一个RingBuffer: 内部一个 新建的 MultiProducerSequencer，就是用这个序号器创建一个SequenceBarrier: sequencer.newBarrier()
								>一个MultiProducerSequencer： 内部有自建的一个序号 cursor--初始为0, 透传给 ProcessingSequenceBarrier的cursorSequence， waitStrategy也透传给它了
							>RingBuffer.publish(long sequence)都做了什么：转给序号器发布：sequencer.publish() 内部仅仅更新了 它独有的int[]availableBuffer的相应位置的值--直接更无cas；然后调用策略进行唤醒 条件等待：。
							>RingBuffer.publishEvent()都做了什么：先序号器占位： sequencer.next()，后再转换事件和发布唤醒@translateAndPublish()。很自然的，序号器占位，就是更新它的cursor增加n了，和前面阻塞等待匹配。同时因为序号器内部还有一个自己的gatingSequenceCache，也会更。
				>info()的过程：从Logger到Appender:。。先到队列，再到流，再到磁盘。
					>先转为Message格式：
						>如org.apache.logging.log4j.core.Logger 实现：转Message后转调策略来处理-->转调配置:配置类先 继续转为LogEvent--->然后就是熟悉的调用Appender来处理了org.apache.logging.log4j.core.config.LoggerConfig.processLogEvent()
						>如org.apache.logging.log4j.core.async.AsyncLogger 实现： 内部AsyncLoggerDisruptor 对象---start()中新建了com.lmax.disruptor.dsl.Disruptor对象---新建时新建了RingBuffer对象。具体过程：直接用RingBuffer来发布事件：通过sequence找到Object[] 位置，因为每个位置都初始化为了RingBufferLogEvent元素，所以直接将message设置进去即可。--->然后sequencer发布可用：在availableBuffer中标记位。
							>Event的消费：新建Disruptor时@handleEventsWith()方法即是消费线程的启动：回调handler:Log4jEventWrapperHandler , 新建的处理器BatchEventProcessor封装为EventProcessorInfo加到了consumerRepository, 在Disruptor.start()时候 executor.execute(eventprocessor)---对于BasicExecutor ：非常粗暴：直接新建Thread并启动。所以总共启动了额外的一个线程：运行起来执行BatchEventProcessor.processEvents():里面直接一个一个从RingBuffer里取，后使用回调类处理@eventHandler.onEvent() 后面就是常见的使用配置类loggerConfig.logToAsyncLoggerConfigsOnCurrentThread()处理--到调用Appender处理。RingBuffer满的时候也会直接logToAsyncLoggerConfigsOnCurrentThread()处理。
			>slfj: 
				>封装为内部事件后缓存到：LinkedBlockingQueue 
				>缓存数据的消费：o.s.LoggerFactory吸干队列元素，反射调用Logger实现类log()方法执行来消耗。
				>API:
					>org.slf4j.LoggerFactory.getLogger(name): 可能有各map的整理过程；接着：都会获取一个 工厂实例@getILoggerFactory() 然后调用工厂的.getLogger(name)方法来获取一个 new Logger 实例
						>获取工厂实例的实现：核心为org.slf4j.impl.StaticLoggerBinder 类的静态方法获取。但是这个类在多个包中都有实现：logback-classic.jar/slf4j-log4j2.jar 里都有。
							>对于logback-classic.jar里的实现：则返回 new LoggerContext 实例; 对应的getLogger()返回的是：ch.qos.logback.classic.Logger 。。工厂的静态块进行了配置读取：系统配置logback.configurationFile > 文件 > logback-test.xml > logback.groovy > logback.xml 
							>对于slf4j-log4j1.jar里的实现：则返回 new Log4jLoggerFactory 实例：对应的getLogger()返回的是：org.apache.log4j.Logger 接口的实现：Log4jLoggerAdapter <-- org.apache.log4j.spi.NOPLogger/org.apache.log4j.spi.RootLogger / org.apache.log4j.Logger 且都是通过 LogManager 获取。这个Manager:静态块就在执行：加载 系统配置log4j.configuration > 文件 log4j.xml >log4j.properties, 后具体的使用配置器吸收而初始化。
							>对于log4j-slf4j-impl-2.jar里的实现：则返回 Log4jLoggerFactory 实例：对应getLogger()返回的是：org.apache.logging.slf4j.Log4jLogger 可能 产生：SimpleLoggerContext/LoggerContext/SLF4JLoggerContext
							>选择哪个包里的实现：随机的。因为是有可能在classpath上find url时候发现这个类的多个url,那么直接 StaticLoggerBinder.getSingleton() 方式让虚拟机自己选择找哪个包里的实现。
						>SubstituteLoggerFactory.getLogger(): 是新增：name -- SubstituteLogger() 实例 这样的k-v 到内部的logers:map里
			>spring-jcl: spring-boot内部代码使用的日志接口
				>日志接口：
					>原生接口：log4j,slf4j
					>统一接口：Log/o.a.c.l.LogFactory
					>适配类：SLf4jLog/Log4jLog/JavaUtilLog；对应适配的原生接口：Logger/ExtendedLogger/java.util.logging.Logger。对应适配器：Slf4jAdapter/Log4jAdapter。
					>统一适配器：LogAdapter
						>决定使用哪个适配器/适配类： 依次看各个具体log类是否可以加载：log4j_slf4j桥接 > log4j直接 > slf4j spi实现类 > slf4j api实现类 >java.util.logging.Logger
	>应用问题处理：
		>用户授权/用户认证问题：
			>授权： 给合法主体授予相关资源的访问权限(允许访问/拒绝访问 xxx资源)。(使用第三方认证)
				>Oauth: 认证用户身份-->颁发token
					>请求授权码(先查看权限再决定是否返回)-->请求token(同时code失效)(token不携带用户信息)-->带上token请求资源
						>资源服务器：根据token查认证服务器得到userid,后执行请求；
						>认证服务器：token-userid的映射查找服务提供；			
				--授权之后访问资源：带上access_token		
			>认证：	确认用户是否为系统中合法主体(非合法主体直接当作游客)(提供用户名+密码)(返回token)。
				>JWT:
					>特殊格式的Token: base64(header.payload.signature)  其中， signature=f(payload),payload=base64(json) header=xxx_RSA之类(签名算法--只有服务器知道私钥)；从而token既有效又绑定用户；payload有时称为claims
					>资源服务器：独立完成签名的验证。payload中有用户信息；
					>认证服务器：颁发jwt格式的token;
				--认证之后访问资源：带上token 
		>mysql主从同步问题：更少延迟、更快恢复；
		>缓存问题：4类
			>缓存穿透：
				>产生原因/条件：数据库不存在的key不会被缓存；
				>导致的结果：每次查数据库，压力大；
				>理想的方案特征/效果/必做必不做的动作&事情/应当改变的环节：不查数据库；
					>特征所导致的必然可以确定的事情/结论：主键集合存到缓存；用键查这个主键集合判断是否在这个集合：
						>一系列结论、约束得到之后(结合条件/问题/情况本身)逐渐可以清晰看到/归结出该具体问题符合的/满足的通用/一般的/一类的问题模型/函数模型/服务模型/IO模型/请求响应模型的轮廓：若干个具体模型；如 bitmap;bloom filter
							>方案的装饰/补充: 补充可靠性/稳定性/高性能(从而高可用/高并发)：因为暂时只是一个裸机、容易受到伤害、有功能但没有抵抗力(仅为打火机的火而不是熊熊大火)
							>方案的用法规则：在请求缓存前使用；使用前加主键范围判断
				>能将具体方案进行分类的维度/情况/模型/环节/流程/抽象表述 的确定：然后使用 抽象-具体 的方法来得到新方案；			
			>缓存雪崩：
				>产生原因：大量key同时过期删除：redis崩溃；
				>导致后果：尽管请求相同key是被同步了(缓存击穿方案)，但是同时来的不同key太多，给数据库的压力依然大；
				>理想方案特征/效果/目标：实际并发查询少
					>必然要求：留住一部分请求；
						>归结出一般的问题模型：限流+降级；(限流的实现可以排队部分和抛弃部分)(漏桶算法：限制最高)(Semphere限制并发同时)
							>方案的补充：可靠性补充：避免redis崩溃(主从+哨兵)(持久化)；稳定性补充：避免同时过期(随机缓存时间(区分大些))；
							>方案的使用：请求缓存前就限流；请求数据库前也限流；
			>缓存击穿：
				>产生原因：热点key缓存到期删除；
				>导致后果：大量查该key的在数据库中的记录，压力大； 
				>理想方案特征：要查数据库，但只一个查，放到缓存，后续查缓存；
					>必要要求/可以确定的事情：在不同节点上的同key请求也要同步：
						>归结出一类问题模型：分布式锁 
							>方案的补充：可靠性：setnx +expire 即带超时时间的尝试获取锁；del k if get(k)=v 即带值的先查值比较后删除的脚本(避免超时后删除了别的请求设置的); 获取失败的则自旋至超时
							>方案的用法： 请求缓存后，查数据库的框架；
				>区分具体方案的维度/模型/流程： 
					>完全不查数据库：缓存不过期+同步更新；(依然有redis不可用时未应对的问题)
		>CMS GC问题：CMS+ParNew组合.延迟-吞吐量-容量 的权衡； 小堆 CMS, 大堆G1(>2G<64G)、超大堆ZGC
			--问题引起的表象：RT上涨、GC耗时增大、线程block增多、慢查询增多、CPU负载高；
			--TLAB: Eden中的一块内存；每个TLAB都是线程独享的；
			--Java8内存结构：栈：虚拟机栈、本地方法调用栈、程序计数器； 堆：Young:Eden+TLAB+s0/s1 ,Old:Tenured+Humongous(超过分区大小50%的对象), 运行时常量池:符号引用+字面量；非堆区：MetaSpace: 压缩类空间+编译代码+域和方法数据； 本地内存：JNI的+Direct的+Stack的； 代码缓存：JIT 代码和编译
			--分配和收集对象：对象地址操作：Unsafe#allocate/free
				>收集算法：标记-清除：时间开销-和存活对象数正相关； 标记-整理：开销-和存活对象数+对象大小都相关；复制算法：开销-只和存活对象大小相关(可达可视)
				>收集器：G1-吞吐量为目标-多核大内存-分区后分代；CMS-一次最大暂停时间-可用性为目标--分代后分区；ZGC-低延迟-大内存
				>指标：延迟：单次停顿时间；吞吐量：总的停顿时间占比；
				>调优条件：GC吞吐量>=99.99%, 即如果单次延迟平均30ms，则300s才进行一次GC，即5min一次；满足不了就要调优；第二：最大GC时间<TP9999 否则也要调优；
				>在线平台：gceasy\heaphero\fastthread 也是GC日志分析工具
					>GC Cause: 分配失败、并发模式失败(old预留空间不足,收集器退化)、FullGC分配失败、晋升失败(old空间不够装young)、GCLocker InitiatedGC(JNI临界区执行时阻塞其他线程也阻塞GC线程)
				>对象存活时间和应用类型关系：IO交互型：RPC之类，存活时间短；Young区大些；   MEM计算型：存活时间长--Old区大些；	
			>动态扩容引起的空间震荡：-Xmx 和-Xms设置不一致，导致动态的扩容和缩容----从而导致触发CMS GC(其他：达到阈值、大对象担保失败、晋升失败、MetaSpace空间不足、手动System.gc);
				>显式GC: 导致FullGC,STW 。但也可以触发GC来保证DirectByteBuffer的清理工作可以及时完成；
			>显式GC的去与留：
			>MetaSpace区OOM：常量池等字面量、类静态变量、符号引用 都移到了Heap, 1.8后PermGen也没有了，只有MetaSpace;
				>jvm向os申请内存：mmap接口 实现；每次2MB,加到链表中；
				>Klass MetaSpace + NoKlass MetaSpace: Class文件的类解析后的数据结构存放的位置 + 常量池/Method
				>查看哪个包下加载的Class更多：jcmd pid GC.class_stats|awk '{print$13}'|sed 's/\(.*\)\.\(.*\)/\1/g'|sort |uniq -c|sort -nrk1 
					>查看类加载详细信息：-XX:+TraceClassLoading -XX:+TraceClassUnloading
			>过早晋升：最大晋升年龄：-XX:MaxTenuringThreshold
				>原因：Young/Eden区过小；Old区大小不一定要很大；Old区大小=活跃对象/FullGC后存活的对象的3倍作有即可；新生代>old区大小也可以；2倍都行；
			>CMS Old GC频繁：吞吐量下降多；
				>启动原因：1.阈值判断：默认92%；2.Young GC失败过；-XX:CMSClassUnloadingEnabled 3.System.gc  
			>单次CMS Full GC 耗时长：单次STW>1s
				>init mark: GC roots开始的标记
				>Final Remark: Card Table的遍历、Reference实例的清理并加入到Reference维护的pend_list;  收集元数据信息：class unloading, 清理 SystemDictionary\CodeCache\SymbolTable\StringTable
					>调节参数：-XX:+PrintReferenceGC 可以在日志清晰展示CMS Final Remark 阶段：1. ParNew 标记的 软引用、弱引用、Final Reference、虚引用、JNI虚引用 分别有多少 2. class unloading 、symbol table(符号引用)、string table 的清理耗时
						>调参2：-XX:+ParallelRefProcEnabled 对Reference进行并行处理
						>调参3：cms-remark阶段 类卸载，jdk8默认开启了：-XX:-CMSClassUnloadingEnabled  。。减少耗时，可以关闭；
					>内存分析工具：MAT, JProfiler
						>FinalReference 的分析：看 eclipse的MAT 的 dominator tree; 加-XX:+HeapDumpOnOutOfMemoryError 就是看对象数量：java.lang.ref.Finalizer会很多；
							>实现了Object.finalize()方法的实例：会被创建一个Finalizer实例--看门狗--引用前面用户对象，且被Finalizer类引用-->新生代Eden回收无法清空看门狗-->新生代GC完成后才将对象放入内部的ReferenceQueue-->Finalizer守护线程弹出队列中元素，执行finalize()方法，同时Finalizer类不再引用这个对象；--->下一轮新生代Eden回收就可以回收了。但是Finalizer守护线程优先级低，回收慢，保留多，从而java.lang.OutOfMemoryError: GC overhead limit exceeded
			>内存碎片和收集器退化：退化后STW时间可能十几秒
				>单线程串行STW： 标记-清理-压缩 
				>退化原因：
					>晋升失败：Survivor放不下，Old也放不下；
						>原因1：短时间Old快速填满---晋升太早；
						>原因2；内存碎片--大对象没有足够连续空间
					>并发模式失败：Concurrent Mode Failure , Old回收阈值太高，在回收结束前，预留的内存空间不够存不断产生的浮动垃圾	
				>调参：优化
					>-XX: UseCMSCompactAtFullCollection=true 开启 FullGC后空间整理；
					>-XX: CMSFulGCsBeforeCompaction=n 控制多少次普通FullGC后进行一次带压缩的FullGC  ，可以实现通过 -XX:PrintFLSStatistics 来观察内存碎片率
					>-XX: CMSInitailingOccupancyFraction 让 CMS GC尽早执行，比例降低；同时配置：-XX:+UseCMSInitialingOccupancyOnly
					>-XX: +CMSScavengeBeforeRemark 提前触发一次Young GC, 防止后续晋升太多对象；
			>堆外内存OOM：top 命令查看 java进程的res 和 -Xmx比较；
				>原因：Unsafe#allocateMemory,  ByteBuffer#allocateDirect, 或者用JNI调用native code申请的内存没有释放；
				>分析工具：NMT 
					>项目启动：添加-XX:NativeMemoryTracking=detail , 使用命令 jcmd pid VM.native_memory detail 查看内存分布(堆内内存、Code区域、Unsafe/DirectBuffer申请的内存;不含Native Code申请的)
				>调参：优化 
					>控制最大堆外内存申请值：-XX:MaxDirectMemorySize=size jdk8中默认和-Xmx一样；
					>检测堆外内存是否释放：-XX:+DisableExplicitGC 去掉；
				>分析工具2：Google perftools(malloc时接替) + Btrace 分析 JNI调用的Native Code 申请的内存未释放 
					>Btrace: java 追踪、监控工具。直接打印出调用栈(而不是看日志里的调用栈)
			>JNI引发的GC问题：GC Cause=GCLocker
				>添加：-XX:+PrintJNIGCStalls 可以打印出发生JNI调用时的线程；
				>JDK升级到14： 避免重复GC: JDK-80488556
			--参数加入：
				>-XX:+HeapDumpOnOutOfMemoryError 
				>基本参数：-XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:PrintGCTimeStamps 
				>时间相关：-XX:+PrintGCApplicationConcurrentTime -XX:+PrintGCApplicationStoppedTime 如STW时间
				>年龄相关：-XX:+PrintTenuringDistribution
				>空间变化：-XX:+PrintHeapAtGC
				>引用相关：-XX:+PrintReferenceGC
			--一般指引：
				>禁用偏向锁：并发激烈时，偏向锁升级到轻量级锁，消除偏向锁时需要STW,开销大；所以 -XX-UseBiasedLocking
				>真正分配物理内存：-XX:+AlwaysPreTouch
		>JVM调优问题：分配、迁移对象、GC
			>Minor GC的直接原因： 
				>分配时-Eden区没有足够空间进行分配：进行MinorGC;(后进行分配，大对象则直接分配到老年代)
					>Minor GC进行中：最后迁移对象时，如果S1不足，则转移到Old区；如果对象年龄超域则转移到Old区；
					--注：动态年龄计算：遍历对象时：新生代对象按年龄分组排序，超过一半的对象都小于的那个年龄 就设置为 下一次 晋升年龄阈值；
					--注：根搜索只在MinorGC,CMS是老代全堆扫描+扫卡表对应的新代。为降低CMS单次停顿时间(和让gctime和业务波动保持一致-无明显毛刺)：remark前MinorGC一次--开启 CMSScavengeBeforeRemark + CMSMaxAbortablePrecleanTime(等待MinorGC触发的时间--超时不再等)
				>Full GC过程中：标记阶段，如preclean?
				>JVM执行到标记为安全点的指令时：进行一次GC信号检测(JVM根据内存占用发出的)，检测到了则停止所在线程而进行GC；
					>安全点：入循环结束处等产生对象少的地方；
				>线程在阻塞结束时：检测JVM是否在GC中，是就等待GC完成。线程进入阻塞，即进入安全区域，会标记安全；
					>注：JVM会检测各个线程的安全状态，都安全了才进行GC.
			>Full GC的直接原因：(不是Full GC频繁的原因)
				>Old区有关：
					>老区使用率达到阈值：(已经存放)
						>形成的可能原因：
							>转移到老区的对象的累积：
								>检测方法：gc日志+堆区查看命令如jmap
									>积累直接可能原因：一个请求里业务产生了大量对象/查询数据库产生的结果-对象大/被老区对象持有；
					>MetaSpace使用率太高：已经没有新空间分配给新的元数据。		
				>Young区转移过来有关：(还未存放到old区)
					>老区连续可用空间不足存储转移过来的对象：尽管使用率还没达到阈值；仅因为内存碎片太多。
					>老区剩余空间不足存储转移过来的对象：尽管使用率没达到阈值，且也没内存碎片；仅因为转移过来的太多。
				>Minor GC前触发：
					>判断老区最大可用连续空间大小是否大于新生代所有对象总空间：
						>是：则MinorGC安全；进行MinorGC
						>否：进行空间分配担保：退一步判断 老区最大可用连续空间大小是否大于历次晋升到老年代的对象的平均大小：
							>是： 则进行MinorGC
							>否： 先进行一次FullGC，(再MinorGC)
				>显示GC：System.gc()
			>从GC日志统计查看某JVM实际GC原因：gceasy工具。java9开始G1为默认。
				>
			>从Hotspot源码gcCause.cpp看所有可能GC原因：28 case。其他补充看gceasy具体报告。
				>System.gc(): Runtime.getRuntime().gc()都可能/自项目/3rd lib/rmi/jmx。手动消除。(框架-继承;lib-引用)显示gc并发进行：-XX:+ExplicitGCInvokesConcurrent。如果用了rmi:则-Dsun.rmi.dgc.server.gcInterval=n来控制System.gc()周期--默认60min。
				>alot类：FullGCAlot/ScavengeAlot/
				>profiler类：Allocation Profiler
				>jvmTI有关: jvmtiEnv ForceGC
				>gc locker： GCLocker Initiated GC 
				>heap 监视：heap inspection Initiated GC 
				>heap dump: heap dump Initiated GC 
					>原因：从应用dump堆的命令执行前触发full gc: 如jcmd/jmap/profilers。因此没有绝对必要，不要执行这些命令。
				>白盒相关：whitebox Initiated YoungGC/Concurrent Mark/Full GC 
				>没有或未知：no gc/unknown GCCause
				>分配失败：allocation failure
					>原因：1.应用创建了太多无法快速回收的对象。2.堆区碎片太多导致直接分配到old区失败。
					>解法：1.-XX:ConcGCThreads增大让垃圾回收更快。2.-XX:InitiatingHeapOccupancyPercent调小而更早进入标记阶段而可能避免FullGC。3.因连续空间不足但有大对象要分配而触发FullGC,通过增大region大小：XX:G1HeapRegionSize 来降低因为大对象导致的空间浪费。
				>Tenured区满：Tenured Generation Full 
				>元数据有关：Metadata GC Threshold/Clear Soft References
					>原因： 1.元数据空间太小；2.类加载器泄漏(可能小)
					>解法： 1.增大元空间-XX:MetaspaceSize
				>CMS直接有关：CMS Generation Full;CMS Intial Mark/Final Remark/Concurrent Mark 
				>Old Generation有关：Old Generation Expanded On Last Scavenge/Too Full To Scanvenge
				>可适应大小政策：Ergonomics
				>G1直接有关：G1 Evacuation Pause/Humongous Allocation  
					>原因：疏散暂停--因为old空间不足存晋升的s1/eden对象； 
					>解法： 1.-XX:G1ReservePercent增大可以更早GC避免疏散时才GC 2.-XX:InitiatingHeapOccupancyPercent调小来更早进标记阶段。3.-XX:ConcGCThreads增大来垃圾回收更快。4.增大-Xmx堆区增大
					>解法2：对于Humongouse Allocation: 因为对象大小>1/2*region_size就会独占region，造成内存碎片，所以增大region:-XX:G1HeapRegionSize来避免放到H region.
				>对话命令触发run：Diagnostic Commend
				>上次gc造成：ILLEGAL VALUE - last gc cause
			>OOM的类型和直接原因：(Full GC可能造成OOM)
				>Java heap space: 
					>原因：1.对象无法在堆区分配。2.应用无意hold住对象导致无法被回收。3.	使用了fininalize()方法。
					>解法：1.增大堆区-Xmx. 2.修复内存泄漏。
				>GC overhead limit exceeded: 垃圾回收耗时占比超过98% 但只回收了不到2%的空闲堆区。
					>解法：1.增大-Xmx堆区。2.禁用-XX:-UseGCOverheadLimit 。3.修复内存泄漏。
				>Requested array size exceeds VM limit: 申请分配的数组大小超过了堆区大小。
				>Permgen space: Permgen区耗尽越界。
					>解法：1.增大Permgen:XX:MaxPermSize . 2.重启应用而不是重新部署。
				>Metaspace: java8开始的本地内存区域，存类元数据，耗尽则抛出这个错误类型。
					>解法：1.增大元数据空间 -XX:MaxMetaSpaceSize。 2.减少堆大小。3.增大服务器的内存。4.修复可能由应用造成的这样的结果。
				>Unable to create new native thread: 没有内存去创建新线程；本地内存空间不足。
					>解法：1.给机器更多内存；2.减少java 堆大小。3.修复可能的线程泄漏。4.增大用户最大进程数限制：ulimit -a 。5.减少线程栈大小-Xss
				>Kill process or sacrifice child: 在极端低内存条件下，OS核心任务-OOM Killer会杀掉进程；
					>解法：1.迁移进程。2.增大内存。
				>stack_trace_with_native_method: 本地方法遇到了分配失败。(另：在顶帧为native时打印栈trace)
					>解法：1. Use OS native utilities to diagnose
			>CPU高的原因：
				>不安全的Full GC: 高CPU消耗--造成响应时间恶化--SLAs就受影响。FullGC越少越好。检测：gceasy
					>表现：某个时刻进行了很多次FullGC,但回收的byte很少。
					>原因：空间太少，要分配的太多。如尖峰流量到来时。
					>解法：增大heap.-Xmx3G .2.增大元数据空间。3.扩节点。
				-减少GC Pause: 1.增大年轻代大小-Xmn减少晋升数-减少耗时的FullGC 2.使用G1自动调参。3.增大内存避免磁盘交换。--查看每个进程的交换率--专门脚本。	4.考虑增加Gc thread count.来降低Times: real time。注意：user:cpu花在用户代码的时间,sys:cpu花在系统代码的时间;real: 阻塞时间+本线程所有代码执行时间。--查看io阻塞活动：sar -d -p 1  5.堆不要太大，8G/6G足够,18G太大了--尽管FullGC频率降低但每次更耗时--太多需要回收。6.cms时的优化：-XX:+CMSScavengeBeforeRemark  让gc任务在多个线程间更工作平衡。
				-提高吞吐量：即降低gc时间占比。
					>降低原因：1.暂停长。2.内存泄漏(继续造成频繁的FullGC)。3.不安全的FullGC.4.应用等待CPU/IO
					>
			>MEM高的原因：
				>内存泄漏： 
					>处理措施：
						>启动应用：10min后捕获heap dump--内存快照；jmap -dump:format=b,file=<file-path><pid>。。启动：需要带参启动：-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=<file-path>。。其他导heap dump方法：jcmd <pid> GC.heap_dump <file-path>
						>比较前后两次heap dump: 增长的那部分objects就可以认为是造成内存泄漏的部分(占用内存的不能被回收的垃圾)。HeapHero.io为分析查看heap dump的工具。
						--JvituralVM/JMX/Jconsole/也可以捕获到heap dump。在应用中也可以：com.sun.management:type=HotSpotDiagnostic MBean 捕获到。
					>处理措施2：
						>诊断工具：gceasy 在线gc日志分析/Eclipse MAT堆heap dump分析工具
							>验证是否内存泄漏：1.grep日志看是否有OOM 2.上传gclog到gceasy,看分析结果是否内存泄漏
						>找到具体的泄漏对象：1.健康时候的heap dump 。2.问题时候的heap dump (cpu出现尖刺/应用无响应/OOM) 3.heap dump传给mat,后找到最多的5个对象；前后对比，如果有对象明显增长了，则它们就是泄漏的对象；
						>找到泄漏对象对应的代码：1.mat工具找出引用了这些泄漏对象的对象，由这些引用判断是哪处代码产生的。
				>不安全的Full GC:		
			>DISK IO高的原因：虚拟内存交换/日志刷入；
			>需要GC优化的标志：1.单次停顿时间超过了TP9999(低延迟) ; 2.GC吞吐量小于了99.99%
				>TP9999: 百分之99.99的调用用时。
				>GC的吞吐量：单位时间内的非GC时间占比。因为GC而导致的吞吐量从100%降低到的那个值。即：1 - 一次GC平均占用的时间/触发GC的平均周期。例如：平均30ms,5min一次，则GC吞吐量降低了0.01%为100%
					>gc.meantime: 或者jstat可以查看平均MinorGC耗时：而从jconsole的堆内存使用变化曲线可以得知MinorGC周期：。例如观察到eclipse某回：15ms/1min,则吞吐量99.975%
			>G1最优配置：
				>-XX:MaxGCPauseMillis: 设置后，-XX:NewRadio,-Xmn不能设置。其他CMS/Parrallel配置也不要；
				>-XX:+UseStringDeduplication: 对spring-boot项目可以考虑：1.8 update20之后，来减少堆中重复字符串；
				>可以考虑调整的：1.region大小：-XX:G1HeapRegionSize=n 2.GC用时比例分配：-XX:GCTimeRatio=12即7.69%
				>-XX:ParallelGCThreads=n: STW阶段并行的线程数-如垃圾回收线程。核数<=8则同核数，否则5/8*核数 
				>-XX:ConcGCThreads=n: 并发标记线程数--和用户线程一起运行的。1/4*并行线程数
				>可以考虑调整：3.-XX:InitiatingHeapOccupancyPercent=45 触发 marking cycles 的堆使用率
				>年轻代有关：1.-XX:G1NewSizePercent=5 年轻代占堆区的比例的最小值 2.-XX:G1MaxNewSizePercent=60 年轻代使用率的最大值
				>老区有关：1.-XX:G1OldCSetRegionThresholdPercent=10 在mixed garbage collection cycle阶段回收老区regions数的比率(占堆区大小)。(即默认回收垃圾最多的不超过10%的region)
				>空闲的堆空间的保持比率：-XX:G1ReservePercent=10
				>不推荐使用的：-XX:+UseGCLogFileRotation不好。XX:+UseCompressedOops 不需要设置。
			>G1 GC监控：原因分析。(三大问题：内存泄漏、GC问题、OOM)
				>jvm启动参数配置：java8 为 -XX:+PrintGCDetails -XX:+PrintGCDateStamps -Xloggc:{file-path}  java9为：-Xlog:gc*:file={file-path}  file-path就是gc日志写入位置。
				>使用gceasy分析gclog文件：对每次gc分类汇总，得出每类gc的回收次数、回收平均耗时/最大耗时/总耗时，总耗时占全类的比例。
					>gceasy报告：1.全类原因-每类的优化措施；2.吞吐量、延迟、耗时长分布。3.各gc阶段次数和耗时统计。4.字节创建总量/字节晋升总量/字节创建速率/字节晋升速率.5.内存泄漏(8类) 6.Tenured区对象年龄分组统计。7.jvm参数如：-XX:GCLogFileSize=2048000 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/scratch/oracle/product/wls_1221/user_projects/domains/orb_domain/info/heaps -XX:InitialHeapSize=1073741824 -XX:+ManagementServer -XX:MaxHeapSize=6442450944 -XX:NumberOfGCLogFiles=10 -XX:+ParallelRefProcEnabled -XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintTenuringDistribution -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseG1GC -XX:-UseGCLogFileRotation
						>
	>源码：
		>java:
			>ConcurrentHashMap: 数据结构+算法 
			>ThreadPoolExecutor: 数据结构+算法 
			>AbstractQueueSynchronizer: 数据结构+算法 
			>ReentryLock:
			>ArrayBlockingQueue:
			>LinkedHashMap:
			>Selector:
		>spring: 各个过程
			>刷新的过程：
			>事务开启到提交/回滚的过程：
				>事务传播级别：
					>已有事务时：
						>需要新事务：REQUERED_NEW(有则悬挂-新建事务)/NESTED(父事务建立回滚点-建立子事务)(子事务回滚-父事务回滚到保存点)(父事务回滚-子事务也回滚了-因为子事务还没提交)
						>利用当前事务：REQUERED/SUPPORT/MANDATORY
						>不需要当前事务：NOT_SUPPORT(有则悬挂)/NEVER(有则抛异常)
					>没有事务时：
						>必须要先有事务：MANDATORY(没有就抛出异常)
						>新建事务：REQUERED_NEW/NESTED/REQURED
						>就没有事务：SUPPORT/NEVER
		>spring-boot:各个过程 
			>启动的过程：
		>dubbo: 各个过程 
			>发送的过程：
			>接收的过程：
		>netty:
			>发送的过程：
		>sharding-jdbc:
			>分库分表流程：sql重写+数据源的确定
			>主备切换流程：sql重写+数据源的确定
		>mybatis:
			>从DAO开始的执行过程：
		>jdbc:
		>tomcat:
		>rocketmq:
	>架构：
		>领域驱动设计：
			>目的：发现业务问题(逻辑问题/缺陷/漏洞)，发现新业务。
			>设计过程|确定过程：确定领域对象(属性和服务)--->
				>领域对象：对象服务：
					>对象属性：跟所处哪个系统无关的，固有的必不可少的属性；对象信息；区分不同对象实例的维度；
					>对象服务：服务需要被调用/被使用(被其他对象/被cpu)。服务使用过程中可能需要留下记录、发出事件；(表明服务的进展)。可被执行的操作。1.改变属性的服务；2.消耗属性的服务；3.处理输入的服务；4.输出数据的服务；
				>概念结构：共享的概念层次 
					>类继承关系：继承、实现
					>类依赖方式：参数注入依赖、属性添加依赖、向中心代理发事件--(完全解耦)
				>综合服务：使用多个对象的服务来产生整体服务；	
					>服务描述：精确用词用度量来描述我们到底提供了一个怎样的服务；---->然后对其中的具体的词进行抽象--->层层抽象，得到更加广泛的服务、更一般的服务---->再具体化，得到全新的服务；。。。这种思考活动要多多进行(当前有的服务 当作验证) (这才是真正的商业思考)
						>尝试发现业务问题：就要梳理完整的业务逻辑;业务发展逻辑；服务逻辑;服务发展逻辑。(这才是真正的商业思考, 且是我的独特优势)(规划和执行)
							>梳理发展的业务逻辑：业务发展逻辑、业务规划逻辑；。能发展起来、发展壮大的业务逻辑；
							>梳理衰落的业务逻辑：肯定发展慢、且最终发展不起来、最终会失败的发展逻辑；不稳定的发展逻辑；不可靠的发展逻辑；性能不高的发展逻辑；不安全的发展逻辑；不便于扩展的发展逻辑；并行请求处理不过来的发展逻辑
								>具体发展过程及其抽象：(也是发现有前途的公司的方法)(自定向下，由抽象到具体)
									>所有环节的确定：每个环节不可再分
									>所有环节的选择: 每个环节具体做了什么事、怎么选择的、选择了什么；

>参考资料：
1.G1：https://blog.gceasy.io/2020/06/02/simple-effective-g1-gc-tuning-tips/#more-4051							
2.OOM：https://tier1app.files.wordpress.com/2014/12/outofmemoryerror2.pdf		
3.内存泄漏：https://blog.heaphero.io/2018/03/27/how-to-diagnose-memory-leaks/
4.内存交换：https://gceasy.io/gc-recommendations/long-pause-solution.jsp
5.暂停时间减少：https://gceasy.io/gc-recommendations/long-pause-solution.jsp
6.吞吐量提高：https://gceasy.io/gc-recommendations/through-solution.jsp
7.内存泄漏的处理：https://gceasy.io/gc-recommendations/memory-leak-solution.jsp
8.问题复现jar:https://blog.gceasy.io/2020/10/23/buggy-app-simulate-performance-problems/#more-4247
9.cpu耗时分析：https://www.linuxtechi.com/generate-cpu-memory-io-report-sar-command/
10.美团技术：https://tech.meituan.com/2017/12/29/jvm-optimize.html
11.时间管理能力-桥水基金创始人雷·达里奥的《原则》