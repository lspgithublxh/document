---------读书战略：自顶向下，从应用层到底层细节。先熟悉的常用的，后底层的不常用的。精读好书---《深入理解系列》
--------es的处理思想都对应有 相应的“某种举动 及其导致 的问题”
>需求背景-痛点陈述：现实开发中遇到了什么痛点导致XXX的开发？  
>那么痛点的原因、产生的条件：分析是什么环境、什么动作 什么效果什么目的 等精准形容词的事实描述 导致了痛点的必然发生，难以避免？。条件-痛点。原因-结果。
>则可以消除痛点的最简单的精准事实陈述是什么：修改“条件-痛点”陈述的哪一部分就可以导致没有痛点产生。 要做的根本事情是什么：
>那么新陈述表明的解决动作是什么：
>新情况的新痛点是什么：新举动、新环境会产生的新痛点描述出来， 继续上述4条操作。
>学习要有战略和格局：过于零散、孤立、末支、叶子的知识点就没必要化太多时间，懂得放弃。聚焦在根节点、枢纽节点、产生分支的节点、主干知识点、枢纽知识点、关联到很多知识点的知识点上。
 >对于主干知识点：要有全新的认识视角和进行精细的描述，大量的提问和好奇和进行必要的实验以获取支撑观点/导出观点的数据。
 >规范是工程最独特的特征.
 >慢慢读：
>一种新技术的学习：
 >它面对的情况和问题、它的世界观、它的方案、它的方案验证/论证/能处理的解决的所有情况及能成功处理的理由/功能边界
  >所有的软件：都可以看作是向上封装一层接口，根据自己的世界观封装底层而向上/对外提供统一的(统一的更简单的更直观的更业务的更少底层信息的)接口，底层包含一系列的第三方的插件/构件/组件；内部则去做兼容和调用(对底层)(对上层则做逻辑分解和底层实现)。

>旧观点：
  >web对外提供一个整体的服务，而这个整体的服务可以拆分为多个不相关的独立的服务：独立的服务如果其中某个想增加修改内部功能，那么web整体服务都要重新编译打包部署，影响线上环境。
  >解法/处理思想：不相关的独立服务 独立出去专门部署，而主服务只需要rpc调用这些服务即可。
  >实现中的问题：性能的保证--用socket通信。
  >带来的新问题：子服务不可用，主服务需要超时判断、服务降级。服务方需要有对调用方的限速。甚至，有服务的切换：如果A1服务不可用了，那么尝试调用A2服务--但是如果数据协议不同，开发量就还要增加。

>举动-痛点：为什么要微服务？一层一层往上就是为什么要解耦？为什么要隔离？为什么功能要扩展？为什么要多层架构？为什么要频繁迭代和频繁部署？为什么要业务拓展而几乎不需要开发太多新代码？为什么要监控？为什么要高并发、高可用、要可靠可用？为什么要更高效的维护服务？。另一个角度直接来看，就是客观本身存在的功能分解以及之间的独立和依赖---天然特征决定---微服务只是顺势而为的处理措施(就像为什么器官为什么不长在一起而是分开通过血液神经内环境来互相联系)。缺点就两个：分布式带来的：响应时间慢了一些，问题排查更复杂了。
            >采用微服务架构的时机，就是服务的子服务越来越多越来越庞大，并发量越来越高，业务扩展越来越快，子服务并行迭代的并行度越来越高，导致如果继续采用子服务一同开发、测试、发版，一方面影响进度，第二因为某个局部子服务出问题而导致系统整体都服务不可用的风险发生的概率更大，新业务的公共，独立维护独立部署带来的好处
		    >采用时的三个特征：这个项目用4个开发都已经开发维护不过来了，子服务的数量超过30个(业务区分越来越大，越来越不希望一个服务造成的异常影响到系统虚拟机而导致其他所有服务都异常)，各个子服务的并发量越来越高但请求都压在这个项目上(高并发仅仅通过粗暴的加机器，部署越多每次迭代版本升级部署机器就越多、暂停的服务就越多；服务经常震动)	(另一方面，对数据库的连接也越来越吃紧开始排队，对其他资源如内存、cpu、磁盘也是)(所有货物不放到一条船上，当然首先货物要足够多)。日志混合也是一个问题。
			>采用后本身带来的新问题和配套方案：如何访问其他服务(服务在哪里，怎么调用)？访问不到怎么办?本身不可用其他服务怎么办？访问量太大怎么办？服务调用关系调用情况错综复杂如何治理和监控？
			 >API网关：应用前端访问的问题
			 >注册中心：服务的管理。Eureka,Consul,etcd,zk
			 >网关层的反向代理：网关层的反向代理。
			 >事务补偿机制：分布式事务的一致性问题。
			>实施微服务需要具备的条件：计算和存储资源是否能快速分配？能否快速部署？基本的监控：CPU,IO,mem? 标准化的RPC
  >解法/处理思想：解耦、公共通用调用、
   >微服务架构：组件
    >服务注册：服务管理接口--注册注销，和服务查询接口--可用服务的实例。
	>服务发现：从注册中心发现服务的地址，客户端发现或者服务端发现。
	>负载均衡：调用方连接到合适的服务节点：服务端负载均衡和客户端负载均衡。
	>服务网关：服务调用唯一入口。用户鉴权、动态路由、灰度发布、A/B测试、负载限流。一个或者多个。
	>配置中心：开发、测试、生产环境中配置信息的获取。
	>API管理：接口文档管理。
	>集成框架：各组件的统一操作界面。
	>分布式事务：TCC.高可用消息服务、最大努力通知。
	>调用链：记录完成一个业务逻辑时的串行/并行的微服务调用关系。
	>支撑平台：系统的部署、运维、监控。持续集成、蓝绿发布、健康检查、性能健康。如Docker
	
   >Spring的目的：自身创建容器，将各种对外接口都统一化并提供相应的接口包, 将工具类型的开发包/框架统一化并以接口包形式提供。无论连接数据库的接口，还是任务管理器接口。
   >Spring I/O platform: maven引入spring jar时工作。
   >Spring boot: 开发和运行阶段的自动化(代劳)：自动引入项目常见依赖并根据配置文件自动装配相应对象，可以自动装配项目下的各个类对象，一起封装到Spring容器，可以自动依赖内嵌web容器jar,而将项目的Spring容器部署上去，开发者仅仅需要main函数执行启动代码即可，即可开启整个装配并部署到web容器并启动web容器。
    >是一套快速配置脚手架。  单个微服务开发。
   >Spring Framework: 基础spring框架, 如AOP和DI的实现和容器的实现。
   >Spring Cloud: 微服务工具包。提供配置管理、服务发现、断路器、智能路由、微代理、控制总线。
    >是一套全局的服务治理工具包/框架。
   >Spring XD: 一种运行时环境。采集大数据并处理。
   >Spring Data: 一种访问各种数据库的通用接口包：
   >Spring Batch: 批处理框架。批量任务执行管理器。任务调度、日志记录。
   >Spring Security: 声明式的安全访问控制解决方案。
   >Spring Integration: 编程框架，面向企业应用集成。
   >Spring shell: 开发命令。
   >Spring Roo: 使用命令行操作来生成自动化项目。
   >Spring loaded:实现java程序和web应用的热部署开源工具。
  >微服务架构设计模式：
   >聚合器微服务设计模式：聚合其他微服务，而自己前端一个负载均衡。
   >代理微服务设计模式：几乎没有业务逻辑，仅仅根据需求代理给多个不同的其他微服务。
   >链式微服务设计模式：本身有cache和数据库，同时进行同步调用其他微服务，其他微服务也同步调用其他微服务。
   >数据共享微服务设计模式：有的几个微服务共享缓存。
   >异步消息传递微服务设计模式：通过消息异步调用。通过消息传递条件，通过消息传递结果。
   (没有缓存和数据库的微服务要么就简单的是聚合服务，要么就缩减为计算工具)
   
  >微服务设计原则：
   >领域驱动设计DDD: 从代码结构中可以理解业务的设计。约定优于配置。从业务设计到代码实现的一致性。
    >领域模型：实体、值对象、集合、服务。
	>将领域元素转换为服务：值元素表示参数和返回值，集合和实体转换成独立的微服务。将领域服务匹配到独立的微服务。每个微服务处理一个完整的业务功能。
     >失血模型：基于数据库的领域设计方式。
	 >贫血模型：不依赖于持久化的领域逻辑，是否包含在领域对象中。
	 >充血模型：划分业务逻辑：大部分业务放到领域对象中。Service应该是很薄的一层。
   >分层架构：典型为MVC.
    >经典的领域模型架构：Domain层, Service层, Repositories层  领域层(Entity核心实体和值对象Value Object)、领域对象服务(Domain Service)，领域对象存储仓库(Repositories)
	 >也是包层次：project/src/domain|services|repositories|interface|gateways 调用不跨层，下层实现上层。
	>通信协议：GRPC移动设备上使用。服务之间Rest api接口通信。
	 >查询时同步，增删改时如果用异步业务上没问题其实可以建议使用。查询接口需要幂等。POST新增资源，PUT更新完整资源，PATCH部分更新，DELETE删除(返回状态：首次200,第二次204状态和数据一致)
   >单一职责：
   >服务拆分：康威定律。按照三个维度划分：   
    >AKF扩展立方体：拆分应用、拆分数据库。
   >前后端分离：代码分离、部署分离。通过HTTP请求互相通信。
   >版本控制：API的所有版本和新服务的启动。
    >在API中反映版本：放到URI/v2/remote 或者报头中。
   >围绕业务构建：构建的微服务本身描述不依赖某种实现技术栈。
   >并发流量控制：缓存、降级、限流。
   >CAP: 根本在于分布式级联调用需要经过网络中多个点，每个点都要成功，这段时间期间如果定义为不可用的则可以保证任何调用成功都满足数据一致性，而如果这段时间定义为可用的则会出现数据没有一致性变化而获得到了不一致的结果。这就是在分区下：一致性和可用性的矛盾。
    >如果在分布式数据系统中：则是备份的数据、冗余的数据的一致性变化需要一个时期，而这个时期内同一个数据的版本在不同的冗余节点副本上是不一致的。其实分布式数据系统中才是真正的数据在各个副本节点上的一致性和可用性的矛盾。此外，一部分节点发生故障也能影响系统的读写可用性。可用性高：则要副本节点多；一致性高，则希望副本节点越少越好(一致化的代价随节点增加而增加)。
	 >在容忍分区故障条件下：副本节点数多则可用性高(节点崩溃/网络故障依然有幸存的节点可用可达)，副本节点数少则一致性高(一致性实现的时间代价和通信代价低)。
     >CA模型：模型的具体过程 实现一致性和可用性，但不容忍哪怕一个网络故障--直接认为是节点崩溃故障，严格的全体一致协议--只要有一个网络故障直接整体都不可写---当作出了最严重的网络问题--出了一个网络故障就罢工---不再工作。 
	 >CP模型：模型的具体过程 实现一致性和分区容忍性：容忍部分网络故障---只要大多数节点可用并且在数据一致性同步过程中成功，这些节点设置为可用，其他节点设置为不可用(直到启动成功并且数据同步一致了) 即可看上去：获取的数据始终是一致的(因为不一致的不让看)。所以可用性会忽高忽低--因为不保证它总是很高。即限制了可用性。
		>或者因为写数据 而导致 数据不一致：这个数据一致化的时期内也是不可以读写的--不对外服务，所以可用性降低。
		>hbase/zk: CP模型。这两种分布式系统满足CP性质。
	 >AP模型：模型的具体过程 实现可用性和分区容忍性：容忍部分网络故障---只要大多数节点可用，在同步中只列出冲突数据，不进行一致性化的补偿操作，这些节点设置为可用，而其他节点无论因为一致性同步失败/网络超时/网络不可访问还是自身崩溃--都设置为继续可用(重启之后也不用等到数据一致性同步完成后才恢复可用---因为有自动同步的程序在跑，不一致的时间很短)，也允许看到不一致的数据。
		>可读但不可写。
		>Eurake：AP模型。
	 ----只要节点不是崩溃，都可用：为AP模型。节点必须数据一致后才能可用：为CP模型。节点只要有一个不可访问无论网络超时/不可访问/崩溃，整个系统都拒绝再提供写服务即都不可用--即根本没有了可用性，为CA模型。
	 ----分区是容忍/允许，一致性的补偿是专门的同步程序，可用性的补偿是更多的节点。
	 ----不保证可用性：就是不保证每次请求都是可用的---即便所有节点都正常网络也正常。因为为了一致性也会中断某些时刻的可用性。同理，保证可用性，就是保证只要节点正常，那么就要可用，尽管数据可能不一致。
   >EDA事件驱动：通过消息队列耦合。
    >服务：以原子粒度更新数据库和发布对应的事件。   
	>保证数据更新和事件发布原子化的方法：
	 >开发者用本地事务来实现：一边更新事件列表，一边发布事件。
	 >监听和挖掘数据库的事务日志：从事务日志中发现事件来发布。
	 >存储使得应用状态改变的事件序列到事件仓库：可以根据这个事件序列重构实体的状态。
   >CQRS: 一种读写分离思想。保证添加、更新、删除时所基于的数据时最新的。而查询的数据不必是。
   >基础设施自动化：DNS/CDN. 负载均衡器。日志、监控、报警服务。运行容器。
   >数据一致性：三种模式保证最终一致性。
    >可靠事件模式：更新业务实体时，微服务向消息代理发送事件。
	>业务补偿模式：保证一致性的工作服务，用额外的协调服务来依次调用。
	>TCC模式：主服务和从服务。从服务提供try-confirm-cancel接口。
   >设计模式：链式、聚合器式、共享数据、异步消息控制
    >应用--网关-->微服务
	>应用--网关-->消息队列
   >DevOps: 开发测试运维。通过自动化的流程来使得开发、测试、部署更加快捷、频繁和可靠。
    >自动化闭环流程的实现框架：规划-代码-构建-测试-发布-部署-运行-监控
   >无状态服务：将状态数据存到分布式缓存，而把服务完全做为无状态的计算服务。
  >Spring boot: 开发时完成依赖引入(spring-boot-starter-xxx说明)，运行时完成装配(@SpringBootApplication说明)。
   >1.自动装配第三方jar里的bean并放到容器里，通过自己提供的统一的专门接口对开发者提供，开发者直接引用即可如@Autowired引用；使得集成第三方非常方便。 想象一个容器：内壁上是多个统一的某类功能的接口bean，外壁上是第三方框架jar,容器中是其他bean和项目中实例化后的bean
   >2.默认内置很多常见第三方jar--开发更方便--不用再maven各种依赖编写， 直接默认集成常用的第三方框架--只需要开发者提供第三方需要的数据即可。约定大于配置。
   >3.非功能特性：指标、监控、安全、健康检查。
   >4.开发工具：基础类加载器和重启类加载器。基础类加载器加载第三方jar里的bean, 开发中的类则通过重启类加载器加载，从而类路径上的文件变更，则自动重新加载这些类，实现快速的热部署。
  >Spring boot starter: 用来引入和装配和运行第三方的依赖：从redis/jpa/jdbc/amqp/actuator到定制自己的都可以。
  >AOP: Spring通过预编译和运行期动态代理实现。
   >将软件系统视作/分为横切关注点和核心关注点：AOP则就是分离横切关注点和核心关注点，分别到专门的类中，而还能保持原来的紧密执行顺序的方法。代码分开，但实际执行顺序和逻辑不变。
	>事务、日志、权限认证、数据源的切换：都是横切关注点。
   >切面：切入核心业务的横切逻辑类
   >连接点：核心业务类中横切逻辑类切入的方法。通知匹配到的方法。
   >通知：切面中的横切逻辑方法。@Before("切入点方法()") @AfterReturning("execution(...)")方法返回通知。@AfterThrowing(value="execution(...)", throwing="exception")方法抛出异常退出时执行。@After @Around
   >切入点：满足某个表达式的所有连接点。在切面中，作为一个单独的方法@PointCut("execution(...)")。这个表达式是切入点表达式，每个通知得关联一个切入点。 *表示所有匹配，...表示路径任意/多个参数,+表示类和子类，。可以约束：可见性、返回类型、方法名和参数指定和异常
   >引入：给被代理的类引入/实现更多的接口
   >目标对象：连接点所在的类。它的bean实际上是另外一个代理它的类的bean。
   >AOP代理：JDK动态代理和CGLIB代理。//修改类方法的字节码--调用切面通知(环绕通知可以通过修改通知方法-增加一个标记入参-而在连接点前后执行入参不同即可)，和重新定义一个继承类/实现类---方法的实现指向一个统一的拦截器MethodIntercept(可以在类加载时、运行时(开始执行main函数之后很快))。
   >织入：将切面和连接点连接起来。Spring在运行期完成。AspectJ在编译器完成。类加载时也可以。
   ---切面引入：@Aspect需要加入依赖：spring-boot-starter-aop
   ---log4j2日志引入：spring-boot-starter-log4j2 同时去掉exclude stater-web里的logging依赖。
  >持久化：将数据保存到存储设备中。JDBC和磁盘IO就是持久化机制。 spring-boot-stater-jpa
   >java持久层API:JPA, 持久层规范，持久层统一标准接口。Spring DATA JPA是Spring为JPA提供的一套实现，底层使用Mybatis/hibernate的JPA实现。
    >使用mybatis的starter:mybatis-spring-boot-starter。配置相应的数据源。然后@MapperScan("mapper xml包路径即可")
	>多数据源：先禁用DataSourceAutoConfiguration， 即在@SpringBootApplication(exclude={Data....class})。。。在配置文件里写配置，然后通过@Configuration一个类来引入两个db source bean: @Bean("db1")@ConfigurationProperties("spring.datasource.db1")----读取配置文件中的指定值。同时可以@MapperScan对应的配置类里加入对应的db DataSource
   >JOOQ: 访问关系型数据库的工具包，有ORM的简单安全，有SQL的灵活。实际上太麻烦。
  >事务管理：spring framework为事务管理提供了一致的抽象。声明式事务，同时和数据访问抽象完美继承。spring-boot-stater-jdbc自动装配出DataSourceTransactionManager实例。如果是spring-boot-stater-jpa则是JpaTransactionManager, 然后@EnableTransactionManagement 后在接口上@Transactional目的就是失败时能够回滚！！
   >事务传播属性：要求有事务(3个)、无事务(3个)、允许嵌套事务(1个)三大类。要求无事务的：有事务时抛出异常或者挂起当前事务或者就在这个事务中执行。要求有事务：已有事务则利用已有事务没有创建事务或者抛出异常，或者已有事务则挂起而自己新建一个事务没有事务则创建一个新事务。允许嵌套事务：当前有事务则仍然创建一个事务独立提交或者回滚，没有事务依然创建一个事务。
   >事务管理器：JTATransactionManager, TransactionManager, DataSourceTransactionManager 第1个和第3个会实现平台事务管理器，中间的不会。
   >并发引起的事务问题：读未提交(脏读)、读已提交、幻读
  >整合Redis: redis数据类型多、api丰富，可持久化。支持事务、HA高可用、主从库等数据库特性。即是缓存系统也是数据库。org.springframework.cache.CacheManager  依赖spring-boot-starter-data-redis 配置之后 StringRedisTemplate可以bean化
   >缓存指标：命中率、Miss率  ，来于从缓存中和从慢速设备中读取的次数的比较。
   >数据淘汰策略：分从已设置过期的数据中进行淘汰(最近最少访问lru, 将要过期的ttl, 随机的random)、从全部数据集中进行淘汰(最近最少访问lru, 随机的random)、不淘汰--禁止驱逐。采取看键-访问频率 的分布情况：指数下降分布lru, 平均分布random
   >spring 缓存规则：@Cacheable查缓存且存缓存 @CachePut只存  @CacheEvict清除缓存条目，
   >spring boot自动化配置合适的缓存管理器：@EnableCaching  会依次检测缓存提供者：EhCache, redis, guava
  >整合消息队列：用在：应用解耦、异步消息、流量削峰。高性能、高可用、可伸缩和最终一致性架构。标准消息队列应用层协议AMQP, 依赖spring-boot-starter-amqp
   >RabbitMQ:  @RabbitListener(queue="队列名")监听队列消息。
  >整合mongodb:更是只需要一条mongodb部署地址的配置，就可以引用MongoTemplate实例了：spring-boot-starter-data-mongodb
  >web开发的整合：spring-boot-starter-web提供内内置的tomcat和springmvc依赖，spring-boot-starter-thymeleaf引入模板引擎-默认thymeleaf 视图跳转路径可以 配置。
   >增加拦截器链：新建实现xxx接口的拦截器，继承xxx的类里重写addInterceptors(...)方法，将拦截器加入。
  >接口文档管理：swagger构建API文档并可以在浏览器里查看和测试接口。
   >引入依赖：springfox-swagger2  配置@EnableSwagger2 配置类---实例化Docket.. 在需要api文档化的controller类上进行@Api("文档注释")    在类里面的需要文档的方法上@ApiOperation("xxx") @ApiImplicitParams({}) @ApiResponse({})   。。。就可以在浏览器中/swagger-ui.html里查看
  >优化的调度：定时任务集中管理，而不是分布在工程各个地方。Spring boot 自带Scheduled可以看作是一个轻量级的Quartz ...
   >@Scheduled
  >健康：
   >配置查看和功能统计：spring-boot-starter-actuator, 则会将相关的类bean化放到容器里，同时还会因为是web项目而部署到web容器---即增加url-controller映射到web容器中。
    >访问url:/autoconfig自动配置的使用情况。/dump打印线程栈。/health查看应用健康指标。/trace查看基本追踪信息。
  >整合Dubbo:Dubbo是典型的四方参与的微服务架构：consumer-registry-provider-monitor .客户端负载均衡和服务调用降级。 consumer-provider都是spring-boot项目，registry是一个zk集群。monitor也是zk。consumer的服务接口@Refrence ,而provider的服务接口@Service, 启动zk,启动provider,启动consumer。因为也是接口依赖，所以需要服务端的接口jar。
  >Docker: 负责高效的进行应用的分发、管理和部署。
   >使用场景：一方面服务器资源闲置，另一方面缺没有服务器可用。一台机器上直接部署多个服务，会端口冲突/cpu\mem互相争抢占用互相影响，(因为没有资源分割)。扩容/缩容 效率低：机器下线到应用部署、测试，周期较长。  
		       多环境代码不一致：如果没有指定一定要让通过测试的版本来上线---而通过测试只能让专门的人来处理。
   >使用特征：单个容器运行单个应用：即面向服务的架构。
   >架构：C/S架构。守护进程和客户端进程。守护进程完成实际的工作。实际的工作包括：1.文件系统隔离(每个容器都有自己的root文件系统) 2.进程隔离(每个docker运行再自己的进程环境中，互不干扰) 3.网络隔离(容器间的虚拟网络接口和ip地址都是分开的) 4.资源隔离和分组(cpu/mem资源独立分配给不同的docker)。完成这些工作所依赖的条件/工具：linux内核特性Namespaces命名空间和Control groups 控制组。
    >功能目的：实现四大分割和隔离：文件系统、进程、网络、cpu和内存。所谓轻量级的操作系统虚拟化解决方案---就是因为只虚拟化了这四大块。
	>docker守护进程：直接和操作系统打交道，通过docker镜像创建容器。一个镜像创建一个容器，秒级创建。docker对系统资源的利用率很高，创建大量容器。docker基本没有自身的消耗，基本都用来运行其中的应用。docker容器可以跨平台运行。
	 >创建特征：快(秒级)、多(数千)、跨(跨平台，无关os)、静(本身不消耗系统资源，都用来运行应用)。多快好省。
    >核心概念：镜像、容器、仓库。
	 >镜像：基础镜像+应用的二进制部署包。通过Dcokerfile, 容器, 本地模板 三种方式创建。
	 >容器：运行镜像创建容器。进入容器nsenter
	 >仓库：存储在远端的镜像集合。新建、拉取镜像、保存镜像。
	>dockerfile内容：指定docker启动后运行的命令集合： 
	 >构建java 环境的dockerfile: maintainer lishaoping xxx  \r\n from centos 然后是在dockerfile文件目录下新增另外2个文件：一个是jdk一个是项目的jar,
								run mkdir /var/tmp/jdk 
								copy jdk-8u152-linux-x64.tar.gz /var/tmp/jdk
								run tar xzf /var/tmp/jdk/jdk-8u152-linux-x64.tar.gz -C /var/tmp/jdk
								run rm -rf /var/tmp/jdk/jdk-8u152-linux-x64.tar.gz
								add xxx.jar app.jar 
								env JAVA_HOME=/var/tmp/jdk/jdk1.8.0_152
								env PATH=$JAVA_HOME/bin:$PATH
								env CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
								expose 8080   //配置容器暴露的端口号
								entrypoint ["java" , "-jar", "/app.jar"]  //配置容器启动后执行的命令
		然后再当前目录执行命令：docker build -t jdk8run .
		构建完毕，运行容器：docker run -p 8080:8080 jdk8run 那么外部就可以通过http://ip:port访问了。
			  其他运行参数：--net 网络模式。--link主机名
	 >跨主机的容器访问：Open vSwitch高质量的多层虚拟交换机。。Weave创建虚拟网络，用来连接部署在多台主机上的docker容器。Flannel网络规划服务。
	 >容器挂载的数据卷：独立于容器的生命周期。docker run -v 本地目录:容器目录。
	 >数据卷容器：被其他容器挂载，实现数据共享。也可以利用容器特性而将数据卷备份恢复。
	>spring boot 整合docker:   volume /tmp创建挂载点 挂载到本地或者数据卷容器/tmp
	 >依赖:dockerfile-maven-plugin
	 >编写dockerfile文件
	 >对工程打包运行即可。
	 >构建docker镜像：mvn install dockerfile:build
	 >查看镜像并运行容器：docker images \r\n docker run -p 8080:8080 -t xxx 
    >镜像管理：harbor	 需要先安装docker-compose, 可以搭建一个本地的docker 镜像管理仓库，并且还有ui界面操作和日志查看。
	>kubernetes: 容器调度工具。自动化容器操作的开源平台。操作包括：部署、调度和节点集群间扩展。
	 >功能目标：自动化部署和复制，随时扩展或收缩容器规模。将容器归组，并提供容器间的负载均衡。提供容器弹性，容器失效就替换它。。----简称：自动部署、弹性伸缩、失效替换。
	 >集群组建：etcd--高可用kv键值存储和服务发现系统。
				flannel:实现跨主机的容器网络的通信。
				kube-apiserver: 提供k8s集群的api调用。
				kube-controller-manager: 确保集群服务。
				kube-schedual: 调度容器，分配到Node
				kubelet: 在Node节点上按照配置文件中定义的容器规格启动容器。
				kube-proxy: 提供网络代理服务。
	 >主要概念：
	  >Pods: Pod是一个容器集合，运行相同应用，相同host.
	  >Services: 真实应用服务的抽象，每个服务都有很多容器支持。对外单一访问接口，对内则通过proxy负载均衡转发给多个容器。
	  >Replication Controller:控制k8s集群中Pods副本运行的数量。
	  >Labels: 标识容器的。kv键值对。
	 >工作方式：master/node集群，master/node之间通过kubernetesAPI通信。每个node上有运行kubelet
	  >单机版本：minikube, 还可以通过web page操作k8s集群的操作。
	>私有云架构：
	 >基础设施：服务器+网络+存储
	 >容器层：基础设施之上，容器初始化层。包括k8s,agent,ip地址管理。用于对基础设施资源进行管理。
	 >容器管理层：容器管理、扩容缩容、版本控制、上线发布、权限控制和资源管理，满足高并发的需求。
	 >应用层：为用户项目运行提供的基本环境，如java虚拟机环境和开发工具包jdk。
	 >云平台基础组件：服务注册和发现、网关服务, 镜像中心、日志中心、监控中心
	 >统一UI平台：统一管理整个云环境的所有资源。
	>Spring Cloud: 
	 >spring sleuth: 服务跟踪框架。整合zipkin, htrace, elk
	 >服务注册中心：zk
	  >zk: 保证CP，不保证每次请求都可用。
	  >Eurake: 保证AP。当作自家的产品，销售时介绍它的优势：界面管理、心跳机制(客户端续约-主动发送，30s, 90s则下线)、客户端缓存(eurake server挂了客户端也能坚持一会儿)
	   >核心功能点/基本功能点(假如自己来实现，当作自己的产品一样来记住)：服务注册、服务续约、获取注册列表信息、服务下线、服务剔除。
	   >分client和server: client就是服务提供方或者服务消费方。所以，还有的基本功能点：消费方通过远程调用访问服务提供方---远程调用就有限流、熔断(后面的不再调用,直接fallback)、降级(fallback)。
	    >工具利用：内存缓存：guava； 定时任务：Timer, Restful http接口实现：jersey框架。
	  >etcd: 高可用键值存储系统，用作共享配置和服务发现。采用Raft一致性算法, 选举机制。提供TTL数据失效、数据改变监视、分布式锁原子操作。
	  >Consul: 一站式服务发现和配置共享。适合容器化无缝配合。etcd也适合容器化配合。
	 >服务发现： 
	  >客户端服务发现：服务实例注册到注册中心，客户端从注册中心获取服务实例列表，这个列表通过服务实例的心跳机制动态刷新。同时客户端进行负载均衡调用服务实例。
	  >服务端服务发现：如用Nginx高可用地实现一个负载均衡器，客户端直接访问这个负载均衡器，而负载均衡器负责从注册中心获取服务实例列表并且转发路由到其中一个实例上。相当于剥离客户端的负载均衡出来到一个专门的高可用集群上来实现。
	   >负载均衡算法/规则：Ribbon作为统一模板远程调用类的拦截器被使用。
		>轮询：循环。线性轮询-重试。
		>随机：随机。小范围的随机：在请求量最小的一个集合里随机寻找一个服务实例。
		>加权响应时间：响应时间大的分配权重小，即概率小，动态的会根据每次请求而调整服务实例的权重：我想到的一种方法：服务器1,2,3,...n分别有一个正的权重a1,a2,a3,,,其中a1是距离0的间隔,a2是距离a1的间隔，从而可以计算出∑ai=m , 然后生成一个0-m的随机数k, 则通过a1+...ai<=k<a1+...a(i+1)方式计算出的ai就是被选择的那个机器。
	 >Feign: 声明式的、模板化的HTTP客户端。使得开发者不用亲自为实现http请求而进行相关的参数封装操作，而直接可以原生的像本地调用一样用接口调用实现(调用远程服务)------自然的识别条件就是，需要对这些接口进行特殊的注解。
	  >Decoder和Encoder可以替换。
	  >服务方用controller实现这种接口打的接口包，而消费方直接调用。----但是耦合度太高，服务端对接口改动那么消费方也需要改动。
	 >服务雪崩效应：服务提供者的不可用造成的服务调用者的不可用。对链式设计模式构建的微服务 为常见。
	  >服务不可用原因：自底向上：网络不可用、硬件不可用、软件bug、缓存击穿(大量缓存失效/缓存服务器重启)、大量用户请求。
	  >应对雪崩方案：
	   >流量控制：分流和限流。nginx/网关分流, redis限流，
	   >服务自动扩容：容器动态扩容。
	   >资源隔离：对调用服务的线程池进行隔离，对池中的各个线程的cpu/mem占用进行监控---当占用过高时杀死该线程来解决性能瓶颈。
	   >降级：将业务依赖服务分为：强依赖是哪些不可用则本服务也只能中止的服务，弱依赖则是那些不可用而本服务业务可以继续残缺运行。从而方案：就是当不可用的服务时弱依赖服务时，直接快速失败fallback---里面执行返回默认数据或者查询其他服务(对于查询服务)。快速失败的判断条件就是(服务不可用的条件)：弱依赖服务超时中断机制、量大熔断机制、(熔断后本服务要么就要么就中止，或者从其他服务调用、或者从缓存中取默认值、或者直接返回默认数据(可以想象的一个方案列表图)-----就是降级，)
	   >熔断：错误达到一个阈值(单位时间内的调用量/服务超时调用的量)--判定为服务不可用，则终止对它的调用,等待一段时间，时间到了之后半开状态/限流--只发送一个请求来探测验证--如果得到了响应则转换到全开--否则重复关闭一段时间，可用时恢复调用。
	    >对于更新、新增接口，只能熔断，对于查询接口，可以降级。
	  >Hystrix: 通过服务熔断、降级、限流、异步RPC等手段控制依赖服务的延迟和失败。
	   >设计原则：资源隔离、熔断器、命令模式。
	   >资源隔离：每个服务都有一个专门的线程池，来做到线程隔离，而做到线程池级别控制调用量，控制单个服务的线程阻塞或者超时的量(而不是不断增长---影响到其他服务)。
	   >Hystrix调用流程中转到fallback的原因：熔断器开启、线程池拒绝、线程服务执行失败、执行超时(单位时间内的超时和失败量会统计上报Metrics而决定是否要熔断)。	
	    >调用服务超时/失败而执行fallback方法的代码实现：在代理类里，将调用服务的代码即obj.invoke统一代码放到一个匿名内部类实例而传递给一个线程池来异步执行--执行完了notify主线程，而主线程则await(200)限时等待----当时间到了本行代码返回结果或者抛出异常，再结合服务调用的结果，都可以当作判断调用成功或者失败/超时的根据：来进行fallback或者正常执行；如果超时，那么还需要直接interupt服务调用超时的线程--来释放占用的资源。
		 >线程interupt()：就是给线程一个中断信号，线程本身会不断检查自己的中断位是否为true, 来判断是否要退出阻塞状态，---但是如果该线程没有阻塞则interrupt无效--即不能强行中断一个正在非阻塞执行的线程。
	 >分布式配置中心：spring cloud zookeeper config为首选：
	  >配置从gitlab传递到server再到client: 同时webhook同步更改也很重要。
	 >API网关：认证、鉴权、流控、协议转换。
	  >路由、版本控制、合并输出：合并输出就是一个请求到网关后转换为并行调用n个微服务，将结果捆绑后输出。
	  >接口灰度移植：想替换一个微服务，则开发新的微服务，然后一点点灰度的将流量转发到新的微服务上，来保证服务一直的高可用和安全可靠转移。
	  >认证：统一的权限认证，没有权限不能被转发到某个微服务。
	  >格式转换：数据格式请求方和微服务方进行转换协调。
	  >协议转换：调用微服务可能grpc,可能thrift,等其他协议。而请求方一般是http
	  >限流和缓存: 访问量比较大的请求，进行限流，对于某些请求的数据进行缓存。
	  >日志记录：统计服务的调用量和响应时间。
	  ---鉴权：哪几类人，哪几类资源，提供什么认证资料：
	 >消息总线：多个应用之间的异步通信信道。
	  >用作配置更新：config server收到webhook的配置更新而发送消息到消息总线，消息总线分发消息给各个客户端， 客户端收到消息而开始主动请求config server来获取最新的配置。
	   >为什么要用消息总线来做这件事？首先，配置更新了，肯定要发送给配置服务器，如果config server直接发送给各个客户端---那么显然配置服务器要维护一个客户端列表，而不应该一个服务一个非配置中心来维护，假设客户端主动来请求那是最好的，但是客户端怎么知道变更了？需要有消息通知它，谁可以发送消息？即消息总线，消息总线怎么知道变更，则配置服务器可以发送给消息总线，如此完成闭环：webhook-->configserver-->mes bus-->config client--->configserver。所以应该交给一专门负责转发的---就是消息总线，所以模式变为configserver发送给消息总线，消息总线专门负责分发变更消息给各个客户端，各个客户端收到变更消息
	 >Consul: Raft协议，多数据中心，健康检查，web管理界面。服务端集群个数：3-5 。用作注册中心。 
	 >Zookeeper: CP系统，内存Znode数据结构，原子广播zab协议保证---实现leader和server的状态相同。可以用作配置中心或者注册中心。 引用依赖、配置访问、注解启用，bean化接口调用。
     >archaius: 分布式配置管理依赖构件。功能为定期1min加载配置文件config.properties	 
	 >spring cloud security: 
	  >安全规范：HTTP Basic Authentication基本鉴权。某个URL需要鉴权，那么访问的时候需要在header上有Authorization: Basic 用户名：密码 的Base64编码。， 但是Base64直接可以解码：echo xxx | base64 -D
	      >JWT: json web token 构成：头部+载荷+签证。。完整的头部：{"typ":"JWT","alg":"HS256"} 然后进行base64加密。载荷：{"sub"... "name":"", "admin":true} 然后进行base64加密；签证：头base64.载base64 进行secret为盐的加盐HS256加密得到。secret在服务端当作私钥，进行JWT的签发和认证。
		   >认证过程：用户线发起http post请求，带上用户名和密码，服务端通过验证----这个用户存在， 签发生成一个JWT token返回给用户，用户将这个JWT token放到报头的Authorization里访问API接口，服务端则验证这个token是否是自己签发的，通过验证则范湖I请求的数据。
		  >OAuth2: 一个关于授权的开放网络标准。
		   >客户端/用户：登录授权层，授权层访问服务提供商。
		   >取得access_token:四种授权模式。
		   >基本流程：用户先转到登录界面，相当于获取授权, 比如选择用QQ登录，登录成功则授权给原来的页面后端，同时给token给用户，用户用这个token再次访问原来的界面就认证成功而可以访问该页面了。
	  >功能：单点登录、资源授权、令牌管理。
	 >spring cloud sleuth: 一套完整的服务跟踪解决方案。
	  >每次链路请求都会：添加一串跟踪信息：server-name-->traceId->spanId, 从而每次请求一个traceId, 到哪个节点了有一个spanId, 返回也有一个spanId, 从而知道调用时间。
	 >spring cloud stream: 异步通信的抽象接口：最简单最基本的该业务类型的接口。使得和具体的消息中间件解耦，而可以随时替换，动态替换。 
	>微服务测试：
	 >UI/UE测试：
	 >端对端测试：不同端下测试业务目标。
	 >API测试：微服务接口测试。用postman 或者hitchhiker---还能压力测试/数据对比/schedule。
	 >组件接口测试：
	 >单元测试/覆盖测试：所有可能的输入、糟糕输入都拿来测试。来增加对程序正确的信心。就是验证。测试就是验证。期望-运行-验证。
	 ---
	 >A/B测试：分离测试。多版本的后端AB测试，分流到不同的版本，返回给用户，看效果而选择好的。
	 >冒烟和回归测试：冒烟测试，好像电路板通电看有没有短路这样，能不能跑起来这样的测试，或者说修复了一个bug,专门测试因为做了这个修复而软件还能不能继续跑起来的测试、简单专门测试就是冒烟测试---最基本的测试：就是冒烟测试，冒烟测试都通不过---就直接给开发部重新搞了。
	  >回归测试：因为某个修改而进行的全盘测试。看能否回归到正常。
	   >postman编写测试用例、newman执行测试脚本生成测试报告,jenkins创建测试项目--并且关联到被测项目--使得构建被测项目到测试环境时，自动构建相关的测试项目，并触发测试项目执行。	
	    >postman根据swagger服务契约而自动生成测试用例并模拟调用。
	 >静态代码检查：找出隐藏的错误和缺陷，提高软件的可靠性。Checkstyle, FindBugs, PMD	
	 >SonarQube: 代码质量管理平台。
	 >JHipster: 代码生成框架。微服务定制界面--输入想要--输出微服务项目(比如说：常规的整合)。
	>自动化部署：持续集成持续部署。
	 >私有仓库：jar仓库，局域网内存在的对远端仓库的代理, 避免所有机器都从远端下载jar。Nexus使用Lucene搜索，ExtJS开发的界面，Restlet提供完整的Rest APIs. 配置本地仓库和settings.xml后，可以将本地项目的jar都上传到nexus。
	 >自动化运维工具：Ansible 。。自动配置数量巨大的机器。	
	>持续集成：每个项目每天大量集成，每个集成都自动编译打包部署自动化测试验证，从而尽快的发现集成错误。Jekins, Hudson.
	 >自动触发单元测试：在编译完成时候，可以设置自动执行@Test的方法---即进行单元测试。之后触发sonarcube客户端执行静态代码检查，生成检查报告；编译构建完成，生成docker镜像；发送到测试环境，触发自动化测试流程(测试新发布的接口和改动的接口)，通过后进行回归测试(测试之前的接口，看对其他接口有没有影响，是否依然正常),发布到预发布环境，再次测试，通过后灰度发布到线上环境。
	 > >构建进度、构建状态、构建结果：查看。
	 >jenkins: 起源于Huston的持续集成工具。安装和迁移方便。可以分布式部署。
	  >master-agent-executor-job: 
	  >pipeline-node-stage-step:流水线部署。一个stage下多个step。
	  >jenkinfile: 编排从代码提交到交付过程中所需的工作。
	  ----docker 下载镜像：docker pull jenkinsci/Jenkins
	  >配置测试：首先增加一个自由风格的项目A, 然后在正式项目B的构建后操作上增加一个：构建后自动触发执行这个测试项目。。构建时执行脚本：newman run xxxx.json --reporters xxx --reporter-html-export xxx
	 >sonar: 代码度量工具,可以配置到jenkins 的post build action中去。可以绑定到maven执行项目的生命周期中：只需要在插件中executions下增加<phase>指明阶段<goal>指明调用指令。
	>灰度发布：Nginx负载均衡：定义一个upstream (即一个server ip-权重集合)，再定义一个server-location 配置即可。  
	 >Nginx+Lua: 配置一个location-content_by_lun 'xxx'脚本，然后配置其他合适location即可。
    >日志收集和监控：
	 >ELK收集和分析：Logstash收集Appserver产生的log, 存放到es, kibana从es集群中查询数据生成图表，再返回给Browser。
	  >Nginx日志+前端埋点(百度统计/google统计)+业务日志(log4j2)
	 >监控：
      >进程监控：nginx进程，python脚本来监控。
	  >线程网络监控：top, iostat, vmstat
	 >监控系统：
	  >Zabbix--分布式系统监控和网络监控的企业级解决方案。server+agent模式。
	   >通过微信方式告警：wechat.py
	  >Open-Falcon:server-agent-client-judge/query
	>服务跟踪系统：快速进行服务链路的故障发现。
	 >APM: application performance management.。参考google的Dapper
	  >PinPoint: 调用链工具，分布式跟踪系统。认为：直接传递到中心就可以，没必要层层叠加返回再传递给中心---浪费传输。
	   >分布式事务跟踪：
	   >自动检测应用拓扑：
	   >提供代码级别可见性：以便轻松定位失败点和瓶颈。
	   >服务器地图：可视化分布式系统的模块和他们之间的联系来理解系统拓扑。
	   >实时活动线程图表：实时监控应用内部的活动线程。
	   >请求应答分布图表：
	   ------模块：collector----agent--web---storage
	   >核心数据结构：
	    >span: 其中spanid在rpc到达节点时生成。ParentSpanId则是传递过来的，这种处理场景，显然对同步调用是可以展示调用链的。但是对于异步调用则不行---会直接终止---除非放到消息里----消息发送的时候也连带发送spanId-traceId。
		>trace:
		>traceId: TransactionId事务id是构成的一部分。
	  >SkyWalking: 也是不是追踪系统
	  >Zipkin:Twitter开源：基于google Dapper的论文。
	   >故障快速定位：调用链分析
	   >性能分析: 调用链延迟。
	   >服务可用性：看各个调用服务的QPS。
	   ------
	   >采集：客户端agent采集
	   >发送：发送到server
	   >落盘：落盘到DB
	  >CAT: 美团的APM工具。实时应用监控平台。实时应用监控、业务监控。
	   >C端上报统一的日志信息。
	   >S端运行定时任务(报表转图表)、告警任务(对报表做筛选，提出告警信息，保存；如果是发送节点则发送给运维人员)、发送节点。
	>spring security的注解配置：@PreAuthorize等都非常简单，使用到oauth2   
	>附加工具：
	 >Activiti:工作流引擎。
	 >UFLO:提供业务流程流转功能
	 >Drools: 开源规则引擎库：ReteOO算法。
	 >URule: 快速实现规则的定义、维护和发布。
	 >调度系统：并发且可以横向扩展。
	  >XXL-JOB:任务定义/创建和调度平台。
	 >消息推送：支持多平台的消息推送平台。
	  >MPUSH: 开源的实时消息推送系统。
	 >网关中间件：
	  >Orange: 基于OpenRestry的API gateway,。访问统计、流量切分，API鉴权、API重定向、Web防火墙。限流。
	  >Kong:基于Nginx的API gateway
	  >Zuul:本质是一个Web servlet应用
	 >分库分表中间件：
      >Sharding-JDBC:
	  >MyCAT: 数据库代理。
	  >UReport2: 报表引擎。
	  >ETL: 抽取数据源里的数据--->转换为全新的格式--->加载到目的数据池/数据仓库/数据集市里。
	  >Spring Batch: 批处理框架。
	  >Kettle: 数据仓库中使用频繁。在不同数据库之间整合数据。
	  >Akka: 简化高并发、可扩展和分布式应用程序的设计。
	  >Disconf: 分布式配置平台。Apollo为携程的。
	  >CAS: 中心验证服务。
	  >反应式编程：WebFlux。 Reactor库。Flux和Mono。。是替换Spring mvc编程的趋势。注解模型、函数式模型、反应式模型。