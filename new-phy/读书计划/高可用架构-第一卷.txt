---------读书战略：自顶向下，从应用层到底层细节。先熟悉的常用的，后底层的不常用的。精读好书---《深入理解系列》
--------es的处理思想都对应有 相应的“某种举动 及其导致 的问题”
>需求背景-痛点陈述：现实开发中遇到了什么痛点导致XXX的开发？  
>那么痛点的原因、产生的条件：分析是什么环境、什么动作 什么效果什么目的 等精准形容词的事实描述 导致了痛点的必然发生，难以避免？。条件-痛点。原因-结果。
>则可以消除痛点的最简单的精准事实陈述是什么：修改“条件-痛点”陈述的哪一部分就可以导致没有痛点产生。 要做的根本事情是什么：
>那么新陈述表明的解决动作是什么：
>新情况的新痛点是什么：新举动、新环境会产生的新痛点描述出来， 继续上述4条操作。
>学习要有战略和格局：过于零散、孤立、末支、叶子的知识点就没必要化太多时间，懂得放弃。聚焦在根节点、枢纽节点、产生分支的节点、主干知识点、枢纽知识点、关联到很多知识点的知识点上。
 >对于主干知识点：要有全新的认识视角和进行精细的描述，大量的提问和好奇和进行必要的实验以获取支撑观点/导出观点的数据。

 
>举动-痛点：搭建高并发、高可用系统
  >解法/处理思想： NewSQL , Serverless, 云，微服务
     >互联网系统的基本要求：高可用。
	 >分布式日志篇：
	  >日志：只追加、严格有序的记录序列。很有效的数据结构。常用来解决分布式系统的问题。
       >实现key-value数据库的CAS强一致性：并非适用paxos二阶段一致性算法。而是利用客户端可以多个，处理端可以多个，但是数据目的地可以只有一个，就是日志(也可以是kafka), 来协调操作排队，然后各个数据存储端读取这个顺序化的日志/kafka流，来更新自己的数据。Pub/Sub模式。
       >持久化、多副本、强一致性：低延迟、高通量、可扩展
        >基于持久化和强一致性的服务：
		 >日志系统核心负载：追加write, 尾部读取tailing-read；要求低延迟。从比较早的位置读--catch-up read ;关注吞吐量。
	     >Apache BookKeeper: I/O分离，并行复制、简单的一致性模型。方便用于构建分布式日志。
		  >clients-bookie-zk注册管理中心:客户端创建Ledger, 挑选一定的bookie, 构成一个Ensemble, 客户端并行发送Entry给Ensemble里的所有bookie， 收到大多数的返回就认为写入成功了，就返回给客户端了；这个确认是严格按照EntryID进行的，小的先确认，从而保证日志的严格有序性。Ensemble Change可以将因为有一些bookie失败而从bookiePool里再增加一些bookie来补充----来保证写操作的高可用性。LAC已经确认， LAP已经添加。
		  >fencing机制：保证多写者的一致性。
          >Speculative机制：平滑的可预测的p999延迟。
		 >读写代理：负责分区、转发/路由和缓存。 
		 >Kestrel: 支持item级别的事务。
		 ><LedgerID, entryID>构成了唯一的记录ID
	 >用户画像识别黑产账户：
	  >ip维度、聚类维度(Adaboost方法)：来分类。若干个弱分类器的综合。
		>Bagging方法：提高学习算法准确性。
	   >光是ip的频率、次数限制不够：代理IP是主流。
	    >识别是不是代理IP：协议扫描方式。
		 >反向探测：是否开通了80,8080等端口，显然一般用户是不会的。反向查看是否有>10000的端口。爬虫爬这些ip记录数据。
		 >HTTP报头：X_Forwarded_For: 有这个信息就一定是代理IP.
		 >Keep-Alive报文：如果带有Proxy-Connection： 是代理ip.
		 >
	  >大数据处理平台：收集埋点数据，存储在平台。供线下和线上分析。
	 >多终端数据一致性：多人协作编辑
	  >消息数据库：总量和增量(各方面的增量)(各端相对的增量---离线后的新增版本量，未看消息的量)
	 >push消息系统：
	  >单通道多App复用：
	  >go语言实现push系统：	长连接
   	   >指标：
 	    >单机的连接数指标：每条连接的tcp协议栈占用4k内存。>12G内存理论上300W连接都ok(服务器可达64G,256G)。弱网络下客户端每秒短线率：。用户心跳包每300s发送一次。单播和多播、广播的数据的转发。
		>内存使用量指标：全双工/半双工，不同的开销，不同的buffer大小配置。 
	    >每秒消息下发：2W QPS
	   >推拉结合：推消息通知，拉消息内容。
	   >IP连通性：
	   >virt/res:
	   >debug工具和profiling工具：
	  >raft:
     >雪球高可用架构：
	  >租用IDC机房自建私有云：每天4亿api调用。单机QPS 5W
	  >服务化拆分和治理：Twitter开源的finagle RPC
      >Gitlab开发、Jenkins打包、zabbix监控系统/openfalcon，confluence、jira
	  >数据来源：交易所的数据公司，交钱-签合同即可得到。
	  >多个JVM之间数据同步：Hazelcast In-Memory Data Grid的replication map	 或者sharding redis
	  >开关降级系统：	  
	  >netflix的archaius:	  
	  >抢占式调度：
	  >单进程瓶颈：
	 >美拍短视频：
	  >动态服务配置和发现：etcd 
	  >客户端负载均衡、故障恢复：节点健康状况检测、metrics埋点
	  >结合统一的TraceID来跟踪服务的分布式调用链路的状态。Tracer	
	  >视频上传：基于CDN走动态加速、分片上传	  
	  >数据存储：专用的分布式对象存储	  
	  >视频播放：Http Range; HLS方式播放。网络链路优化。	  
	  >数据编码格式：H.265	  
	  >视频处理：尽量客户端处理。服务端审核转码、抽帧。	  
      >架构：
	   >设计：分而治之、化繁为简:开放扩展、柔性可用
	    >模块内聚、模块之间解耦：依赖影响问题。
		>协议：http方式跨语言通信：负载均衡、节点探测、并发保护
		>扩展：向前兼容
		>属性字段：序列化为protocol buffer数据。
		>性能问题：降级策略、运维配套。
		>兼顾：开发效率、系统架构、部署和运维成本等方面平衡。	避免过度设计或者架构上支撑不了业务。
	   >容灾：资源容错、CDN容错：云存储容错、域名劫持容错
	    >自身服务容灾：多级cache, cache的分片hash的方式。核心的cache资源还有主备节点(缓存集群每个节点上都有)，避免单一节点挂掉之后穿透会压垮后端DB。对于热点资源访问量很大的情况下，在之前加一层L1的LRU cache来规避和缓解这一问题。
		>CDN容灾：接入多家供应商进行互备(检测服务厂商的链路和服务状态，有问题时通过DNS进行区域的切换)。	选择CDN厂商：关注可用性、节点和布点和链路状况，回源量、资源冗余量、晚高峰的链路状况，对多媒体是否有单独的优化。
		>云存储容灾：两家互备。上传先走主的云服务，失败则走备份的云服务。服务端层面也可以控制整体降级的方式：主云服务直接降级读写备份云服务。
		>服务端带宽压力：p2p+CDN的方式来缓解。p2p有防火墙和节点网络质量的影响。
	   >部署：分级隔离、资源冗余：
	    >CDN层面：不同厂商不同地域下的资源冗余。
		>云服务的冗余：是否式一个可自动动态伸缩调度的场景。
	   >监控：链路追踪、监控统计
      >
     >微博“异地多活”部署：多机房部署。关键就是多机房数据同步。三个层面的数据：消息、缓存、数据库。
	  >好处：异地灾备、提升访问速度、降低部署成本。流量均衡、在线压测。
      >跨机房消息同步方案：借助MYSQL从库的触发器将增删查事件转换为消息，跨机房消息同步组件WMB(Weibo message broker) 北京机房和广州机房有40ms延迟。专线问题。
	  >MYSQL/HBase多机房数据同步：
	  >异地部署：预览、发布、测试、监控、降级多方面。
	  >数据同步层面：消息、缓存、数据库。消息对缓存更新。而消息来源于数据库。未采用数据库双写，而是采用主从同步的方式。异地2个机房足够。
	   >消息跨机房分发可以保障：web层部署到离用户更近的机房。
	 >Google的高可用部署：
	  >可用性的指标：99.9%时间都可用(一年)才是基本上可用。每年8h不可用。
	  >可用性的的保障：系统的自愈。架构的容灾、容错设计、灾备系统的完善。人为登陆VPN敲命令就慢了。
	   >提高冗余度，多实例运行，用资源换可用性：N+2设计。滚动更新。即假如服务至少需要1个实例跑。那么加一个来防备实例丢失。由于实例升级、发布过程中的实例不可用，所以在升级过程中避免实例丢失还需要一台来保障升级过程的可用和容许升级失败。
	    >两地三中心：
	   >流量控制系统：按API\用户类型\用户来源进行调度,隔离(避免冲突，资源消耗大影响其他)。
	   >灰度发布：1%--10%--100%发布之后还能回滚--基本需求。
	   >数据存储格式：protobuf这种支持数据版本，前后兼容。
	   >Puppet:
	 >分布式redis架构设计：
	  >设计为一个可以水平扩展的分布式缓存服务：
	  >Redis Cluster缺点：数据存储和逻辑模块耦合在一起。
	  >Codis: 将分布式逻辑写在Proxy无状态层，底层存储引擎还是Redis, 数据分布状态存储在zk/etcd上。Proxy本身也是可以动态扩展的。
	  >不读写分离：保障一致性。因为redis replication是主从异步复制。会在master崩溃而没来得及复制的从节点提升为master后丢失一部分数据。除非同步复制。
	   >分布式事务：要解决的四大问题：读成功的标准、写成功的标准、节点数据版本一致性的方案、事务回滚的实现(事务三阶段：打开-提交-关闭)(WAL且分发到中心存储，以便崩溃重做提交了但还未持久化的部分)
        >跨行事务：因为行在不同的节点上。如果此时多个这种跨行事务在提交执行，交叉行如何处理。
		>两个分布式操作一起成功或者一起失败：各个分布式操作的数据所在的节点是不一样的。并且要保障有：单个操作的都成功，就是整体的成功！根其他事务是否操作了数据没关系。如微博关注者数量和关注主题数。量增而不是倍增。操作前的数据视图，操作过程中的数据视图。队列？cache暂存?
	   >强一致性存储：zk或者raft
	   >Slot迁移：
	   >HA保障：代理层的HA：	都是使用类似zk的有序节点列表/可用节点列表：一个挂了直接下一个升级为可用节点。
	   >高性能*分布式事务：用原子钟搞定Spanner, Spanner上构建了SQL查询层F1。即NewSQL的公开设计系统。
		>Spanner: 跨数据中心的复制和一致性保证(Paxos实现)。
	   >google任意业务类型开发的基础支撑：可扩展的KV数据库---BigTable。高性能的支持分布式事务的和SQL查询接口的分布式关系型数据库----F1-Spanner。
	   >zk: 事件同步、可用节点维护、多节点顺序协调。
      >redis冷备的数据库的迁移：使用基于RocksDB的磁盘存储引擎。os的COW机制复制。
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 --反问他技术挑战在哪里?去年年终发了多少？
 
参考资料：编程珠玑..。。allthingsdistributed(无服务器构建，什么都用云上的)