---------读书战略：自顶向下，从应用层到底层细节。先熟悉的常用的，后底层的不常用的。精读好书---《深入理解系列》
--------es的处理思想都对应有 相应的“某种举动 及其导致 的问题”
>需求背景-痛点陈述：现实开发中遇到了什么痛点导致XXX的开发？  
>那么痛点的原因、产生的条件：分析是什么环境、什么动作 什么效果什么目的 等精准形容词的事实描述 导致了痛点的必然发生，难以避免？。条件-痛点。原因-结果。
>则可以消除痛点的最简单的精准事实陈述是什么：修改“条件-痛点”陈述的哪一部分就可以导致没有痛点产生。 要做的根本事情是什么：
>那么新陈述表明的解决动作是什么：
>新情况的新痛点是什么：新举动、新环境会产生的新痛点描述出来， 继续上述4条操作。
>学习要有战略和格局：过于零散、孤立、末支、叶子的知识点就没必要化太多时间，懂得放弃。聚焦在根节点、枢纽节点、产生分支的节点、主干知识点、枢纽知识点、关联到很多知识点的知识点上。
 >对于主干知识点：要有全新的认识视角和进行精细的描述，大量的提问和好奇和进行必要的实验以获取支撑观点/导出观点的数据。

 
>举动-痛点：搭建高并发、高可用系统
  >解法/处理思想： NewSQL , Serverless, 云，微服务
     >互联网系统的基本要求：高可用。
	 >分布式日志篇：
	  >日志：只追加、严格有序的记录序列。很有效的数据结构。常用来解决分布式系统的问题。
       >实现key-value数据库的CAS强一致性：并非适用paxos二阶段一致性算法。而是利用客户端可以多个，处理端可以多个，但是数据目的地可以只有一个，就是日志(也可以是kafka), 来协调操作排队，然后各个数据存储端读取这个顺序化的日志/kafka流，来更新自己的数据。Pub/Sub模式。
       >持久化、多副本、强一致性：低延迟、高通量、可扩展
        >基于持久化和强一致性的服务：
		 >日志系统核心负载：追加write, 尾部读取tailing-read；要求低延迟。从比较早的位置读--catch-up read ;关注吞吐量。
	     >Apache BookKeeper: I/O分离，并行复制、简单的一致性模型。方便用于构建分布式日志。
		  >clients-bookie-zk注册管理中心:客户端创建Ledger, 挑选一定的bookie, 构成一个Ensemble, 客户端并行发送Entry给Ensemble里的所有bookie， 收到大多数的返回就认为写入成功了，就返回给客户端了；这个确认是严格按照EntryID进行的，小的先确认，从而保证日志的严格有序性。Ensemble Change可以将因为有一些bookie失败而从bookiePool里再增加一些bookie来补充----来保证写操作的高可用性。LAC已经确认， LAP已经添加。
		  >fencing机制：保证多写者的一致性。
          >Speculative机制：平滑的可预测的p999延迟。
		 >读写代理：负责分区、转发/路由和缓存。 
		 >Kestrel: 支持item级别的事务。
		 ><LedgerID, entryID>构成了唯一的记录ID
	 >用户画像识别黑产账户：
	  >ip维度、聚类维度(Adaboost方法)：来分类。若干个弱分类器的综合。
		>Bagging方法：提高学习算法准确性。
	   >光是ip的频率、次数限制不够：代理IP是主流。
	    >识别是不是代理IP：协议扫描方式。
		 >反向探测：是否开通了80,8080等端口，显然一般用户是不会的。反向查看是否有>10000的端口。爬虫爬这些ip记录数据。
		 >HTTP报头：X_Forwarded_For: 有这个信息就一定是代理IP.
		 >Keep-Alive报文：如果带有Proxy-Connection： 是代理ip.
		 >
	  >大数据处理平台：收集埋点数据，存储在平台。供线下和线上分析。
	 >多终端数据一致性：多人协作编辑
	  >消息数据库：总量和增量(各方面的增量)(各端相对的增量---离线后的新增版本量，未看消息的量)
	 >push消息系统：
	  >单通道多App复用：
	  >go语言实现push系统：	长连接
   	   >指标：
 	    >单机的连接数指标：每条连接的tcp协议栈占用4k内存。>12G内存理论上300W连接都ok(服务器可达64G,256G)。弱网络下客户端每秒短线率：。用户心跳包每300s发送一次。单播和多播、广播的数据的转发。
		>内存使用量指标：全双工/半双工，不同的开销，不同的buffer大小配置。 
	    >每秒消息下发：2W QPS
	   >推拉结合：推消息通知，拉消息内容。
	   >IP连通性：
	   >virt/res:
	   >debug工具和profiling工具：
	  >raft:
     >雪球高可用架构：
	  >租用IDC机房自建私有云：每天4亿api调用。单机QPS 5W
	  >服务化拆分和治理：Twitter开源的finagle RPC
      >Gitlab开发、Jenkins打包、zabbix监控系统/openfalcon，confluence、jira
	  >数据来源：交易所的数据公司，交钱-签合同即可得到。
	  >多个JVM之间数据同步：Hazelcast In-Memory Data Grid的replication map	 或者sharding redis
	  >开关降级系统：	  
	  >netflix的archaius:	  
	  >抢占式调度：
	  >单进程瓶颈：
	 >美拍短视频：
	  >动态服务配置和发现：etcd 
	  >客户端负载均衡、故障恢复：节点健康状况检测、metrics埋点
	  >结合统一的TraceID来跟踪服务的分布式调用链路的状态。Tracer	
	  >视频上传：基于CDN走动态加速、分片上传	  
	  >数据存储：专用的分布式对象存储	  
	  >视频播放：Http Range; HLS方式播放。网络链路优化。	  
	  >数据编码格式：H.265	  
	  >视频处理：尽量客户端处理。服务端审核转码、抽帧。	  
      >架构：
	   >设计：分而治之、化繁为简:开放扩展、柔性可用
	    >模块内聚、模块之间解耦：依赖影响问题。
		>协议：http方式跨语言通信：负载均衡、节点探测、并发保护
		>扩展：向前兼容
		>属性字段：序列化为protocol buffer数据。
		>性能问题：降级策略、运维配套。
		>兼顾：开发效率、系统架构、部署和运维成本等方面平衡。	避免过度设计或者架构上支撑不了业务。
	   >容灾：资源容错、CDN容错：云存储容错、域名劫持容错
	    >自身服务容灾：多级cache, cache的分片hash的方式。核心的cache资源还有主备节点(缓存集群每个节点上都有)，避免单一节点挂掉之后穿透会压垮后端DB。对于热点资源访问量很大的情况下，在之前加一层L1的LRU cache来规避和缓解这一问题。
		>CDN容灾：接入多家供应商进行互备(检测服务厂商的链路和服务状态，有问题时通过DNS进行区域的切换)。	选择CDN厂商：关注可用性、节点和布点和链路状况，回源量、资源冗余量、晚高峰的链路状况，对多媒体是否有单独的优化。
		>云存储容灾：两家互备。上传先走主的云服务，失败则走备份的云服务。服务端层面也可以控制整体降级的方式：主云服务直接降级读写备份云服务。
		>服务端带宽压力：p2p+CDN的方式来缓解。p2p有防火墙和节点网络质量的影响。
	   >部署：分级隔离、资源冗余：
	    >CDN层面：不同厂商不同地域下的资源冗余。
		>云服务的冗余：是否式一个可自动动态伸缩调度的场景。
	   >监控：链路追踪、监控统计
      >
     >微博“异地多活”部署：多机房部署。关键就是多机房数据同步。三个层面的数据：消息、缓存、数据库。
	  >好处：异地灾备、提升访问速度、降低部署成本。流量均衡、在线压测。
      >跨机房消息同步方案：借助MYSQL从库的触发器将增删查事件转换为消息，跨机房消息同步组件WMB(Weibo message broker) 北京机房和广州机房有40ms延迟。专线问题。
	  >MYSQL/HBase多机房数据同步：
	  >异地部署：预览、发布、测试、监控、降级多方面。
	  >数据同步层面：消息、缓存、数据库。消息对缓存更新。而消息来源于数据库。未采用数据库双写，而是采用主从同步的方式。异地2个机房足够。
	   >消息跨机房分发可以保障：web层部署到离用户更近的机房。
	 >Google的高可用部署：
	  >可用性的指标：99.9%时间都可用(一年)才是基本上可用。每年8h不可用。
	  >可用性的的保障：系统的自愈。架构的容灾、容错设计、灾备系统的完善。人为登陆VPN敲命令就慢了。
	   >提高冗余度，多实例运行，用资源换可用性：N+2设计。滚动更新。即假如服务至少需要1个实例跑。那么加一个来防备实例丢失。由于实例升级、发布过程中的实例不可用，所以在升级过程中避免实例丢失还需要一台来保障升级过程的可用和容许升级失败。
	    >两地三中心：
	   >流量控制系统：按API\用户类型\用户来源进行调度,隔离(避免冲突，资源消耗大影响其他)。
	   >灰度发布：1%--10%--100%发布之后还能回滚--基本需求。
	   >数据存储格式：protobuf这种支持数据版本，前后兼容。
	   >Puppet:
	 >分布式redis架构设计：
	  >设计为一个可以水平扩展的分布式缓存服务：
	  >Redis Cluster缺点：数据存储和逻辑模块耦合在一起。
	  >Codis: 将分布式逻辑写在Proxy无状态层，底层存储引擎还是Redis, 数据分布状态存储在zk/etcd上。Proxy本身也是可以动态扩展的。
	  >不读写分离：保障一致性。因为redis replication是主从异步复制。会在master崩溃而没来得及复制的从节点提升为master后丢失一部分数据。除非同步复制。
	   >分布式事务：要解决的四大问题：读成功的标准、写成功的标准、节点数据版本一致性的方案、事务回滚的实现(事务三阶段：打开-提交-关闭)(WAL且分发到中心存储，以便崩溃重做提交了但还未持久化的部分)
        >跨行事务：因为行在不同的节点上。如果此时多个这种跨行事务在提交执行，交叉行如何处理。
		>两个分布式操作一起成功或者一起失败：各个分布式操作的数据所在的节点是不一样的。并且要保障有：单个操作的都成功，就是整体的成功！根其他事务是否操作了数据没关系。如微博关注者数量和关注主题数。量增而不是倍增。操作前的数据视图，操作过程中的数据视图。队列？cache暂存?
	   >强一致性存储：zk或者raft
	   >Slot迁移：
	   >HA保障：代理层的HA：	都是使用类似zk的有序节点列表/可用节点列表：一个挂了直接下一个升级为可用节点。
	   >高性能*分布式事务：用原子钟搞定Spanner, Spanner上构建了SQL查询层F1。即NewSQL的公开设计系统。
		>Spanner: 跨数据中心的复制和一致性保证(Paxos实现)。
	   >google任意业务类型开发的基础支撑：可扩展的KV数据库---BigTable。高性能的支持分布式事务的和SQL查询接口的分布式关系型数据库----F1-Spanner。
	   >zk: 事件同步、可用节点维护、多节点顺序协调。
      >redis冷备的数据库的迁移：使用基于RocksDB的磁盘存储引擎。os的COW机制复制。
	 >屁大的事也能说的天花乱坠：是自信和想象力。而不是把不好说给别人听---丧气的事别人听了也丧气也不开心。
	 >业务系统插件化改造：系统分为：引擎--插件两部分。
	  >引擎：插件规范：解析插件，运行插件。插件管理。	
	  >插件：指定了产品需要的各种逻辑。插件注入引擎，完成。热插播，引擎不用重启。
	  >服务：接口jar和实现jar.
	 >IM系统的更多设计启发：TCP长连接，HTTP短连接。
	  >XMPP协议：不建议。
	  >SIP:
	  >推拉模式：
	  >协议设计：
	   >语义：定义做什么
	   >语法：特定范围语言描述怎么做
	   >时序：操作的先后
      >协议分层：
	   >应用层：文本协议、二进制协议、流式XML。。首尾标记。只有首标记。
	   >安全层：自定义密钥， AES方式加密。
	   >传输层：TCP
	  >聊天室：	HTTP消息连接：1.客户端和服务端维持一个Http连接：90s服务器超时返回空后，客户端再次发起http连接。2.如果有消息发送到了群里，那么服务端将消息通过这些连接分别将消息返回给相应的客户端，客户端收到后再次发起一个连接。
	 >海量数据非关系型分布式存储数据库：360
	  >存储数据的节点DataServer: 获取存活的DataServer---QConf   。 数据节点上，多个分区管理器。每个管理器上：一个leader, 一个备份，其他woker。共享数据引擎(基于LevelDB开发)和binlog.
	   >分布式系统多副本策略：无主从结构：W+R>N即可(多写几个；强一致性；读性能不佳；写性能也不佳；只是一致性佳)。有主从：先写主,wal,binlog再将数据同步给从节点/副本(最终一致性)。
	    >分区容错上：都必须超过一半的节点存活才能堆外提供服务。(选举和W导致)
		>Vector Lock: 
		>Mnesia:
		>MongoDB:扩容和数据膨胀的问题。
	 >广告系统：基于受众的精准投放，实时监控受众特征和广告转化率。
	  >广告投放过程：web系统调用方向广告系统发送 竞价请求，参数包括：广告位URL,用户cookieID，所在网站网页，等信息。广告系统返回是否曝光、要出的价格，
	  >广告点击率的分析和影响投放：客户在哪里出现，
	  >网站的用户是什么产品的受众：
	  >受众-广告位-广告：精准分析受众会在哪里出现，何时何地；对应的广告位有哪些；何时何地投放多久，实时监控该地受众量、受众特征、广告转化率。
	  >广告受众-媒体网站-RTB服务商-DSP系统(多个)：根据用户、媒体网站网页特征，返回展示什么广告的信息。
	  >Tair:
	  >mr离线计算-spark批处理-storm流式计算：
	 >亿级规模的es优化实战：
	  >索引性能：分词插件-IK分词？副本数量、碎片程度、存储SSD、各种缓冲区大小、routing策略方式、
	   >情况特征：各种参数是多少。
	   >常见方案：分索引而非增加分区：。JVM堆空间<32G
	   >插件工具：Kopf
	   >Aggs: not Facet
	  >查询性能：
     >微博Feed分布式存储方案：
	  >先sharding: 如按照范围，按照hash。数据量满了之后，可以re-sharding, 对一个分区进行再次划分为多个分区，此时采用的值则是对%1024得到值的进一步的/1024, 求倍数(余数虽然相同，但是倍数不同)，根据倍数来对一个新的数%取模来决定存放在哪个地点；同理可以这样一层一层的re-sharding下去。
	   >UID+权重的方式进行hash, 来均衡不同用户的不同量的数据。权重接近的用户落在不同的库里。即vip和非vip在一起，大号小号在一起。
	   >时间维度hash: 用户注册时间维度：
	   >性能上：sql优化-sql拆解、增加缓存、增加索引、增加统计表。分库、分表。
     >数据库一致性问题：
	  >对mysql:	强同步模式或者异步复制模式。强同步，要求redolog复制到备机之后才成功返回客户端，导致备机宕机，主机无法继续提供服务，牺牲了可用性(主机受备机的影响)。且跨机房同步延迟过大，从而跨机房的主备同步不实用。异步复制，则主机宕机，备机会丢失数据。另一种方式就是主机写日志到一个专门的分布式数据库。
      >高可用的需求：数据不丢失，服务持续可用，自动的主备切换。
	   >paxos协议进行数据同步：paxos目标：使得多数的acceptor的数据一致，一致变为proposal的提案内容。OB的paxos算法和事务redolog库紧耦合。
	   >最大Commit原则：
       >实际场景-数据库同步Redolog: 
	   >Raft协议：对网络抖动的容忍度低一些。相比multi-paxos算法。抖动就是：突然挂了突然重启。
     >OpenRestry: 用在HTTPProxy, APIServer,WebApplication。是一个基于Nginx的C模块，将Lua语言嵌入到Nginx服务器中。甚至可以用来实现分布式存储的后端。
	  >特点：用同步的代码逻辑实现非阻塞的调用。单进程内有LRU cache 和进程间的share DICT cache;
	  >高性能服务器的开发：一两个月做出来的API可以达到Nginx C模块的性能。	
	  >开发内置在Nginx上的K-V数据库：+Nginx C模块。
	  >一种技术组合：Linux + OpenRestry + Redis + Postgres 而没有使用PHP和Sqllite 也没有使用Apache(同步多进程模型), 
      >第二种技术组合：Nginx + (Nginx的fast_cgi_cache);;Golang可以尝试。
	  >测试用例丰富：每一个功能点和bug都有测试用例。systemtap源码动态追踪。
	  >CPU占用百分之百：进行不修改代码、不重启服务，无感知的调试：定位阻塞系统的调用位置。
	   >火焰图：把采样数据重新整理，on-CPU火焰图。off-CPU火焰图。平坦的山峰--性能瓶颈。
	  >NginScript: 把javascriptVM嵌入到了Nginx中， location  / { js_run  } 但是没有即时编译器和垃圾回收器。
	  >反向代理和负载均衡之外：在线实时修改更新集群的配置。
	  >高性能WAF：
	 >商品详情页：键值对存储系统。 
	  >系统耦合度：导致一个模块的变化引起另一个模块的变化
	  >系统性能依赖：称为瓶颈的地方。
      >基于Redis改造的加了持久化引擎的KV系统：
	  >数据异构：
      >数据原子化处理：
	  >数据聚合：
	  >数据存储：
	  >多机房多活：机房CND+LVS+HAProxy+接入层Nginx+业务层Nginx
	  >线上压测：TCPcopy直接线上导流。多层翻倍放大流量。
	   >测试用例: 随机读和随机写：LevelDB和RocksDB都会读写混合时抖动。。LMDB读写效率都更高，但是磁盘达到了瓶颈，归并时，基本没有抖动。
	  >键值存储数据库：LMDB采用了mmap内存映射-效率更高。
	  >分片逻辑维护：Twemproxy
	 >大促应对：
	  >全链路全流量线上压测：读业务和写业务分开。DDOS工具模拟压测。
	   >加量：检测线上响应情况、订单量情况、各个服务器缓存数据库的实际负载情况。
	   >购物车里加热数据缓存：SKU添加。
	   >接单：直接写数据库一份数据，然后异步状态机任务会读取进行数据异构到管道服务里，给其他服务消费而落盘到其他具体的数据库表里。
	  >限流：保护后端系统。多余的流量不处理。
	   >秒杀系统：分流和限流的典型案例：通过IP+PIN风控数据。
	    >限流：	1s内提交了多少次
	  >分流：
	  >容灾降级：机房容灾降级、网络容灾、应用容灾、(业务层面降级：降低非强依赖的服务，枝丫服务)
	  >监控完善：网络监控、机器性能监控、业务监控、订单量监控、登陆量监控、库存监控、购物车监控、优惠券监控。mysql落地存储。
     >秒杀系统：业务架构设计。对于高性能：分流、分级(先Nosql--后到mysql)解决压力问题。
	  >限时抢购&限量抢购：商品按照用户地点远近等排列。
	   >自建商品库：Mysql存储。
	   >自建抢购库：可以回答商品还有没有的问题。NoSQL存储。
	  >业务时序图：资源方、数据层、运营层、业务层。商品入库，运营配置活动场次和商品和量。
					用户、业务层、抢购计划表、抢购库、资源方。用户开始抢购。
					抢购计划表、商品库。活动结束后，剩余的商品入库。
	  >对账机制：成功的事务，和资源方成功支付的对账。
	  >防刷机制：账号体系，购买消费记录。用户画像分析。
	  >整个过程：PM想法、产品提需求、设计方案-考虑未来一定会遇到的并发可用性-性能-一致性问题、发起评审-成功后开始写代码。
	 >Lamda架构与推荐在电商网站实践：。实时处理范式，批处理范式。更好的架构： Kappa架构。Spark streaming, Storm的DRPC
	  >Lamda架构：实时大数据系统关键特性的架构：高容错、低延迟、可扩展。
	   >融合了的架构原则：不可变性、读写分离、复杂性隔离、
	   >可集成：Hadoop\Kafka\Storm\Spark\HBase 
       >对系统的抽象：Query=Function(all data)
	   >2个假设：不可变假设：数据不可变如日志。Monoid假设：function需要满足结合律，如：query=function(data/2) + function(data/2)
	   >架构分层：
	    >批处理层：新数据流到不可变集合里。
		>实时处理层：新数据另一方面流到实时处理流里。
		>服务层：将上述两个结果查询返回给前端。
       >优点：实时、可重计算、容错、复杂性隔离-读写分离。
	  >Netflix推荐架构：
	   >批处理层：从Hive,pig数据仓库，离线计算推荐模型，生成离线推荐结果。
	   >实时处理层：从消息队列实时拉取用户行为数据和事件，生成在线推荐结果。
	   >服务层：结合离线、在线推荐结果，为用户生成推荐列表。
	  >一号店6大推荐引擎：
	   >用户意图：实时分析用户行为，存储短期爱好。
	   >用户画像：长期用户数据，存储。
	   >千人千面：群体分析，所属群体。
	   >情景推荐：季节、节日、天气特定情景做推荐。
	   >反向推荐：根据商品购买周期等反向生成推荐结果。--提示购买。
	   >主题推荐：用户与主题的匹配度，进行推荐。
		>存储设计：HBase, KV存储。主从方式进行读写分离。flush,split, compaction会影响可用性。region重新分配期间也不可用。优化：Region访问量少的要合并。Request的分流处理，避免脚本split
		 >HBase问题之一：HBase lock hang. 由于HDFS客户端没有设置读超时。	
		 >Mahout,Mlib推荐引擎库：
		 >Kafka问题之一：Close_wait
	 >压测工具构建：
	  >读取线上日志：多线程模拟用户请求。	
	  >数据聚合：InflunxDB:
	 >基于Docker容器的混合云迁移实战：
	  >场景：短期峰值应对、常规部署、离线计算。公有云的优势更加明显。调度能力更强：5min千级别的节点弹性调度。
	  >流量规划：
	  >整体技术：Docker + SWarm + Consul 
	  >Docker Machine要求：SSH.. Puppet方案。CI为变更推送到pluto系统的通道。
	  >通过描述文件定义虚机的配置：
	  >网络选择：VPC+VPN+专线：
	  >Consul：用来做节点发现。raft协议保证server之间数据的一致性。gossip协议管理成员和传播消息。一致性模式选择：default。。long polling机制，UDP协议。etcd
	  >容器调度：Swarm。 Filer机制实现调度算法----选择出合适的主机的算法。
	  >业务调度：一键扩容，一键缩容。
	  >自动打包工具：pom.xml  , dockerfile工程，直接打包为对应jar/war, 或者镜像。一键打包。
	  >监控告警解决方案：对IT基础架构的整体监控和预警。
	   >系统级监控：CPU,磁盘，网络
	   >业务级监控：JVM监控，业务系统吞吐量，平均耗时、单机性能，Slow监控-业务系统中最慢的性能瓶颈。
	   >资源监控：命中率，QPS，连接数，上行/下行带宽
	  >缓存数据同步：
	  >Docker Registry底层存储：Ceph分布式文件系统...HOST网络。
	 >容器实战：迁移部署、动态伸缩。保存os上下文。
	  >操作系统环境：物理机、自建虚拟机、云虚拟机、LXC容器、Docker容器。
	  >构建镜像体系：基本镜像、工程镜像。
	  >分发：借助Ceph
	  >运行：
	   >网络使用模型：bridge, HOST .。修改容器HOSTname, hosts, DNS配置。在容器中提供sshd, 从而ssh登陆容器。日志：物理机上和容器ip相关目录下。
	   >不同机房之间的流量切换：使用DNS做负载均衡。
	   >混合云架构：公有云上部署一定的只读服务。Docker之间的互通采用桥接方案---本质上是一个路由方案/overlay隧道方案。公有云和私有云之间拉专线。
		>发布系统平台：基于ssh分发。构建部署。上游：gitlab, jekins。。本身基于Docker Registry, Docker API
     >使用docker构建		
	  >让每个容器有自己的网络栈：
	  >跨服务器的容器间通信：
	  >访问控制机制：不同应用之间相互隔离，有调用关系的可以通信。
	  >网络模型选择：Docker原生的Bridge模型，原生的Host模型， Weave OVS基于隧道的模型.
       >Calico: 纯3层的SDN实现,基于BPG协议,和Linux自己的路由转发机制,  可以部署在容器,自带基于Iptables的ACL管理组件..可以创建容器的网络栈. 
	    >缺点：容器的网络栈是在容器启动后才进行初始化。
	   >etcd: 可以用来给容器自动分配一个可用IP。
	   >veth接口：用于容器和主机之间通信。设置好容器内的IP,打开IP转发。在主机路由表添加指向此接口的路由。ip link show ; ip addr ; 
	  >吞吐量测试：每秒能发送的字节总数Gb/s
	  >CPU使用率测试：每Gb/s而CPU的使用率。
	  >延迟测试：节点之间交换1byte数据包，OpenStack由于网络虚拟化的缘故延迟稍大。总之，比基于隧道的OVS性能好很多。
	  >增加容器与宿主机路由：
     >芒果TV相关：
	  >容器内存储：Devicemapper, Overlay(适合大量小文件持续写),。容器间数据共享：MooseFS, 
	  >网络方面存储方案：路由类MacVLAN .。。而隧道类方案的缺点：性能低20%， Debug也困难。
	   >在二层做Qos, 按照IP流控。Host模式，方便在云上部署。
	  >存储：
	  >SDN网络二层隔离：
	  >Docker平台上的监控系统：cAdvisor ;; ; InflunxDB
	 >微博Docker混合云架构：
	  >面临挑战：瞬间峰值高；
	  >传统方案：申请足够设备保证冗余。降级非核心周边业务；缺点：成本高、水平扩容耗费时间久；
	   >基础运维从采购得到新机器-->录入CMDB-->根据业务运维需求，上架到相应的IDC、机架，操作系统安装、网络配置，-->分给相应的运维。--->运维对机器初始化配置、服务部署--->check挂到负载均衡上--->引入流量--->过期下架、坏了保修，替换。
	    >缺点在硬件资源使用率和调度方面。
	  >Docker Container的基础设施：阿里云-VM架构(连公有云必然专线VPC--否则网络质量堪忧)，私有云-裸机架构。
	   >Docker在裸机上的部署架构+改进版的Docker Registry + 负载均衡组件Nginx Upsync模块：构建Docker Container平台基础架构：
	    >裸机方案：ip+port定义一个唯一的Container服务，
	    >Docker Registry: 官方部署，部署在分布式开源存储平台Ceph
	    >Nginx Upsync模块：处在nginx中，nginx的worker从Consul拉取配置，而docker server事先注册到Consul, 然后nginx可以转发到这些docker server；
	   >资源管理：mesos, 调度工具swarm..。。运算资源共享池，业务可以释放和申请。多租户管理机制。
	    >5min之内扩容数千个节点：
	  
	 >运维保障：
     >两万台以上服务器的配置管理：QConf
	  >读验证：MD5验证--读取内存序列化数据。
	  >父子进程Keep-alive方式应对Agent进程异常退出的情况：
	  >内存数据同步到本地：gdbm
	  >同类产品：淘宝diamond, 微博vintage  百度disconf, 	前两者数据存在mysql/redis上，通过客户端拉取获得---通过MD5方式验证避免传输整个配置值。后者zk通知，且存数据到mysql
      >问题：zk死掉后，新增的zk节点如何被感知到。zk要重启吗？
	  >镜像后写还是边读边写：
	  >zk客户端：3-4千估计。	
	 >CAT监控系统：实时和接近全量
      >性能指标、健康状况、监控告警：
	  >需求背景：大量报错、异常日志、错误定位耗时。
	  >ebay内部的CAL系统：吴其敏。
	  >原型和理念：快速发现故障、快速定位故障、辅助进行程序性能优化。
	   >要求：
	    >实时处理：
		>全量全采：
		>高可用：所有应用倒下了，监控还站着。以便故障还原和问题定位。
	    >故障容忍：监控系统本身的故障不影响业务正常运转。
		>高吞吐：高吞吐处理能力。
	    >可横向扩展：支持分布式、跨IDC部署。
		>不保证可靠：容许消息丢失。是重要trade-off， 99.99%可靠，可靠系统和不可靠系统设计区别非常大。
	   >模块：
		>CAT-Client: 业务和中间层埋点的底层SDK
		>CAT-consumer: 实时分析从客户端获取的数据。
		>CAT-home: 和consumer部署在一个JVM中
	   >多机房整体结构图：
	    >路由中心：负责提供上报信息路由到CAT服务端的地址。
		>机房内：原始信息的HDFS集群
		>CAT-home:会跨机房收集多个consumer的信息，数据合并展示给用户。
	   >设计架构：
		>客户端设计：将所有的监控请求作为一个监控的上下文存入线程变量；
		 >线程上下文：ThreadLocal存放一个监控树结构的对象。
		 >异步内存队列：业务线程结束时，ThreadLocal里的对应这个线程的监控树对象放入异步内存队列中。
		 >消费线程：将队列里的数据异步发送到服务端。
		 >监控树对象：包括各个部分：SQL节点、cache节点，等。
		>API设计：监控和性能分析的。
		 >一段代码的执行时间：URL执行耗时，SQL执行耗时。
		 >一段代码的执行次数：比如程序抛出异常的数量。
		 >定期上报核心指标：JVM内存、GC平均耗时和次数。
		 >监控业务指标：订单数，交易额，支付成功率。
		>核心监控对象：
		 >Transaction/Event/Heartbeat/Metric
		>序列化和通信：
		 >自定义序列化协议：高效。
		 >基于Netty实现NIO的数据传输。
		>日志埋点：日志质量决定监控的质量。
		 >以问题为中心：不符合预期的地方，抛出异常的地方等。。不仅仅只是收集一下数据，而是上报问题。
		>缺点之处：ThreadLocal内部监控对象的节点数，如果在线程中有循环，每个循环又sql查询，那么可能会导致节点数太多而OOM
		 >MappedByteBuffer: 文件内存映字节射缓冲区，注意是一个字节缓冲区。但是不同于byte[]数组存在堆中，这个是通过Unsafe.allocate()分配的堆外空间,将数据写入这里会更快地被转移到文件/更高效的持久化--而文件通道无法感知到MappedByteBuffer里的修改改动(且数据可以修改；而零拷贝方式的DirectByteBuffer则只能读不能修改；而HeapByteBuffer就在堆上)，要手动释放(或者FullGC的时候释放)。
		 >Page Cache的锁竞争：
	    >服务端：100台物理机计算，35台物理机存储。每天处理100TB数据，单台高峰期110Mbps	。每秒300w消息要处理。
		 >消息接收：接到上报就返回。采用Netty的NIO实现。先放到本地内存队列，然后有一个线程会消费它来分发给某个消费队列---对应有消费线程在消费(可以一个消费队列多个消费线程)。
		 >消息存储：先存到本地磁盘，后异步上传到HDFS文件。
		>实时分析：报表生成：将消息按照时间段分片，一个小时为一个分析单位，产生一个报表，滚动分析。
		>报表模型的增量计算：计数、计时、关系处理。
		 >算数计数：count, sum, avg, max,min,吞吐tps,标准差std
		 >集合计数：95线--95%的请求的平均完成时间。
		>报表建模：将5个维度组织成深度为5的树：应用-机器-Type-Name-分钟级分布情况。从根节点开始，逐层往下进行。 
		 >每个报表单独一个线程：
		 >Maven PLugin自动生成报表模型：报表可以合并，剪裁。使用访问者模式。
		>性能分析报表：
		 >Transaction: 一段代码执行时间，次数
		 >Event: 一段代码执行次数。
		 >Problem: 系统可能出现的异常，包括运行较慢的程序等。
		 >Heartbeat: jvm内部一些状态信息，memory, thread等。
		 >Matrix: 一个请求调用链路统计
		 >RPC: SOA系统关于RPC调用的报表
		 >Cache: 缓存使用分析统计
		 >Dependency: 系统之间实时调用依赖关系等。
	    >故障发现类报表：历史数据滑动窗口得到的基准曲线，和实时调用统计曲线：差值比较进行故障检测。
		 >系统报错大盘：实时数据库大盘，服务大盘，缓存大盘。
		>存储设计：消息ID格式：四部分：应用名-机器ip-小时-递增值
		 >批量压缩和随机读：
		 >分布式调用里，RPC消息串起来的问题：
		 >消息存储是最具挑战的部分：单物理机每秒100MB数据，既要实时计算，也要压缩后存入磁盘。
		  >Data文件：分段GZIP压缩，每块<64KB,2字节可以表示完块内的地址空间。
		   >一个消息：对应一个48bits的索引，前32bits是文件块偏移地址，后16bits是文件块解压后的块内偏移地址。40亿个文件块。共256TB的数据。一个Data文件。
			>寻找过程：消息前三段确定 一个索引文件，第四段确定索引文件内的地址：n*48bits， 读出48bits的内容就是这个消息在数据文件中的地址。
		  >MVP版本：功能1：知道所有API接口访问量成功率。功能2：实时地在平台上看到异常日志。典型的，特别亮眼的功能。
		>数据质量：
	  >单表Mysql 60亿数据的优化运维：性能堪忧？
	   >缺点：大规模集群方案不成熟。HA方案不完善。备份和恢复方案比较复杂，依赖外部组件。
	   >数据库开发规范：
		>不在数据库中存储图片、文件：表字符集UTF8, emoj表情用UTF8mb4;  decimal存储浮点数。
		>单个索引的字段数小于5：最左前缀匹配原则。索引多导致的额外索引写入和加锁降低了写入能力。
		>尽量不使用存储过程、触发器、函数：这是维护成本和性能隐患。
		>大表的JOIN: mysql优化器处理的太简单。
		>Upate,delete: 建议加上Limit
	    >Online DDL : Facebook OSC实现：触发器+change log, 不锁表，有一定的性能损失。pt-online-schema-change
					  腾讯互娱的DBA实现：修改InnoDB存储格式来实现。数据文件的存储格式，非常重要。
	   >可用性：
	    >无缝切主库：MHA部署结构和方案：双主+单从
	   >数据备份：恢复用。全量&增量，热备-冷备，物理备份-逻辑备份，延时备份-全量binlog备份。
	    >建议方式：热备+物理备份。核心业务：延迟备份+逻辑备份。全量binlog备份。
	   >具体备份方案：备份策略集中调度管理。xtrabackup热备。备份结果统计分析。备份数据一致性校验。采用分布式文件系统存储备份。
	   >恢复过程：两个东西：一个是上次备份的实例。第二个是从上次备份到现在的binlog中关于删除的表的所有增删改语句拿出重做重放。
	   >SQL线程单线程：主从延迟的原因之一。从Relay Log里取数据。I/O线程则往里面写数据。库级别可以多线程。
	   >异步复制和半同步复制：主收到ACK确认。mysql binlog 以deamon的方式。更安全的复制：Group replication;官方多主方案，基于Corosync实现。
	   >主从延迟问题：I/O压力，CPU压力，SQL单线程压力。硬件升级、并行复制、Sharding方案。都很普通直接考虑没有太多技巧。
	    >Seconds behind master不可靠：网络抖动问题。用hearbeat表插入时间戳更准确。
		>binlog格式采用row格式数据一致性更好。
	   >INNODB好处：细粒度锁、MVCC、支持O_DIRECT. 共有的：支持事务ACID,四种隔离级别。undo单独放到高速设备，可以单独进行压缩。默认级别：可重复性读。所以只剩幻读的问题。
		>迁移ibd文件，用于快速单表恢复。
	    >日志文件，redo文件放到机械硬盘，undo文件放到SSD。。SSD稳定性和性能可靠性有大规模验证。多快SATA SSD 做Raid5 , 推荐使用。PCLe SSD
		>atomic write: 不需要double write buffer
		>随机读的文件：undo,顺序读的文件binlog
		>数据安全性更高：比Myisam
		>提高性能：可以改数据库隔离级别。而不只是sql优化，索引添加，分库分表。改存储引擎。
		>死锁问题：
	   >TokuDB: 写入性能好，高压缩比。zabbix后端数据表采用。但有bug
	    >容量大：Innodb中1TB的数据，压缩后只有80G
	    >单表恢复、online DDL: 两种需求和场景都可以。
	   >监控备份和HA: 在小集群上完成。
	   >跟踪数据库table某个字段值发生变化：分析row格式的binlog, 监控binlog,开发自己的工具来解析row格式的binlog。从复制数据的可靠性看，也是row格式的binlog更好，而不是mix
	   >超大表水平拆分：360的atlas
	   >读写分离：读写服务，读写分离。
	   >物理备份：采用xtrabackup热备方案比较好。
	 >微博在大规模、高负载系统问题排查方法：
	  >面对：高并发、大数据量、高负载的业务压力。
	  >排查: 需要哪些工具和数据。已知哪些规律和因果关系。
	   >分布式链路追踪：集群的调用链分析工具。TCPdump/strace/ltrace/btrace/housemd;;;jmap/pmap/jstack/gbd
	  >解决：重启、回滚、扩容、降级、迁移。(打印日志时加上线程id?) 框架和逻辑分离，增加逻辑不用改代码。
	  >日志方案：Scribe, logstash
	 >代码要有组织：解耦、分层。不仅仅是entity/controller/model/service/util这种。而且要factory/proxy/template/builder/observer等, 抽象、接口编程、泛型编程。通用性更强，扩展更简单，代价已经最低。高内聚低耦合
	  >c++之父：整洁的代码只做一件事。逻辑应该是清晰的，bug难以隐藏。依赖最少，易于维护。性能接近最佳化，避免代码混乱。
	  >没有明显的需要改善的地方。代码的作者似乎考虑了所有的事情。 
	
	
	
	
	
	
	
	
	
	
	
	
	
 --反问他技术挑战在哪里?去年年终发了多少？
 -- 不必技术慌张，因为使用的基本元素自己都知道都懂。
 -- 独当一面，心病。意味着不能靠任何提示而做出来。从开发到需求。	
 -- 开发技术工具产品的目的：预备。因为差异在于：它使用的技术、架构、机制，我这个产品/工具没有使用。比如零拷贝，NIO技术，比如磁盘只添加写，内存行伪共享，，只要它使用了的技术，我也使用了，那么效果差异不会很大。后面再做优化。或者系统中还存在冗余的多余的事情、时间和资源上的浪费。
 
 
 
参考资料：编程珠玑..。。allthingsdistributed(无服务器构建，什么都用云上的)