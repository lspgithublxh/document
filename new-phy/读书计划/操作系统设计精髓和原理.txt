---------读书战略：自顶向下，从应用层到底层细节。先熟悉的常用的，后底层的不常用的。精读好书---《深入理解系列》
--------es的处理思想都对应有 相应的“某种举动 及其导致 的问题”
>需求背景-痛点陈述：现实开发中遇到了什么痛点导致XXX的开发？  
>那么痛点的原因、产生的条件：分析是什么环境、什么动作 什么效果什么目的 等精准形容词的事实描述 导致了痛点的必然发生，难以避免？。条件-痛点。原因-结果。
>则可以消除痛点的最简单的精准事实陈述是什么：修改“条件-痛点”陈述的哪一部分就可以导致没有痛点产生。 要做的根本事情是什么：
>那么新陈述表明的解决动作是什么：
>新情况的新痛点是什么：新举动、新环境会产生的新痛点描述出来， 继续上述4条操作。
>学习要有战略和格局：过于零散、孤立、末支、叶子的知识点就没必要化太多时间，懂得放弃。聚焦在根节点、枢纽节点、产生分支的节点、主干知识点、枢纽知识点、关联到很多知识点的知识点上。
 >对于主干知识点：要有全新的认识视角和进行精细的描述，大量的提问和好奇和进行必要的实验以获取支撑观点/导出观点的数据。
 >规范是工程最独特的特征.
 >慢慢读：
>一种新技术的学习：
 >它面对的情况和问题、它的世界观、它的方案、它的方案验证/论证/能处理的解决的所有情况及能成功处理的理由/功能边界
  >所有的软件：都可以看作是向上封装一层接口，根据自己的世界观封装底层而向上/对外提供统一的(统一的更简单的更直观的更业务的更少底层信息的)接口，底层包含一系列的第三方的插件/构件/组件；内部则去做兼容和调用(对底层)(对上层则做逻辑分解和底层实现)。
>知识混乱就是因为没有组织：
	>组织就是关键字树：几个单词就是每层上的每个节点的内容；
	>组织也可以看作逻辑树：有逻辑关系，逻辑顺序，逻辑联系的关键字的层层集合。层层囊括更精细的范围，层层划分范围。
>推进理解的属性发展拓展、问题延展：重要方式；
>什么是架构：架构也是从抽象到具体的考虑和描述；树形延展开来，可以写满非常大的黑板和巨大的脑图！！sharding-jdbc,dubbo,spring都可以这样方式来展现它的架构！！它的抽象到具体的考虑---本身才是架构！！！而不是什么模块、模式之类！！
>抽象设计：则某一层就不管上一层的含义和下一层的含义，即更抽象的含义或者更具体的含义；而是实现本层的含义；完成本层的含义指定的功能；。如网络协议的架构设计；	
>面向设计来理解，面向架构设计来理解，面向架构问题一层一层来理解它：面向设计来理解，所以按照面向对象设计的方式，看其中的对象、行为属性、流程环节逻辑。	
>找不到知识/描述 所对应的问题 ， 那么看书将没有条理纲领，变得零散琐碎没有组织。	
>不是按概念方式组织，而是按架构、问题方式来组织 笔记，书本内容。架构顺序，问题层次顺序。	
>架构不是设计出来的，也不是演进出来的(甚至不是迭代出来的--尽可能避免迭代)：而是问出来的。	
>每个方法方案都从属于一颗树，所以找到一个方法巧妙方法仅仅是第一步--找到从属的层次树 有更大的价值；(无论是谁想到的方法/概念，都要这样更进一步)
>解决问题的办法就是提出问题：类似递归和动态规划；。。权衡就是线性规划；	优势劣势在一定场景下也是劣势优势；
>一个词，到一句话，两句话，一段话，一篇文章；这个就是抽象总结，层次总结；越简洁，站得越高
--在网络、搜索引擎、推荐系统 三方面的专家；作为系统方面的独特优势/拔高优势；(网络-查询-推荐)
	
----有且只有响应，通信端才知道连接是否成功；。浏览器自动扩展。
----维持连接，并发连接，都是软件的实现，物理上看都是一条出口；从响应就是维护连接的角度看，不存在需要维护什么连接，维护就是维护连接数据而已；只要发送响应，连接就活了；在网络端口出口，可以连续发送不同目的地的响应报文，这就是并行；所以完全可以用队列来接收请求数据包；而用队列缓存发送响应数据包；多核使用起来，来并行大批量的发送和接收；不存在要维护和持续占用“端口”网络出口这种概念---完全没必要，用完即走 就可；	
	>或者不存在连接这个概念：所有的事情就是接收数据包和发送数据包(接送/发送缓冲区)。(连接 是 软件臆造出来的概念，不要和物理对应；和物理对应就会束缚思想，就会很多事情理解不了不知道原因)
	>连接的状态转移图；
	>应用的固定端口：实际上是建立新TCP连接的请求的处理的端口，请求到达这个端口--后面建立一个独立的TCP连接---来负责和客户端通信-交互数据；
----UML：为什么类继承关系图---因为这就是具体到一般的概念对象抽象过程。自上而下是能力顺序，能力组合；	
----说话和介绍：语速不要快，快就是掩盖问题，掩盖过程步骤；直接导致别人认为思路不清晰，表达不清楚，东拉西扯；也不利于自己思路的成长和扩展和自己主动发现问题，且必然导致不简洁--废话很多；
	>介绍需要先纲目后具体：抽象到具体；而不是张口就是罗列枚举---内容没有结构--全是线性结构；
	>描述更精简：一个字一个词，一句话，两句话，一段话；
----大事和吏治：大事 就像西天取经；吏治就像管理四人；


--计划：nginx/tomcat-->计算机系统-->架构-->自己的系统架构方案:专题研究、大提问、大总结。大简化/模型图化；
>一个进程看作一个消息，代码计划/任务计划；；都是异步隔离；	
	>程序启动点/执行点：可以多个，看作是并行的；(一个机器上，多个程序文件里)；可以留下执行点/新增执行点；可以删除执行点/减少执行点；
	>函数式编程为什么好：因为每个精细环节清晰描述确定了下来；使得充分配置和指明动作；
	>如何看待对象的方法：所有的对象都是被动的；主动的只有cpu/并行点；
	>程序的执行要想象为人在执行；多线程则是交接执行权给其他人执行；
	>抽象编程与具体填充：假设编程和实现假设。面向对象中一个对象属性就假设已经填充好了，一个接口的实例就假设已经在容器中有了。代码编码层面和虚拟机执行层面，都规定/定义/设计为 将 接口和实例分开，系统启动时/甚至具体接口调用时才去容器里找接口的实例(启动时 一方面建立实例容器，另一方面 对接口寻找匹配的实例和链接到实例---进行连接和关联)。资源填充 和 接口调用(抽象调用)，资源--接口的映射对。领域抽象，资源抽象，功能抽象。
----未知和迷惑的地方：痛点	；
----关键和核心的地方：要点

--混乱的答案，宁可不说；只回答真正掌握的；。没有逻辑，因为没有进行抽象；没有找到所在的流程环节、模型中的位置
--系统、中间件的介绍，不是一来就是组成结构；这层次已经太细了太具体了太里面了，必须要从最简洁最抽象最上层开始；最表面最近开始；务实，不僵硬，不突然，要自然，不要忽视和没注意没意识和跳过很多步；而是从问题出发、从困难出发、从疑惑出发
	>从问题出发：先明确问题；先明确表达出问题、疑惑点、黑箱、痛点、矛盾点、难点，表述的范围可以很大(完全不知道是什么怎么办)后面逐渐具体问；无论多少问题，先明确下来；尤其要全部且完整的描述下来；
		>问题的提出：先明确背景，自然衍生、过渡、转折、演化，逻辑关系上，什么时候什么事情什么人，事情什么阶段遇到的什么问题、阻碍、阻挠、缺陷、瓶颈、不够简洁、不够简便、不够方便、不够优雅、离目标远、离理想情况远、离期望/极限效果远；不够抽象的地方；把它们充分描述完整叙述结构式组织起来。
			>问题抽象：归结为一类问题；去除具体和细节而明确问题模型；
		>问题产生原因：过程；条件；	
		>问题导致的恶果：阻碍、损失；
		>理想的方案特征/效果/必做必不做的动作&事情/应当改变的环节: 
			>这种特征/必做必不做的前提、必要条件、必然要求、必然说明、必然指示、必然可以确定的更多的事情/结论：
				>一系列结论、约束得到之后(结合条件/问题/情况本身)逐渐可以清晰看到/归结出该具体问题符合的/满足的通用/一般的/一类的问题模型/函数模型/服务模型/IO模型/请求响应模型的轮廓：若干个具体模型
					>方案的装饰/补充: 补充可靠性/稳定性/高性能(从而高可用/高并发)：因为暂时只是一个裸机、容易受到伤害、有功能但没有抵抗力(仅为打火机的火而不是熊熊大火)
							>方案的用法规则：在请求缓存前使用
		>能将具体方案进行分类的维度/情况/模型/环节/流程/抽象表述 的确定：然后使用 抽象-具体 的方法来得到新方案；					
		>普通的方案：已有的方案；方案的抽象，方案的取值选择评价；方案的表象缺陷、劣势；。。模型、数据结构和算法、协议约定分担 维度 上考虑；
	>任何事情/事物都有顺序/逻辑：且几乎都是几种常见逻辑中的一种: 时间先后、空间远近、因果环扣、程度递增
--大总结：含义包括：重新 深刻理解：
--通用的建模架构能力+Flink深度强化学习的推荐系统。。。。而不是做简单的业务逻辑开发；用深度强化学习来做应用/解决实际问题(用户的识别问题和抉择问题)；用抽象建模架构出逻辑完整的方案(工具方案/服务方案)；
--一体两翼的发展模型：底座：增强操作系统、网络、搜索、推荐能力； 两翼：普通项目：则架构建模；特殊项目：则深度强化学习；。。四大基础+两大实践(应用/使用)。。基础：是为了解决自己的问题；实践：为了解决别人的问题(用户的问题/大众)；
--一次彻底弄懂，而不是 反复低温加热。看架构书和源码书，不看使用书。
--对话中胜利：一个是提问，二个是不断的输出-高能输出。
--牢固的观念: 系统都是被使用的。
--任何一个系统、产品、服务、方案、东西、事情，它要解决的核心问题是什么？理想的形态效果影响应该是什么？市面上对应的哪些产品达到了或者没达到或者很难达到？没达到是为什么是否有我们的机会？是否还有我们可以满足的缺口。找市场缺口。
--从缝纫机原理看方案所属的分类和方案内的环节。抽象出分类和环节。
--把自己当做cpu,调/使用各个服务/接口/类/系统。
--全新学习掌握方法：先定问题体系，先提问，定逻辑路径，后开始找答案--推导和思考和查阅资料。
	>旧方法：还是盲目阅读，还是从头到尾的阅读一遍的阅读。
--所有系统和方案的理解/研究/制定的出发点：都是 出发顶点/问题顶点/概念顶点，找到了顶点才能出发，出发要从顶点出发，才顺畅，没有后顾之忧

--商业经营才能：(全新的解决问题的方法：提出问题)

>举动-痛点：资源管理、资源调度、多核设计 和 容错机制
	>解法/解决方案： 
		>计算机系统的组成：
			>处理器：
				>内部寄存器：
					>存储器地址寄存器：MAR 存确定下一次读写的存储器地址
					>存储器缓冲寄存器：MBR 存要写入存储器的数据或者读出存储器的数据。
					>IO地址寄存器：IO AR 用于确定一个特定的输入输出设备
					>IO缓冲寄存器：IO BR IO模块和处理器之间减缓数据。
			>内存：
			>IO模块：
				
					
			>总线：
		>处理器执行一条指令的步骤：
		>处理器如何和为何利用中断：注册中断、设置中断、检测中断、响应中断。程序注册中断后释放，硬件设置中断后cpu检测到而响应中断。
			>中断：中断的是处理器。IO设备/程序/时钟模块都可以产生中断信号。
				>例子：外部设备发出中断信号，处理器收到后暂停当前处理程序，而转去处理服务于特定I/O设备的程序---中断处理程序；处理完成后恢复原先程序的执行；
			>处理器如何检测中断：每次执行指令后，都去检查中断	
			>上下文的保存：系统栈/控制栈。
			>中断优先级：多个中断发生时的执行顺序。
		>计算机存储体系的每一层：
			>存储器：容量、速度、价格。
				>高速缓存：对os不可见？。包含：若干个槽，每个槽K个字，每个槽一个标签--高c位地址，其余位地址表示的地址范围数据放在槽中(可能64个)，
					>映射函数：块占用哪个高速缓冲单元的映射算法。
					>置换函数：选择块从高速缓冲中移除。
						>写策略：如果块已经修改，则需要在移除前写回内存。策略1：更新后就回写。策略2：置换时才回写。
		>直接内存存取：DMA.。处理器的委托 和 IO设备 传输数据(会占用总线)，处理器不需要中断，只需要开始告诉DMA和谁IO，DMA则独立和IO设备交互，而完成后向处理器发送中断信号；
		>多核计算机组织结构：对称多处理器SMP.。一个芯片上多个处理器--每个都独有L2，共享L3
			>连接：总线互联。共享内存/IO设备
			>高速缓冲一致性问题：一个高速缓存失效后必须通知其他高速缓存失效；---硬件来解决而不是操作系统。
			>快速通道互联：QPI: 点对点的电气互联规范；----在相连的多个处理器芯片间实现高速通信；速率：单向：12.8GB/s
		>局部性概念：多级存储体系的性能
		>栈对过程调用和返回的支持：
		>操作系统：应用程序和计算机硬件之间的接口。
			>目标：更充分有效(压榨)的利用计算机资源，更方便的使用(计算机资源)	，更方便的开发新的系统功能；
			>本质：
				>1.(为开发提供)共享功能/共享库程序：创建程序/管理文件/控制IO设备。。。(调用过程：就是转向的过程--应用程序自己编译后可以直接是指令集指令,也可以是操作提供的函数代码入口指令)。
				>2.(为程序)运行代理：操作系统解释执行。
				>3.(为运行中的应用)系统资源访问的协调(解决竞争时的冲突问题)。
				>4.(为运行中的应用)检测错误和清除错误，如硬件错误、设备故障，使得对运行中的程序影响最小。如中止出错的程序、重试、直接报告错误。
				>5.(为各个阶段)资源利用率等各种性能参数的统计和监控，以调整系统和提高性能。
			>意图：给处理器提供指令，告诉如何使用其他系统资源(和控制其他程序的执行时机)(告诉做什么和怎么做)	(操作系统能自己主动做一些事情，也能执行用户让执行的事情)
				>os可以看作是主动方：而处理器、磁盘、文件等都是服务方/资源--等待被使用。
				>内存中：内核程序+其他部分os程序。+用户程序+数据。
				>os为什么需要模块化：专门做某件事的程序为一个模块，供其他模块调用，从而被复用。减少重复代码和相似功能代码。每个模块又可以自己升级和优化。
			>历史：
				>监控程序：常驻内存，当用户程序执行中，可能会执行到特权指令---直接发送错误--而转到监控程序；例如IO指令；转到监控程序，则监控程序控制IO设备。
					>内存保护：当用户程序试图改变监控程序的内存区域，处理器硬件发现错误将控制权转给监控程序。。。转：就是根据条件跳转到新的执行指令地址。
						>可以访问受保护的内存区域+执行特权指令：则程序处于  内核模式/系统态。如监控程序。
				>多道程序设计：
					>批处理：内存中有多个用户程序，则一个在IO时，处理器可以切换去执行另一个用户程序。充分利用处理器。		
						>切换的实现：调度算法。
						>新问题：内存管理：因为多个作业保存在了内存中。
					>分时系统：不等特殊条件，程序每次只被分配 固定的执行时间 就释放。	减少响应时间。
						>交替执行的实现：定时中断，如0.2s一次的中断，每次中断时os恢复控制权，然后告诉处理器执行哪个用户程序，之前在执行的被挂起--写出到磁盘。
			>主要挑战：
				>进程：
					>信号机制：
						>正确的同步---一个进程执行到某个命令时激发另一个进程开始。
						>正确的互斥：一个进程在访问一个资源，其他进程则不能再访问。相当于抑制其他进程。
						>正确的进程调度顺序：可能影响特定程序的输出结果。
						>避免死锁：资源分配和释放的时机安排。
					>内容：程序+数据+上下文
						>上下文：处理器+寄存器的内容，程序计数器+数据寄存器。进程优先级等。进程被中断时就需要保存上下文和恢复上下文。
					>建立和维护的进程表：	
				>内存管理：
					>进程隔离：防止相互干扰各自的存储空间。
					>自动分配和管理：给作业分配存储空间。
					>支持模块化程序设计：程序员定义程序模块，并动态的创建和销毁模块，动态改变模块的大小；
					>保护和访问控制：部分内存空间是可以共享访问的。
					>长期存储：文件系统实现长期存储。
						>虚存：利用了动态映射硬件实现的虚地址(页号+页中偏移量)--内存中的实地址 之间的动态映射。
							>一个进程：可能多个页。且各个页在内存中不同区域。
								>进程执行时：部分页调入内存；要访问的页不在内存--检测到后 安排 载入这个缺页
				>调度和资源管理：属于运筹问题。
					>可用资源：内存空间/IO设备/处理器
					>使用可用资源的主体：活动进程。
					>将可用资源分配给使用资源的主体：有策略。
						>策略特征：
							>公平性：同等和公平的访问同一资源。
							>有差别的响应性：作业的服务要求不同/紧急程度/服务后的收益大小
							>有效性：因为 吞吐量、响应时间、容纳的用户量，是相互制约的。
				>信息保护和安全；
					>可用性：保护系统不被中断；
					>保密性：保证用户不能读取未授权访问的数据
					>数据完整性：保护数据不被未授权修改；
					>认证：用户身份的正确认证和消息/数据的合法性；
				--可用性： MTTF/(MTTR+MTTF) 平均正常运行时间，平均失效时间。	
				--容错性：增加冗余度来实现：
					>空间冗余：物理冗余。多个组件同时执行相同功能；设置一个备份的可用组件。增加多条并行线路。
					>时间冗余：遇到错误重试。对临时错误有效，对永久错误无效；如重传数据。重新调用。
					>信息冗余：冗余位 来修复位数据；差错控制编码电路。
					--操作系统实现的容错性：
						>进程隔离： 
						>并发控制：
						>虚拟机：更高程度的应用隔离和错误隔离；
						>检测点和回滚机制：
				--windows:
					>内核模式组件：
						>执行体：操作系统核心服务：内存管理、进程和线程管理、安全、IO和进程间通信
						>内核：线程调度、进程切换、异常和中断处理、多处理器同步。是不可抢占或分页的部分。
						>硬件抽象层：对先定义好的统一的逻辑层-系统总线/直接存储器访问控制器、中断控制器、系统计时器和存储控制器，这些服务和接口，不同的硬件有不同的指令集，实现这些服务和功能和接口的程序指令就是不同的，统一接口+每套实现 都包含在硬件抽象层中。
						>设备驱动：怎么刺激(提问)(询问/听得懂的语言/可以理解接受的指令)设备和解读响应的程序指令集合。包含在动态库里。扩展了执行体。以及利用硬件实现的更加复杂的功能的程序--比如文件系统(利用磁盘)和网络协议(利用网卡/网络)。
						>窗口和图形系统：
					>面向对象的设计：把数据和方法封装在了一起。而面向过程则仅仅封装了函数。即还涉及到了保存数据，而函数本身只是计算--不保存数据--调用者集中保存数据/状态。而面向对象，就自然而然按归属 分散保存数据。	
				--unix: 一切服务都是/都要想象成 指令和数据。可以加载指令和数据到内存，可以执行指令。
				--linux: 高度模块化 且易于配置。
					>单体内核：可加载模块结构---特征：动态链接&可堆叠模块。模块有依赖，所以一般级联加载。
						>模块的组织结构：链表(每个元素为模块表)。模块如：FAT,VFAT
					>内核组件：	
						>信号：被内核使用来联系进程，告诉一些信息。内核如虚拟内存、系统调用、陷阱和错误， 都调用信号 来 告知进程。
							>内容：一般都是 来自硬件的情况描述/异常描述。
						>系统调用：几百个，分类：文件系统、进程、进程间通信、套接字、调度。。。
						>进程和调度器；创建管理和调度进程。
						>虚存： 
						>文件系统： 
						>网络协议：
						>字符设备驱动：
						>块设备驱动；
						>网络设备驱动：
						>陷阱和错误：
						>物理内存：
						>中断：
				--android: 系统内核+中间件+关键应用的软件栈。对传感器处理的很好。		
					>应用：
					>应用框架：
						>各种应用管理器：
					>系统库 & android runtime: 
						>系统库：SSL/OPenGL/SQLite
						>DVM, 一个应用有一个自己的DVM
					--硬件抽象层：HAL	
					>Linux内核：硬件和软件中间的抽象层的角色。
						>各种驱动：
		>进程： 操作系统一方面可以看作：资源的管理、分配(被调用而去使用资源)、监控和保护。
			---处理器是唯一的主动方。操作系统就是 资源的 使用说明书(方案书，而不止是死命令)(处理器解释)(命令可以是转向命令--如用户程序中包含的转向os A库指令起始地址的指令)，处理器可以看懂这本说明书并且一直在查阅这本说明书。资源包括：内存、硬盘、网络、IO设备。
			---用户程序(可以简单的想象为分段的几段代码--先cpu相关指令/后存储器相关指令/后IO设备访问指令/)
			---最开始是操作系统调用用户程序，用户程序执行时可以调系统函数而已。处理器主动直接做的事： 检测中断位+查询os代码。
			>定义：
				>表征：标识符+状态+程序计数器；各种指针地址+上下文数据(处理器寄存器数据)+IO状态信息(进程使用/占用的文件列表)。优先级。
			>进程控制块：进程表征存储在的数据结构。
				>保证可以中断进程和恢复进程：而不出错。
				>os支持多进程的关键工具：
			>进程状态和之间的转换：
				>两状态模型：
					>进程生命周期：创建和终止。创建：os负责实际执行(创建过程：是否就像提交一个任务一样，提交一个进程控制块到队列里？)(然后等待被调度执行)
						>进程派生：运行中的进程上的应用也可以创建新进程。
						>进程终止条件：正常结束+各种故障/限制指令非法越界/父进程终止	
				>五状态模型：新建-->就绪-->运行-->阻塞-->退出
					>新建：仅在进程表中有记录，程序还在磁盘。
					>退出：先保留进程表中记录，后删除。
					--队列：就绪队列(按优先级又分为多个队列)+阻塞队列(按等待事件1/事件2/事件3分多个队列)
					>阻塞：可能先被换出(部分/全部)到磁盘。
					>就绪：低优先级的就绪态进程可能部分换出到磁盘。
			>管理进程所用的数据结构：进程控制块+调用栈(用户栈/内核栈)+程序+局部变量
				>进程映像：
					>位置：内存或者部分在外存。
					>记录内容：每个进程的每页的位置。
				>执行模式：处理器里2位CPL当前特权状态 寄存器PSR。0为最高级别。模式是安全机制。
					>模式切换：用户模式切换到内核模式，保存模式上下文，但是没有切换进程--还在当前的用户进程内执行(同一进程中切换模式)。
				>进程切换：
					>时机：发生什么事件时：时钟中断()、IO中断(阻塞态转就绪态)、内存失效(发出调入内存块的IO请求后，内存失效的进程进入阻塞态)
				>进程创建：内核系统调用fork()实现。	
			>os对进程控制的需求：
				>资源管理： 
					>内存： 内存表来管理。表里记载：分配给进程的内存/外存(及其保护属性)。
					>IO: IO表 来管理。IO设备/通道 ---- 进程  的映射。IO的源/目标 的内存单元；IO操作的状态；
					>文件：文件表。文件外存位置/当前状态
					>进程：进程表。资源---进程标志符。
			>进程管理模式：
		>线程：没有资源所有权的单位(专门有独占的虚拟地址空间和对资源的映射)。一个进程内支持多个并发执行路径的能力。	
			>特征：与进程内的其他线程共享内存和对资源的访问。每个线程：线程控制块+用户栈+内核栈
				>创建和终止：都快。
				>线程切换：快。
				>线程间通信：无需内核介入---共享内存和文件。而进程间通信需要内核介入。
			>线程控制块：就绪、运行阻塞队列。
			>分类： 
				>用户级线程：ULT，内核意识不到线程的存在，还是一个内核进程在执行；线程库实现的用户级线程(调度)。用户空间中实现。内核继续以进程为单位调度。但是无法利用多核。且一个系统调用引起整个进程阻塞。
					>套管技术：将阻塞的系统调用转为非阻塞的系统调用；
				>内核级线程：KLT，内核为进程和进程内每个线程维护上下文信息；调度由内核基于线程完成。从而利用多处理器，和一个线程阻塞不会影响其他线程。缺点为：线程切换 需要先切换到内核模式。
					>混合方法：m个用户线程 映射到 n个内核线程上(排队)，线程库调度+内核调度结合。m>n
				--solaris 中采用的3层线程架构：用户级线程--轻量级进程--内核线程。	
				--linux 克隆新进程：共享同一内存空间，但创建独立的栈空间。
				--android: 一个应用多个活动，全部压入栈中。栈顶的活动的窗口信息显示在屏幕上，通过返回按钮弹出活动。
				--mac: gcd任务并发。
		>并发性：互斥和同步
			>竞争条件：进程会获得、等待、释放资源。
				>控制问题：
					>死锁：
					>饥饿：
			>互斥需求：一段代码还在执行中则其他进程不能执行。就是进程互斥。在临界区互斥。互斥粒度。
				>互斥粒度太小(如一行代码)：可能造成 数据一致性问题。
				>实现互斥：
					>硬件支持：CMS指令---不接受中断。exchange指令XCHG
					>信号量： 01互斥量。
					--生产者消费者问题：其实最好：就是 两个只增大的数表示队列头和尾：head,tail. 生产者增加head, 消费者增加tail,生产者和消费者都保证head-tail<=n, 否则就要阻塞(已空已满，在非空非满两个条件下等待)(等待非空，激活非满)。
			>信号量：整数值。初始化、递增、递减。
				>互斥量：二元信号量。加锁和解锁的进程必须为同一进程。(无重入概念)(为什么要可重入，因为同步块里如果调用某个方法，这个方法还在其他方法下被调用，那么这个方法就被共享了---所以如果为了也变为临界区--就需要再次同步--如果再使用同一个锁--就是重入)
			>管程：java有实现。任何时候只有一个进程在管程中执行---其他进程调用则被阻塞--直到管程可用。
				>java实现：就是同步块里主动条件等待(入队)和唤醒/wait/notify。唤醒调用后，也要等待唤醒线程退出后，被唤醒线程才能醒来。
			>进程间通信：
				>消息交换：无阻塞send不能确定 消息 是否被消费。无阻塞received则不能及时收到消息。。。引入中间者 信箱 。
				>一写多读问题：读写锁。。进程到x条件的队列中等待，被唤醒后执行操作，后唤醒队列中下一个进程。可以交叉在多个条件上等待和唤醒。
					>写者优先：非常形象的，三个条件队列：write-队列，read-队列，y-队列；写者：先在y-条件队列下等待，到顶后到read-队列等待，来等待所有的读进程先执行完，又到队列顶后(此时在2个队列顶)唤醒y队列顶，来到write-队列等待，又到顶后(此时在write/read队列的顶)--所以此时读进程和写进程都没有在执行--所以可以开始写数据了，写完后优先激活写队列的下一个进程，然后到y-队列等待(此时继续占领read-队列顶部/不可读)，到队顶后 如果没有写者了-则激活read-队列下一个进程，后固定激活y队列下一个。(是只有write-队列最后一个进程才会激活read-队列下一个元素---所以叫写者优先)
					>消息交换方式：控制进程--三个邮箱：读/写/finish, 接收三种请求。读请求 进程 则1个邮箱，写请求进程也是。处理读，-1，处理写-100，处理finish+1>。。。每轮依次finish,write,read邮箱轮询--但只一个实际接收；每轮结束，count<0则要等待接收finished到count==0才开始下一轮；==0，则要发write/并等待接收后count=100
						>轮询+事件等待队列：可以实现无锁无阻塞并发。
			>资源共享与竞争：
			>多个进程活动的同步：
		>并发：死锁和饥饿。
			>死锁产生的条件：某个时期占有资源A1而阻塞等待释放资源A2事件。但每个进程都阻塞，没有释放资源事件触发，导致无限等待。
				>联合进程图：
				>进程占有/阻塞时间轴图：每个进程一个轴，占有资源(请求成功为占有)为加实线，等待资源(请求失败为等待)为加波浪线/虚线
				>死锁例子：可重用资源--磁盘/IO, 可消耗资源--信号/消息/中断
					>请求独占磁盘和磁带两个资源：如果各个进程请求顺序不同，一先磁盘一先磁带，就发生死锁。
					>请求两块内存资源：各个进程各自先成功请求了一块，又等待下一块；但是剩余空间不足了。
					>互相等待对方的消息：死锁。你发了我才发。
				>三个死锁存在的必要条件：
					>互斥：一个资源一次只被一个进程使用
					>占有且等待：进程等待资源时，继续占有已占资源
					>不可抢占：不能抢占其他进程占有的资源
					--条件4：循环等待：进程组中，每个占有资源的进程所等待的资源都已被组内进程占有。四个条件可以构成一个 死锁产生的充分条件。三个条件是存在的可能性；四个条件则是存在的必然性。			
			>死锁预防：消除4个必要条件之一的出现。
				>策略：保守：预提交资源
					>一次性请求所有资源：必须知道将来的资源请求。
					>抢占：占有一个，则可以抢占另一个。一成一败--按优先级。就是主动提出要抢它的资源--比较获取资源的优先级。
					>资源排序：请求的资源的排序顺序，必须一个一个按资源顺序请求多个资源。
				>间接预防：3个条件的防止
					>互斥：不可避免
					>占有且等待的破坏：不占有的等待---即一次性请求所需的所有的资源。可能不知道资源；知道了可能很久都没使用；
					>不可抢占的破坏：可抢占；请求资源时，如果资源被优先级低的进程占有，则强制获取资源--调os来抢占；例如请求处理器资源；但是要求资源状态必须容易保存和恢复。
				>直接预防：第四个条件的防止
					>循环等待的破坏：线程占有Ri资源后只能请求Rj资源，其中i<j, Ri排在Rj后面；Ri<Rj;
			>死锁避免：基于资源分配状态做动态选择。主动发现安全路径，或者主动放弃请求部分资源；主动等待；
				>允许三个必要条件：只是恰当选择 而不达到死锁点；
				>资源分配前要判断：该请求是否可能造成死锁。如果一个请求会导致死锁，进程不启动；如果进程已经启动，则不允许这一资源分配；
				--需求/分配矩阵：Claim/Allocation:..。总量/可用向量：R/V。分配<需求<总量。总量=需求+可用。。。。死锁检测：只看新增线程的资源需求+已有线程的资源需求 <= 资源总量 成立，才启动；
				--银行家算法：n进程+m资源的系统
					>安全状态：至少一个资源分配序列不会导致死锁；就是V向量表明的剩下的资源，先分配给谁，再给谁，后给谁，每个谁都能顺利执行完毕。这个执行路径/序列的寻找。显然，需要看C-A 得到的还需矩阵。然后看V能满足哪行/哪些行，然后回收资源后又可以满足剩下的哪行/哪些行,....知道全部行都得到了满足；如果中间有不能的，则说明该分配路径会造成死锁要丢弃；如果所有路径都没有找到可以全部行满足的，则无法避免死锁；
						>本质：是分配策略和释放策略；。。无需抢占和回滚进程。仅仅必要的悬挂进程；
			>死锁检测：jstack 查看。测试已经发生的死锁，并破坏死锁。
				>事后检测：事后破坏。资源请求时进行。但会消耗相当多的处理器时间；
				>算法：标记未死锁的过程
					>策略：查找 当前可用资源 可以满足资源需求的进程，找到则标记，然后回收它占有的资源；尝试标记下一个；。。第一个为标记尚未分配资源的进程；
				>检测后的恢复：
					>取消死锁进程：
					>回滚重启进程：
					>逐个取消死锁进程：直到不存在死锁；
					>逐个抢占资源：来满足进程需求，直到可以满足剩下的进程；被抢占资源的进程则回滚；
			>综合方案：
				>对 可交换空间：一次性分配所请求的资源：
				>对 进程资源：死锁避免/死锁预防策略；(优先级先占用)
				>对 内存： 基于抢占的预防；抢占其他进程占用的内存，则被抢占的进程则置换到外存；
				>对 内部资源： 可以使用基于资源排序的预防策略；
			>资源分配图：资源(节点)/进程(节点)/占有(线)/请求(线)	
			>哲学家就餐问题：
				>基于信号量：等待条件：左叉子/右叉子； 吃饭； 激发条件:左叉子/右叉子；
				>基于管程：保证不会出现死锁；因为保证一次可以拿到两把；
			>UNIX并发机制：
				>管道：进程间传递消息
					>内容： 一个环形缓冲区。允许两个进程以 生产者/消费者 模型 进行通信；。类似Disruptor, head/tail; 读空了则阻塞；写满了也阻塞；
					>匿名管道：血缘关系的进程可以共享；
					>命名管道：不相关的进程可以共享；
				>信号量：
					>内容： 当前值 + owner(最后一个操作进程的id) + 等待信号量的值大于当前值的进程数 + 等待信号量的值等于0的进程数；；；相关：等待在该信号量上的进程队列
					>信号量集合：
					>操作信号量：
						>sem_op > 0: 内核增加信号量的值，唤醒所有等待该信号量的值增加的进程 
						>sem_op ==0: 内核检测信号量的值，如果=0 则继续其他信号量操作，否则增加等待该值=0的进程数，并将该进程阻塞在信号量值=0事件上；
						...
				>信号：用于向一个进程通知发生异步事件；进程之间可以互相发送信号；内核也可以内部发送信号；
					>信号的传递：
					>信号的处理：进程做出响应---执行信号处理函数/终止进程/忽略该信号
				>共享内存：进程间传递消息，速度最快；
					>内容：为虚存中多个进程共享的公共内存块；进程读写这块空间 用的指令 同 读写 虚存 其他空间；
				>消息：进程间传递消息
					>每个进程配一个消息队列：。。系统调用 msgsnd , msgrcv 来将消息发送到对方消息队列或者读取自身消息队列；
			>LINUX内核并发机制：独有---实时信号；多个信号能进行排队；
				>原子操作：保证对变量的原子操作；--用来避免简单的竞争条件；执行期间 线程不会被中断；多处理器中则原子操作的变量被锁住--避免被其他进程访问；
					>针对整数变量：
					>针对位图中某一位的位图操作：
					---实现：某些计算机体系结构：对应有汇编指令；某些计算机体系结构中：通过锁住内存总线的方式来保证操作的原子性；	
					---实现api: 原子整数操作：atomic_t, 原子位图操作：
				>基于原子操作的锁机制：
					>自旋锁：spinlock: 检查 一个整数值 == 0 ？ 是则更新为1， 获得锁；否则自旋；释放锁：更新为0；
					>读写自旋锁：
				>内核信号量：
					>二元信号量：MUTEX互斥信号量； init_MUTEX, init_MUTEX_LOCKED 函数初始化； 
					>计数信号量：
					>读写信号量：多个并发读 和 一个 写者；实际：对读者--计数信号量；对写者--二元信号量；使用不可中断睡眠；
				>屏障：	
					>内存访问 指令 的 重排序：
					>内存屏障：rmb()操作 保证 之前的代码 中 的读操作 都会在rmb()操作之前(拦截读)；之后的代码中的读操作也在rmb()之后；类似的，wmb()是写屏障的实现；。mb()则是装载和存储屏障；	
						>功能1：可以指示 编译器的行为：编译期间不要重排序指令；
						>功能2：可以指示 处理器的行为：指示流水线上在屏障前的指令必须在屏障之后的指令开始执行之前提交；。。。barrier()仅仅控制编译器的行为；
						>其他：smp_rmb, smp_wmb, smp_mb 操作能优化SMP上编译的代码；在SMP结构，这些指令定义为内存屏障，UP结构则仅仅作为编译器屏障：barrier()；
			>Solaris 线程同步原语：			
			>Win 7 的并发机制：锁也是服务(全套方法集合)。。使用内部锁操作来实现同步原语；内部锁操作可以实现更复杂的锁无关原语；
				>分派器对象：
				>临界区：
			>Android进程间通信：连接器----传递两个进程之间的交互。进程组件-->连接器-->目标进程的目标组件。接力一样；		
		>内存管理： 有效的分配内存来保证 适当数量的 就绪进程 能占用 这些 可用的 处理器时间。
			>基本概念：
				>页框：内存中 固定长度的块；
				>页：固定长度的数据块；存储在二级存储器中--磁盘；数据页可以临时复制到内存的页框中；
				>段：变长数据块；存储在二级存储器中；整个段可以临时复制到内存的一个可用区域(分段)；或可以将一个段 分为 许多页，然后每页单独复制到内存中；
			>内存管理的需求：
				>重定位：进程换出 后重新换入时，重定位到不同的内存区域。
					>程序代码中的内存访问：转换为 实际的物理内存地址；
				>逻辑组织：分模块；模块级别只执行只读；
				>物理组织：2级：内存外存(大慢久)；
				>共享：合作完成同一个任务的进程可能需要共享访问相同的数据结构；
				>保护：其他进程不能访问本进程的内存空间；操作系统的部分更不能访问；。由处理器硬件满足 内存保护的需求。
			>分页：进程的(部分/所有)页装入内存的页框；多对多
				>页框： 操作系统维护 空闲 页框 列表；
				>页表： 操作系统为 每个进程 维护一个 页表；---该进程每页所对应的页框位置(页号--页框号 的映射)；逻辑地址：页号+页中的偏移量。。给出逻辑地址(页号+偏移量)后，处理器使用页表产生 物理地址(页框号+偏移量)
					>大小：为方便：页框和页大小是2的整数次方，以便容易的表示出相对地址；
					>地址：16位；6位为页号，10位为偏移量；
					>动态地址转换：硬件实现；。。地址-->页号-->页表-->页框号k-->起始物理地址=k*2^m...。。由页框号和偏移量 算 物理地址；
			>分段：进程的(部分/所有)段装入内存的动态分区中；多对多
				>段：大小可以不同；程序和数据分段；段号+偏移量。所有段都要载入内存；但可以不连续。
				>段表：进程有段表；系统维护空闲块列表；段表项：段在内存中的起始地址+段的长度
				>地址映射过程：段号+偏移量：n+m,  则从段表找到该段的 段号n的起始物理地址， 偏移量和段长度比较，不大则有效；
			>分区：对用户内存空间进行分区。进程占据分区，若分区中的进程都未就绪或者运行态，则换出；
				>动态分区：换入换出后，最终产生很多空洞；外部碎片。
				>固定分区：内存空间利用率低。内部碎片。
				>伙伴系统：分配2^K个字，刚好大于需求s的2的整数次方个字；
				--换入换出：指令和数据单元的位置会发生改变；
					>逻辑地址：
					>相对地址：程序使用相对地址；。硬件机制：将相对地址转为物理地址；---使用基地址寄存器--指明程序开始的内存地址；界限寄存器---则指明程序的终止位置；；；换入时 需要重新设置这两个寄存器；。。处理器执行时：会将基地址寄存器的值+相对地址值 得到绝对地址，再和 界限寄存器比较，在范围内 则继续该指令的执行，
					>物理地址：
			>装载：
				>创建活动进程：程序装入内存，创建一个进程映像--->二进制代码时刻的程序还是使用的逻辑地址/相对地址；
				>寻址需求：
					>绝对加载--给定模块总被加载到内存中同一地址；但最好是用符号表示 程序中的内存访问；。(编程时写死地址，编译时编为死地址)
					>可重定位加载-：加载时确定具体的内存地址。加载模块到内存时 才解析 外部访问；然后动态链接模块附加到加载模块后；动态地址计算。
			>链接：链接器的功能：输入一组目标模块，产生一个包含完整程序和数据模块的加载模块，并传递给加载器。
				>每个目标模块中：有到其他模块的访问，都是符号访问；。所以链接器会创建一个 单独的加载模块， 它把所有的目标模块逐个链接起来；即将符号引用转为相对地址引用
				>动态连接器：某些外部模块的链接可以推迟到创建加载模块之后；。即一个应用模块被加载，如果它引用了一个外部模块，则加载程序查找目标模块加载它，再修改符号引用为相对引用；
					>代码共享：操作系统可以识别出有多个应用程序使用了相同的目标代码；从而只加载这个代码的一个副本；。运行时加载的动态模块，链接到调用模块；这些模板被称为动态链接库DLL--windows
		>虚拟内存：
			>支持虚拟内存的硬件和控制结构：
				>处理器访问不在内存中的逻辑地址时(即页表中某页的页框号暂时没有)：会产生一个中断，操作系统介入(即处理器转而执行操作系统)，将进程置为阻塞态--->后将产生一个IO读请求，调IO程序处理--将需要的进程块读入内存，此工作不一定是操作系统在做，操作系统可能去做其他进程调度的事情，当IO程序将进程块载入内存后产生一个IO中断，操作系统才将被阻塞的进程置为就绪态；。。
				>只加载程序部分模块到内存的好处：可以保留更多进程在内存；程序可以比内存空间还大；换入换出进程更快更省(代码执行覆盖率更高)。。部分载入程序+需要时再从磁盘加载 就是虚拟内存机制；。。简单分页，所有页要载入内存；虚拟分页，则部分页载入，需要时再载入；
				>页表项：P--页是否在内存，M位--页从载入到现在是否改变过；页框号；。。
				>页表指针寄存器：
				>页表太大的问题：即当程序太大时的问题：虚存中保存页表；方案2：页表的页表---两级方案；根页表-页表-偏移量：10位-10位-12位
				>倒排页表：key=页号的m位散列函数值，value=进程标识符/页号/控制位/下一页的链指针
				>虚存访问的实际过程： 先 取 页表项 --> 再取需要的数据
					>转换检测缓冲区：TLB 高速缓存；给定一个虚拟地址-->处理器先用页号查TLB,查到则找到页框号从而+偏移量得到实际地址。否则-->查找进程页表，如果P置位页在内存，则映射到页框号+偏移量得到实际地址,并更新TLB；未置位，则产生中断，os开始介入，执行IO程序，加载缺的页后(如果内存不够，则页面置换出去)，IO中断，Os更新页表和TLB。。所以TLB就是进程页表的高速缓冲；
					>使用实际地址：如果高速缓冲中有包含实际地址的块，则返回cpu，没有则从内存中检索加载这个字(块/缓存行)；
					
			>实现虚拟内存的各种操作系统机制：
				>读取策略：进程首次启动--预先分页，后来 请求分页。
				>放置策略：决定进程块驻留在实存中什么位置。NUMA系统则 自动放置系统--分配到提供最佳性能的内存；
				>置换策略：每个进程分配多少页框；计划置换的页集中，选择换出哪一页；
					>页框锁定：被锁定的页框中的页不被置换；操作系统和重要的控制结构就在锁定的页框中；
					>LRU:
					>FIFO:
					>时钟策略：页框01标记；。表示未被访问过/访问过。还有修改标记01，表示修改过(要先写回辅存)，未修改过。00，01都可以置换出去；
					>空闲页链表/修改页链表：
				>驻留集管理：
					>固定分配策略：为进程分配固定数量的页框；
					>可变分配策略：分配的页框在进程生命周期中不断变化；
					>置换范围：局部(保留驻留集)/全局。。缺页中断--空闲页框/置换页(产生一个空闲页框)
					>工作集大小：W(t,delta), delta是观察进程的时间窗口；每个进程有一个工作集；。。。发现缺页率低-->减少驻留集-->其他进程得到更多页框；
						>缺页中断频率算法：PFF算法：
						>可变采样间隔的工作集策略：
				>清除策略：何时将已修改的页写回辅存；
					>请求式清除：页被用于置换时才写回辅存；
					>预约式清除：在需要使用它们占据的页框之前成批写回辅存；
				>加载控制：如果内存中进程太少---则同时处于阻塞的概率就大--则很多时间花费在交换上。如果内存中进程太多--则平均每个进程的驻留集大小将不够用--频繁发生缺页中断--导致系统抖动；
					>频繁的处理缺页中断  还是 频繁的 因进程阻塞而交换：
					>L=S准则：调整系统并发度，使得缺页中断之间的时间 =  处理一次缺页中断 所需的时间；
			--局部空闲块的合并：
			>虚拟内存管理机制：
				>段页式：用户地址空间被程序员划分为多个段，每个段内许多固定大小的页，。。段偏移量=页号+页偏移量；
					>此时：段表项：存段号--页表地址；页表项：还是 页号--页框号；
					>分段：有助于实现保护和共享机制。因为段表项：基地址+长度 保证不轻易过界；。。共享：一个段 可能被多个进程的段表引用。
			>linux内存管理：
				>虚存寻址：三级页表结构；全局目录-中间目录-页表-偏移量
				>页面分配：连续的页分配到连续的页框中；使用了伙伴系统；
				>分配页：slab分配方案：
			>windows内存管理：
				>2g内核空间+2g用户空间：
				>页状态：可用-保留-提交
				>太多页的进程总会被os注意到：而移走该进程最近未使用的页面；。。
			----内存中：进程数量多还是进程的驻留集页多的权衡选择分配的问题；	
		>调度：单处理器调度
			>长程/中程/短程调度：处理器调度。三程调度程序-三队列。
				>长程调度：决定加入待执行进程池。新建后的加入。
					>控制了并发度：决定用户程序成为进程。
					>决定：是否创建、选择哪个进行转变(为进程)
				>中程调度：决定加入部分位于内存中的进程集合；阻塞后的交换入
					>交换功能的一部分：
				>短程调度：决定处理器执行哪个可运行进程。就绪后的分配到处理器
					>短程调度程序：分派程序
						>执行时间：导致当前进程阻塞/或被抢占的事件发生时。事件包括：时钟中断、IO中断、操作系统调用、信号。
			>IO调度：决定可用IO设备处理哪个进程挂起的iO请求。
			>调度的目标：满足系统目标(响应时间/吞吐率/处理器效率)的方式，把进程分配到一个或多个处理器上执行；
				>目标细化：使得平均响应时间 小于x秒的用户数量最大；吞吐量--处理器执行进程的时间比；。响应时间小则可能频繁切换--增加系统开销--降低吞吐量。处理器利用率---处理器处于忙状态的时间比
			>调度的问题模型：队列管理问题。
			>调度规则：公平对待进程、强制优先级高的先调度、使所有资源处于忙状态--优先调度较少使用紧缺资源的进程；吞吐量和处理器利用率要高；可预测性、周转时间和响应时间短；
			>选择函数：
				>决策模式：抢占/非抢占。抢占有开销，但避免长进程独占处理器。若进程切换机制有效、内存大使得大部分程序在内存，则抢占代价低；
				>进程相关时间：等待被调度时间、需要时间/实际执行时间、最大暂停时间、平均暂停时间、暂停次数、剩余所需时间、进程切换总次数/切换平均耗时/切换平均间隔、处理器利用率(和业务类型有关如IO密集)。
				>先来先服务：更利于处理器密集型；且可能使得处理器和IO都没有充分利用；
				>轮转：基于时钟的抢占；处理器开销大。(限时版本的先来先服务)。利于分时系统和事务处理系统；
					>虚拟轮转法：辅助队列>就绪队列>IO队列
				>最短进程优先：FCFS的短作业调度优化版本。非抢占策略，所以看下次选择---选择预计处理时间最短的进程；但降低了可预测性--响应时间波动--受新的短进程的影响；。。进程预计时间---通过统计计算出。SPN
				>最短剩余时间：SRT。SPN增加了抢占的版本。选择预期处理时间最短的进程；新加入的进程预计剩余时间更短则可能抢占当前正在执行的进程。要记录服务时间，所以有开销；。优点在 归一化时间较小。
				>最高响应比优先：当前进程完成或者被阻塞时，选择 R=(w+s)/s最大的进程就绪进程。HRRN. 最终会调度等待了很久的长进程。服务时间越长等待越久。
				>反馈法：处罚运行时间较长的进程；。基于抢占(时间片)原则，动态优先级；被抢占时降级到下一个优先级的队列---但这个队列中的进程被调度时将有更多的时间片。
				--进化类算法：
			>调度策略：
				>基于进程组的调度策略：公平共享调度。组内竞争资源，而不影响其他组。组cpu计数越少，进程cpu计数越少，优先级越高则优先执行该进程；cpu计数=每秒cpu中断次数*进程执行秒数；每次结束时，cpu计数/组cpu计数都折半。
			>传统unix调度思想：	保证好的响应时间，低优先级的进程不会饥饿；。多级反馈。优先级队列里采用轮转。cpu计数也是折半，优先级动态和cpu计数正相关；1s抢占。选cpu计数最少的。
				>用户看响应时间、系统看吞吐量和处理器利用率。
		>多处理器和实时调度：紧耦合多处理器。一系列共享同一个内存并受操作系统完全控制的处理器组成。
			>线程粒度：
				>粒度：
					>无约束并行性：进程之间没有显式的同步
					>粗粒度和极粗粒度并行性：进程间存在同步，但级别为进程。
					>中粒度并行性：进程的线程之间的 同步。
					>细粒度并行性：
				>相关问题:	
					>把进程分配到处理器：
						>静态分配和动态分配：静态--处理器维护一个短程队列--但可能为空导致空闲。单一队列则可以。
							>动态负载平衡：线程能在不同的处理器所对应的队列之间转移。linux采纳。
						>分配方法：主从---主是瓶颈。对等式--	
					>单处理器上多道程序设计：一个进程的所有线程都希望同时运行；
					>一个进程的实际分派：进程调度/线程调度。
				>进程调度：系统视为 多服务器排队结构。	
			>线程调度方法：
				>负载分配：全局线程队列，处理器空闲时调度一个线程。瓶颈在队列---处理器越多越互斥冲突大；
					>分配方案：
						>先来先服务：新进程的所有线程放到队列末尾，等待其他线程执行完毕或者阻塞；
						>最少线程数优先：共享就绪队列组织为优先级队列；
						>可抢占的最少线程数优先：刚到达的任务的线程数少于正在执行的作业的线程数，则抢占这个被调度作业的线程。。。
							>当被抢占的线程下次：不在同一个处理器上执行，则处理器的缓存失效；
							--mac: 每个处理器一个队列 + 一个全局队列。
				>组调度：一组相关的线程，一对一调度到一组处理器上。使得进程切换的开销最小；。即一个进程的线程同时分配到多个处理器上,占用时间片，方便协作，而不是线性的，一个放到一个处理器，而其他处理器执行的其他进程的线程；
				>专用处理器分配：线程指定到处理器。也是进程的所有线程分配到多个处理器，较少进程切换；。进程同时的活跃的线程数应该小于等于处理器数量。
					>活动工作集：
				>动态调度：程序能动态改变它的线程数量；请求队列-等待被分配处理器。
				--考虑的其他方面：多核共享的缓存。
			>实时调度的需求：自动驾驶汽车、实验控制、过程控制设备、机器人、空中交通管制、电信、军事指挥与控制系统；智能制造中的系统查找、空间站和海底勘探等。
				>实时任务：对实时发生的事件响应。所以必须跟得上发生的事件的频率；
					>硬实时任务：必须满足最后期限；
					>软实时任务：可超过最后期限；
					--可确定性：等待服务的延迟：<1ms才是实时系统；军用飞机10-100us
					--可响应性：服务的时间
					--用户控制：用户可以指定一些特性
					--可靠性：处理器失败的响应。故障弱化操作；
						>抢占式调度：保证任务在最后期限内完成；
					>实时调度算法：
						>静态表调度法：执行可行调度的静态分析，
						>静态优先级抢占调度法：执行静态分析，但未执行调度，给任务指定优先级；使用 传统的基于优先级的抢占式调度程序；
						>基于动态规划的调度法：运行时动态的确定可行性，。分析结果是一个调度或者规划，可用于确定何时分派这个任务；
						>动态尽力调度法：不执行可行性分析；。任务到达-->系统指定优先级--->时限调度；
						--调度需要的信息：就绪时间、启动最后期限、完成最后期限、处理时间、资源需求、优先级、子任务结构，
						--调度问题：下次选择哪个任务和允许哪种类型的抢占；
						--优先调度最后期限最邻近的进程；
				>限时调度：
				>速率单调调度：为周期性任务解决多任务调度冲突。
					>最短周期的任务：具有最高优先级；
					--优先级反转：优先级高的等待优先级低的任务；
			>linux中的调度算法：优先级 实时进程。
				>系统中断一个FIFO线程条件：另一个更高优先级FIFO线程就绪；被阻塞--等待IO事件；自愿放弃--sched_yield.
				>调度顺序：优先级高的>等待时间长的；>轮转。
			>unix svr4调度：实时进程最高优先级；内核模式下的进程次高优先级；用户模式下最低优先级；
				>可抢占：实时可抢占内核/用户进程；
				>处理器亲和性：
			>windows调度：可抢占式调度；IO密集型线程优先级可能更高；	
		>输入输出/文件: IO管理和磁盘调度
			>IO设备的主要分类：
				>数据传输速率：
				>控制的复杂性：如磁盘的控制接口
				>传送单位：字节流/字符流/块传送
				>数据表示：不同设备使用不同的编码方式；字符编码/奇偶校验约定
				>错误条件：设备不同，错误的性质，报告错误的方式，错误造成的后果以及有效的响应范围，各不相同；
			>IO功能的组织结构：
				>执行IO： 
					>程序控制IO：处理器代表进程给IO设备发送一个IO命令
					>中断驱动IO：处理器代表进程给IO设备发送一个IO命令后，如果IO指令是非阻塞的，则继续执行进程后续的指令；否则下一条指令来自操作系统，它将当前进程设置为阻塞态并调度其他进程；
					>直接存储器访问DMA：内存和IO模块之间的数据交换---DMA模块控制。处理器-->DMA模块-->传送数据(内存/外存之间)-->中断发送给处理器
						>DMA：能在一个指令下，以后就自动执行(脱离系统总线完成)；逐字传送整块数据；
				>IO设计：
					>目标：提高IO效率。尤其磁盘IO的效率；第二：通用性--处理器看待IO设备的方式，操作系统管理IO设备和IO操作的方式；。模块化、层次化。实现基本功能如：读、写、打开、关闭、加锁和解锁等通用的函数；
					>逻辑结构：
						>组织1：
							>逻辑IO：即用户级别的设备API
							>设备IO：API的IO指令序列实现，通道命令和控制器命令。可以用缓冲技术提高效率。
							>调度和控制：IO操作的排队；和硬件设备真正交互的软件层；
						>组织2：
							>通信体系架构：如TCP/IP
							>设备IO：
							>调度和控制： 
						>组织3：
							>目录管理：符号文件名被转换为标识符；
							>文件系统：处理用户指定的操作；
							>物理组织： 对于文件和记录的逻辑访问必须转换为物理外存地址；
							>设备IO： 
								>面向块的设备：磁盘、USB智能卡。IO时一次传一块。
								>面向流的设备：终端、打印机、通信端口；字节流方式输出输入。
							>调度和控制： 
								>磁盘调度：磁盘比内存慢了4个数量级；
									>磁盘IO传送时序：等待设备(进程排队等待设备可用)-->等待通道(因设备和其他磁盘驱动器共享IO通道)-->寻道-->旋转延迟-->数据传输。寻道时间：定位到指定磁道耗时；目标扇区旋转到磁头：旋转时间；两个为存取时间。然后旋转扇区而磁头读取数据同步传输到内存:传输时间。寻道：10ms, 旋转2ms, 读取 b/rN ms。。由于寻道和旋转耗时，所以如果顺序读取磁盘上连续扇区的数据，那么可以减少大量无效的旋转和寻道，减少读取剩下的扇区的时间，而节省时间可能达到300倍。所以一次读取的数据的所在的扇区连续非常重要；
									>磁盘调度策略：选择 请求队列中排队的进程， 调度 给 IO设备；如果随机选择，则对磁道随机访问，效率低；所以要考虑进程要访问的磁道号--按照相邻的方式访问---最短的路径访问完所有的磁道--路径规划问题；可以是一个图论上的最短路径问题。
										>FIFO: 大量进程下近似于随机调度；
										>优先级：满足操作系统的其他目标。有短作业倾向；
										>后进先出：对于事务处理系统	，这种方式可以顺序读取文件。
										>最短服务时间优先：需知道磁头臂当前位置；最小寻道时间。但不一定平均寻道时间最短。
										>SCAN: 电梯算法；先沿一个方向扫描处理磁道请求，完成后反向。
										>C-SCAN: 电梯算法；先沿着一个方向扫完，在回到另一端 按同样方向扫描。
										>N步SCAN：队列分为N段，每段用SCAN方式来扫。
										>FSCAN: 队列分为2个，一次处理一个，另一个装新来的请求；
			>IO缓冲技术：用来平滑IO需求的峰值的一种技术；。可以提高操作系统效率和单个进程的性能；
				>单缓冲：读入时：IO设备数据先传输到系统缓冲区-->完成时进程将该块移到用户空间，并立即请求下一块；称为预读；且输入发生在系统内存 而非用户进程内存中，所以os可以将进程换出。。写出数据也是。
				>双缓冲：进程读一个时，IO设备写另一个缓冲?
				>循环缓冲：消费者/生产者模型。IO设备逐个写入，进程逐个读出。	
			>RAID: 一个组件有影响，则并行使用多个组件来提高性能；。磁盘阵列。数据分布在多个磁盘上，则多个IO请求可能可以并行处理。独立磁盘冗余阵列RAID
				>内容：一组物理磁盘驱动器。数据分布在这些物理驱动器阵列里。使用冗余磁盘容量保存奇偶校验信息--保证在一个磁盘失效时-数据具有可恢复性；
				>RAID0: 无冗余 .常用 。 超级计算机使用。关注性能和容量。忽视可靠性；
					>数据呈条状分布在所有可用磁盘中： 一个条带为 一个物理块、扇区等单元。数据按每个磁盘上同一个条带号存储---从而一个IO请求可以同时分散到n个磁盘读取--从而读取更多的数据。。。。请求模式和数据布局非常重要。	
				>RAID1: 镜像冗余 .常用
					>数据冗条带余：读请求从而可以被请求数据的任何一个磁盘提供服务，而不管哪个磁盘拥有最小寻道时间和旋转延迟；写请求则需要并行更新。读的吞吐量更大，但是写的吞吐量就更小了。
				>RAID2: 汉明码冗余
					>数据条带：同轴磁盘；写时直接同时写到同轴磁盘的多个盘上；读时则直接读出同轴磁盘的多个盘上相同位置的数据；从而提高速率---单位时间读出的字节数。
				>RAID3: 交错位奇偶效验
					>对异或运算：0 就是单位元。A^B=C, 则 A=C^B。 i个磁盘，从而Xk(i)= X(n)(i) ^ X(n-1)(i) ^ X(n-2)(i)........ 从而 如果 有一个Xk(i)异常，则用校验位和其他位进行异或运算就可以得到结果；
				>RAID4: 块奇偶校验
					>独立访问阵列；即可以满足并行执行不同IO请求，但数据传送率不高；。。写操作，也奇偶校验，执行2次异或得到新的校验位值。老校验位^改变位之前值^改变位当前值
				>RAID5: 块分布奇偶校验 .常用
				>RAID6: 双重冗余 .常用
			>磁盘存取过程中涉及的性能问题：
			>磁盘高速缓存：内存中 为磁盘扇区设置的一个缓冲区；包含磁盘中某些扇区的副本；IO请求就先请求这个缓冲区中的数据。
				>失效时间：
				>置换算法：当缓冲区满了，新增一个扇区则要换出一个扇区；。LRU算法。
					>最不常使用页面置换算法：LFU. 记录访问次数；置换访问次数最少的。
			>磁盘IO性能模型：
			>UNIX SVR 4 IO: 每个单独的设备和一个特殊文件关联；从而向设备交互转为向该特殊文件读写。。。。DMA将数据从内存转移到磁盘，不消耗处理器，但是会消耗总线周期。
				>空闲列表：高速缓存中的可分配内存槽列表。
				>设备列表：当前与每个磁盘相关联的所有缓冲区。
				>驱动程序IO队列：正在某个设备上进行IO或等待IO的缓冲区。	
			>Linux IO：	可以识别 块设备、字符设备、网络设备。
				>磁盘调度： 
					>电梯调度算法：为磁盘读写 维护一个 队列；队列上可以执行 排序和合并功能；排序字段：块号。处理磁盘请求时，磁盘驱动器向一个方向移动，以满足该方向上遇到的每个请求；
					>最后期限IO调度程序：进程写请求是异步的。读操作则必须等待；新来的请求放到三个队列(读/写)中。一次从队列中取出所有到期的请求或一个头部请求。
					>预期IO调度程序：处理同步读请求，即处理一个读请求后 延迟一小段时间 看看附近是否有新的读请求出现，则可增强整个系统的功能。
				>页面缓存：缓存虚拟内存的页面；单独的缓冲区高速缓存--用于块的输入输出。脏页写回时，可以批量有序，从而更高效；。局部性原理，一个页面失效前可能再次被使用--避免不必要的IO。	
			>windows IO:
				>高速缓存管理器：特定文件的高速缓存--可变大小。
				>文件系统驱动程序：软件驱动程序。
				>网络驱动程序：
				>硬件设备驱动程序：
				>异步IO和同步IO：异步：IO操作排队；	
			---磁盘调度、高速缓存、RAID1同轴和冗余等方式是增强IO性能的手段；
		>文件管理：
			>文件： 长期存在、可在进程间共享、内部结构可定义。field-record-file。文件是一组相似记录的集合。
			>文件系统： 对文件的存储、管理；提供 增删改查、打开(声明文件状态)关闭(之后不能再对文件读写)读写 接口。维护文件属性：所有者、创建时间、最后更改时间、访问权限。
			>文件组织和访问技术：
				>文件组织形式： 堆--对大多数应用不适用。数据按到达的顺序被收集。顺序文件--记录相同域，像表格。索引顺序文件--增加了 用于支持随机访问的文件索引+溢出文件(记录的新的域的存储)---单条记录访问更快；。。索引文件--例如mysql的索引文件。
				>B树：linux/windows文件系统中使用。
					>节点的关键码数量：不能超过最大关键码数量。
					>关键码非递减顺序：
					>每个关键码左边都有一个比它小的指向更小关键码节点的分支指针：最右边还有一个大于最右关键码的指针。
					>度数d: 则节点最多 2d-1个关键码，2d个指针。至少d-1个关键码，d个指针/子女。根节点最少1个关键码和2个子女。
					>新增：1.加上后少于2d-1,直接新增；2.加上后刚好2d-1,加上后均分d-1，中间那一个提到上一层节点(或者先对已有的2d-1均分，中间节点提上去，再将新增的放入某一个节点)。3.递归判断父节点是否要分裂；
			>文件目录：
				>
			>文件共享：
			>记录组块：
				>文件分配方法：
					>顺序分配：文件A从块x开始连续n个。
					>链式分配：文件A从块x开始，链式n个。
					>索引分配：使用大小可变的分区，局部性好；使用固定大小的分区--消除外部碎片。索引块 存储 有序内容块的索引。最普遍文件分配形式。
				>空闲空间管理：
					>磁盘分配表：DAT. 块的空闲与否：bitmap表示/位表。
				>卷：一组 在辅存上 可寻址的 扇区的集合。操作系统 或 应用程序 用 卷 来存储数据。	
			>辅存管理：
			>文件系统的安全性设计：
			>unix文件管理：
				>文件类型：
					>普通文件：字节流。
					>目录文件：包含文件名列表+指向索引节点的指针。具有特殊写保护权限的普通文件。文件系统写，用户程序读。
					>特殊文件：每一个IO设备都有一个特殊文件和它关联。不包含数据。
					>命名管道：缓存队列。进程间--消费者-生产者模式通信。
					>链接文件：已有文件的另一个可选文件名。
					>符号链接：数据文件。包含了其所链接的文件的文件名。
				>索引节点：控制结构，包含操作系统所需的某个文件的关键信息。直接指针和三个间接指针。
					>120字节的地址信息： 等价为 15 个 64位 地址信息。前12个 直接指向文件的前12个数据块(每块>4KB)，第13个地址指向一个索引块--索引块里指向若干个数据块；第14个地址指向二级索引块--内容指向若干个一级索引块；第15个地址指向三级索引块--内容指向若干个二级索引块；所以这个地址下文件可以最多存512GB数据。
				>文件分配：块为单位，动态进行。不一定连续块。
				>目录的每个目录项：文件名/目录名 + 索引节点号。	
				>卷结构：
					>引导块: 包含引导操作系统的代码。
					>超级块: 包含有关文件系统的属性和信息。
					>索引节点表：系统所有文件的索引节点集。
					>数据块：数据文件和子目录所需的存储空间。
			>linux虚拟文件系统：VFS。支持大量的文件管理系统和文件结构。VFS向用户提供了一个简单且统一的文件系统接口。定义了一个能代表任何文件系统的通用特征和行为的通用文件模型；		
				>文件：文件名--标识文件，所有者、对未授权的访问和修改的保护(拒绝/要求提供密码)和其他一系列属性；文件可被创建、读写或者删除。
				>文件调用过程：进程使用VFS用户接口的系统调用--->linux虚拟文件系统 调用VFS中的一个函数，再 从 映射函数 找到 VFS具体系统调用函数 对应  具体目标文件系统 上 对应的函数 来实现调用目标文件系统上的相应函数。 映射函数：是目标文件系统 在linux 上的实现的一部分。---->目标文件系统再将系统请求转换到面向设备的指令。
				>四个对象：
					>超级块对象：表示一个已经挂载的特定文件系统
						>挂接的设备：
						>基本块的大小：
						>脏标志：
						>根目录指针：
						>控制访问文件系统的信号量：
						>指向操作超级块的若干个函数指针(形成数组)数组的指针：函数指针数组里的函数指针包括：read_inode,write_inode
					>索引节点对象：表示一个特定的文件。和一个特定文件关联，包含除了文件名和内容的所有信息。
					>目录项对象：表示一个特定的目录项。包含：指向索引节点的指针+超级块，还包括一个指向 父目录的指针和指向子目录的指针。
					>文件对象：表示一个与进程相关的已打开文件。opem()时创建，系统调用close()时销毁。
				>三个缓存：
					>索引节点缓存：每个文件和目录都由 一个VFS索引节点表示，。存储最近访问过的索引节点。
					>目录缓存：目录名称--索引节点号  映射对的存储。
					>缓冲区高速缓存：独立于文件系统，请求块设备驱动程序 读取物理磁盘上的数据时，先检索 高速缓存存储器。
			>windows文件系统：NTFS		
				>特征：
					>可恢复性：文件系统的每个变化 都 视为原子 动作，变化使用一个事务处理模型 来实现这个目的。
					>安全性：打开的文件 作为一个文件对象 来实现，且有 一个定义其安全属性的安全描述符。
					>大磁盘大文件：支持。
					>多数据流：文件实际内容当作字节流。
					>日志：维护一个 记录 卷 上 文件修改的日志。
					>压缩和加密：目录和个人文件可以被透明的压缩加密。
					>硬链接和符号链接：支持。
				>卷和文件结构：
					>扇区：磁盘最小物理存储单元。
					>簇：一个或者多个连续的扇区。最基本的分配单位。卷越大，簇的扇区数越多。
					>卷：磁盘上的逻辑分区。一个多个簇组成。可以是整个磁盘或者部分磁盘，或者跨越多个磁盘。采用硬件或者软件的RAID5时 ，卷由跨越多个磁盘的条带组成。
						>布局：4个区域
							>分区引导扇区：卷的布局信息。文件系统的结构。引导启动信息和代码。
							>主文件表：卷中所有文件和文件夹的信息。未分配的可用空间。
							>系统文件：MFT2，日志文件---事务步骤列表，簇的位图--哪一簇正被使用；属性定义集--定义该卷支持的属性类型
							--SQLie: 不是独立进程，而是它的库被链接到应用，成为应用的一部分。
				---总结：文件访问、目录维护、访问控制。			
		>嵌入式系统：嵌入式操作系统。TinyOS.eCos..。。汽车中的防抱死系统 也是一个嵌入式系统。		
			>存储空间的限制、功耗、和实时需求：
				>实时操作：
				>响应操作：
				>可配置性：
				>IO设备的灵活性：
				>改进的保护机制：
				>直接使用中断：
			>必要性特征：
				>快速轻量的进程和线程切换：
				>调度策略实时：分派模块是调度程序的一部分。
				>快速响应外部中断：<10us
				>为存储管理提供固定或者可变的分区：
			>嵌入式linux: 支持特定的设备、外设和协议。可以灵活配置。
				>使用闪存：持久存。
				>文件系统：简洁。cramfs--简单的只读文件系统。squashfs:压缩的只读文件系统，用于低内存环境。jffs2:基于日志的文件系统，面向闪存---可穿戴设备。
			>TinyOS: 核心操作系统的代码和数据只需要 400B的内存。非实时。没有内核，因为没有存储保护。基于组件。没有进程，没有存储分配系统。完全无阻塞，很少直接同步原语。用于无线传感器网络。无线通信硬件、微型机电系统	
				>网络-PC-基站-无线传感网络：
				>目标：允许高并发性、在有限的资源下操作、适应硬件升级、支持广泛的应用软件、支持不同的平台、应是鲁棒的---单个传感器冗余。
				>组件：调度程序组件、标准组件(单跳网络/自主路由/电源管理/定时器/非易失存储控制)。软件组件由nesC 实现。通过接口与组件进行交互的模型。基于事件的并发模型。组件顺序相连(发命令和收事件信号)。最底层是硬件组件，最顶层是应用组件---符合TinyOS组件的结构。
					>组件内的任务：类似线程。任务原子--开始执行就要执行结束---单个组件内的任务不被其他任务抢占。任务可被事件抢占；所以: 任务栈。
					>命令：不可阻塞的请求---让底层组件完成某些服务的请求--如初始化一个传感器读操作。。。接收到命令后：调度任务
					>事件：直接或者间接的与硬件事件关联。
				>调度程序：全部组件的全部任务中，只有一个正在执行。	
		>虚拟机： 
			>虚拟化方法：
				>虚拟机管理程序：Hypervisor， 使得 多个虚拟机安全的共存于一台物理服务器主机并共享主机的资源。整合率：4:1 单主机虚拟机数量。利于服务器整合。
				>服务器虚拟化：虚拟化使得单台物理机上运行多个多个虚拟机。虚拟化隐藏了服务器资源，
				>创建虚拟机：可以为虚拟机配置一定的处理器、内存、存储资源和网络连接端口。创建后，可以像物理服务器一样启动、加载操作系统和软件解决方案。
					>虚拟机本地的操作系统需要执行的特权指令：由虚拟机管理程序 代理执行。
					>虚拟机构成：文件 几个。描述虚拟机的各种属性：分配了的各个资源量。方便备份，整合和快速资源调配。
				>虚拟机增加了可用性：一台物理机上的虚拟机在物理机崩溃后 可以 在集群中另一台好的物理机上恢复和启动------使用隐藏的虚拟机来同步执行任务并容错；确保物理服务器失效时不会丢失事务，也不会增加复杂性；。且可以将一个正在运行中的虚拟机迁移到另一台物理机无需中断、回退和影响该虚拟机的用户。虚拟机迁移不需要停机。虚拟机可以根据使用情况自动进行迁移----比如一台虚拟机开始申请更多资源--其他虚拟机就可以自动迁移到其他由可用资源的主机上。
				>虚拟机分类：
					>I类作为轻软件层直接运行在物理服务器上，更像os.几分钟完成安装和配置并提供给虚拟机使用，。虚拟化主机聚集在一起可以提高可用性和负载平衡能力。如VMware ESXi, Hyper-V,Xen系列。
						>特点：直接控制主机的物理资源。性能更好。允许更多的虚拟机。安全性更高，虚拟机请求资源时 会在外部处理，无法影响到其他虚拟机和支撑它的虚拟机管理程序。
					>2类作为传统应用程序运行在windows/linux之上。如 VMware Workstation 和 Oracle VM Virtural Box 
					--半虚拟化驱动：
			>实现虚拟机的处理器/内存管理/IO问题：
				>处理器问题：
					>软件方式模拟芯片：并提供访问芯片的接口。如安卓模拟器。
					>向虚拟机提供主机物理CPU的时间片：虚拟机的操作系统向cpu发出一个指令--->虚拟机管理程序拦截请求，调度主机的物理处理器的时间，发送执行请求并将结果返回给虚拟机操作系统。确保高效利用物理服务器的处理器资源。当多个虚拟机争夺处理器时，虚拟机管理程序充当交通控制器，调度各个虚拟机请求的处理时间、处理请求并将结果返回给虚拟机操作系统。
					>保护环：描述了计算机内部的系统或特权的访问级别。最可靠的称为 Ring0,操作系统的内核运行区，直接和硬件交互。Ring1和Ring2是设备驱动执行区，用户应用程序运行在最小信任区Ring3。这种隔离可以防止无特权代码的不可信行为，如系统关机或未经授权的访问磁盘数据和网络。
						>虚拟机管理程序运行在Ring0区：为其托管的虚拟机控制硬件访问。。虚拟机操作系统也认为自己运行在Ring0，但实际上请求命令被虚拟机管理程序拦截，模拟了请求的执行，实际上为了保护其他虚拟机可能没有实际的执行----如关机。
				>内存管理问题：
					>虚拟机使用内存资源时：虚拟机管理程序 会 使用转换表 管理内存请求，使虚拟机操作系统将内存空间映射到预期的地址。
					>页共享：虚拟机管理程序 自带的帮助优化内存使用的功能。
					>管理虚拟内存到物理内存的映射：能确定某个页面是否已经加载到内存，重复页面则不再加载，而是共享一个物理页，并在虚拟机的转换表中 提供 到共享页面的链接。如果虚拟机都使用相同的操作系统和应用，则页共享能节省10-40%的物理内存。
					>自动精简配置技术：允许管理员分配给用户的存储资源超过系统的实际大小。
					>膨胀技术：回收内存---将虚拟机操作系统的页面挤压到磁盘。。。多主机集群中，虚拟机可以在主机资源稀缺时自动实时迁移到其他主机。
				>输入输出管理问题；设备抽象。
					>虚拟机操作系统调用设备驱动：这个设备是模拟设备 并由 虚拟机管理程序创建管理----虚拟设备挂载在虚拟机管理程序的输入输出栈上--并与那些映射到主机物理设备的设备驱动 通信---将虚拟机的输入输出地址转换为物理主机的输入输出地址。虚拟机管理程序 控制和监视 虚拟机设备驱动的请求，通过输出输入栈 发送到物理设备，再返回(到虚拟机设备驱动)。
			>VMWare ESXi 、Hyper-V、Xen、JavaVM的区别：
				>ESXi: 虚拟机管理程序的核心：虚拟化内核。典型的虚拟机管理程序--安装需要32MB空间。大小：100MB.。=VMkernel + 无代理系统管理 + 无代理硬件监视 + 配置和支持命令行。
					>特性：可用性：可扩展性、安全性、可管理性、性能。
						>存储迁移：运行中的虚拟机 文件进行迁移并组成一台虚拟机。
						>容错功能：为虚拟机在另一物理主机上创建一个时钟同步的副本。如果原始主机发生故障，则虚拟机的连接转移到副本，无需中断用户和它们正在使用的应用。
						>站点恢复管理：在数据中心灾难时 使用各种复制技术 将 选定的虚拟机复制到第二站点。第二站点可以在数分钟内启动，虚拟机以选定和分层的方式启动，。
						>存储和网络输入输出控制：允许管理员 细粒度 分配虚拟网络中的网络带宽。
						>分布式资源调度：DRS，智能部署虚拟机，通过商业规则和资源使用 来 实现自动负载平衡。分布式电源管理DPM能够根据实际需要 关闭和启动 物理主机。存储DRS能够基于存储能力输入输出延迟动态的迁移虚拟机文件。
				>Hyper-V 和Xen系列：
					>Xen虚拟机管理程序：
						>域0：运行Xen的工具栈，配合虚拟机管理程序的专用操作系统。
						>域U: Xen上的虚拟机---未授权的域/用户域。域0通过后端驱动和域U的前端驱动沟通，进而向虚拟机提供 网络访问和存储资源。
					>Hyper-V: 
						>父分区：作为 虚拟机管理程序的管理助手， 管理 虚拟机管理程序、虚拟机分区、设备的驱动程序，运行windows服务器操作系统。使用一个虚拟服务器提供商VSP来提供设备到子分区的服务。
						>子分区：虚拟机。子分区使用虚拟服务客户VSC/消费者 来 与 VSP 沟通 来完成它们的IO需求。
				>Linux VServer: 提供一个共享的虚拟操作系统镜像：根文件系统+一组共享的系统库+内核服务		
					>宿主机平台；共享的操作系统镜像和一个特权虚拟机。
					>虚拟平台；创建虚拟机。
					>虚拟服务器：Linux内核将每个虚拟服务器和其他虚拟服务器 隔离开来。
						>隔离机制：chroot,chcontext,chbind,capability
							>chroot: 一个linux命令，特权用户执行，以便让一个进程只能访问文件系统的受限部分。提供了文件系统隔离。虚拟服务器执行的命令 只影响为 该服务器指定的 根目录 下的那些文件。
							>chcontext: 分配一个新的安全上下文，并在这个环境中执行命令。宿主机的安全上下文是 context0,与根用户 拥有相同的权限。context1 用来观察其他环境，但不能改变这些环境。其他环境 都是完全隔离的，一个环境中的进程 既不能看到 其他环境中的进程 ，也不能与它们进行交互----从而提供了在同一台计算机上同时运行若干相同环境的能力--而在应用层这些环境不能交互，因此每个虚拟服务器都有自己的执行环境---因此提供了进程隔离。
							>chbind: 工具。执行一个命令，产生的进程和子进程锁定到一个特定的IP地址，所有由该虚拟服务器通过系统网络接口发出的数据包 的 发送IP地址 ，都会被指定 为 由 chbind的参数确定的值。这个系统调用 提供了 网络隔离。每个虚拟服务器使用一个 隔离且不同的IP地址，，进入某个虚拟服务器的网络数据 自然 不能被 其他虚拟服务器 访问。
							>capability: 对根用户 可用的 所有权限的 一个分割。提供了 根的隔离。
						>进程调度：虚拟机设备提供了一种控制虚拟机处理器时间的方法。
							>令牌桶算法：每个虚拟机一个，虚拟机的进程正在执行时， 在定时器的每个周期消耗一个令牌---从而消耗的令牌数 表示 消耗的处理器时间。
		>计算机安全技术：
			>操作系统安全问题：
				>操作系统将每个进程和一组权限关联：指明进程可以访问的资源。内存区域/文件/系统权限指令。
				>如何阻止和检测到用户或恶意软件 在系统中尝试获取未被授权的 权限的行为：如尝试获取root访问权限。
					>入侵检测：一个能监控和分析 系统事件的安全服务。IDS: 传感器，分析器，用户界面。
						>用户认证：
							>识别：提供识别符
							>证实：提供证实 识别符 和 这个实体 之间存在绑定 的 认证信息。(这个识别符就是这个实体的)(证明材料/证明信息 只有这个实体有---其他人不知道/无法获取)
								>认证方式：个体知道的信息：密码，个人识别码PIN,预定义问题集的答案。个体拥有的信息：物理钥匙、电子卡---令牌。指纹/视网膜/笔记特征。
						>访问控制：谁(证实/未证实的用户)对谁(什么资源)能访问，访问到什么程度(访问类型/权限级别)	。
							>访问的范围/资源范围/领域范围/对象范围：
							>访问的权限级别/操作级别/动作类型/动作集合/受限动作集合：哪些用户能对哪些资源进行怎样受限的访问。
						>防火墙：保护本地系统和系统网络 免受 网络的安全威胁。对因特网的访问控制(双向)。	
			>文件系统的安全设计：
			>入侵者行为模式：
			>两种访问控制方法：
			>防御缓冲区溢出攻击：
				>阻止未授权的对进程的内存内容的访问：
				>缓冲区溢出：缓存区界限之外存储数据--覆盖了相邻的内存位置。栈上/堆上/进程的数据段上。造成数据损坏和程序控制流异常跳转。
					>产生原因：未经检查的将数据放到缓冲区。
				>防御：
					>编译时防御：编译程序时配置程序 来 检查和阻止缓冲区溢出。如加入额外的代码来检查 栈帧的崩溃。
						>语言设计：空间利用率、性能、类型安全。
						>栈溢出攻击：canary技术。
					>运行时防御：	
			>访问控制： 
				>文件系统访问控制：
					>访问控制模型：访问矩阵：主体x资源, val=访问权限。按列划分---称为访问控制列表(每个对象的用户和访问权限)。按行划分---权能标签(指定用户被授权的对象和操作) 
					>访问控制策略：
						>自主访问控制：主体-对象-权限 矩阵。 主体请求时，发送信息(S0,a,X)给对象的控制器，控制器决定是否通过。访问矩阵控制器  则控制主体对 矩阵的值的修改。
						>强制访问控制：
						>基于角色的访问控制：用户在系统中的角色，决定它的访问权限。用户-角色-权限 矩阵。 
				>unix访问控制：		
					>传统unix文件访问控制：
						>用户：标志号。用户ID。属于若干个组，组有组ID.。创建一个文件时，被指定为属于某个用户，创建人的组。
						>文件：关联12位保护位---文件索引节点的一部分。避免组太多，而使用访问控制列表。
							>保护域结构：用户关联。可以改变用户ID。
						>访问控制列表：将组和用户 分配给 文件。同时每个用户/组 对应三个保护位：读/写/执行。9位权限域：命令用户和组分别由3位 权限域。
							>一个进程访问一个文件：选择与进程匹配最紧密的访问控制列表项。项的查找：所有者---<命名用户-->组，其他。再检查匹配的项 是否包含 关键权限。属于的多个群组的权限的集合。
			>操作系统加固：			
				>安装操作系统并安装补丁更新：断网安装。最少组件。驱动具有内核权限，第三方的注意。
				>删除不必要的服务、应用和协议：
				>对用户、组和认证过程进行配置：用户的分类，所有者的权限、可访问的信息类型，以及在何处进行定义和认证。
				>对资源控制进行配置：
				>安装额外的安全控制：如杀毒软件
				>测试基本操作系统的安全性：
			>windows安全性：统一的访问控制功能。
				>用户登陆：用户名密码来认证和授权。成功则为该用户创建一个进程，并创建一个相关联的访问令牌。进程访问时，安全子系统 会检查 进程相关用户的令牌 看访问权限。
					>权限赋予、认证和回收：
					>访问令牌：安全ID--标志用户；组SID--所属组-组有权限；权限--系统服务列表；默认所有者--创建者。默认ACL：用户拥有的对象的ACL
					>访问控制列表：头部+访问控制标记位。。矩阵中每个元素都是一个32位的标记位。
				
		>分布式处理、客户-服务器和集群：
			>客户-服务器计算：
				>应用程序和底层通信软件/操作系统之间 标准的接口和协议：中间件。
			>分布式消息传递：
			>远程过程调用：
			>集群的原理设计：
				>优点：
					>绝对可伸缩性：创建大型集群。
					>增加可伸缩性：增加节点 只需少量额外工作。
					>高可用性：节点的失效不意味着 服务的失效。
					>高性价比：廉价计算机。
				>分类：节点 有共享磁盘--RAID系统 或者不。	
				>集群方法：
					>主备：主 挂 从 接管。主服务器工作期间 从服务器不提供服务。
					>主从：主从都服务。但只有主有磁盘/数据库。
					>主从且独立数据库：数据复制存在一致性和开销。
					>对称+共享磁盘RAID系统：RAID故障和补偿磁盘故障的消耗。
						>公共磁盘：若干卷，每卷一台计算机？
				>增强功能：
					>故障管理：
						>故障补救：将应用程序和数据资源 从 发生故障的系统 交换 到 集群中的另一系统上。
						>故障恢复：原系统修复后，将应用程序 和 数据资源 恢复到 原有系统 。
					>负载平衡：
					>并行计算：
			>windows服务器集群：		
		>附录：简化操作系统：OS/161,System/161,	