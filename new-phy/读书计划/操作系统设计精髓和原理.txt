---------读书战略：自顶向下，从应用层到底层细节。先熟悉的常用的，后底层的不常用的。精读好书---《深入理解系列》
--------es的处理思想都对应有 相应的“某种举动 及其导致 的问题”
>需求背景-痛点陈述：现实开发中遇到了什么痛点导致XXX的开发？  
>那么痛点的原因、产生的条件：分析是什么环境、什么动作 什么效果什么目的 等精准形容词的事实描述 导致了痛点的必然发生，难以避免？。条件-痛点。原因-结果。
>则可以消除痛点的最简单的精准事实陈述是什么：修改“条件-痛点”陈述的哪一部分就可以导致没有痛点产生。 要做的根本事情是什么：
>那么新陈述表明的解决动作是什么：
>新情况的新痛点是什么：新举动、新环境会产生的新痛点描述出来， 继续上述4条操作。
>学习要有战略和格局：过于零散、孤立、末支、叶子的知识点就没必要化太多时间，懂得放弃。聚焦在根节点、枢纽节点、产生分支的节点、主干知识点、枢纽知识点、关联到很多知识点的知识点上。
 >对于主干知识点：要有全新的认识视角和进行精细的描述，大量的提问和好奇和进行必要的实验以获取支撑观点/导出观点的数据。
 >规范是工程最独特的特征.
 >慢慢读：
>一种新技术的学习：
 >它面对的情况和问题、它的世界观、它的方案、它的方案验证/论证/能处理的解决的所有情况及能成功处理的理由/功能边界
  >所有的软件：都可以看作是向上封装一层接口，根据自己的世界观封装底层而向上/对外提供统一的(统一的更简单的更直观的更业务的更少底层信息的)接口，底层包含一系列的第三方的插件/构件/组件；内部则去做兼容和调用(对底层)(对上层则做逻辑分解和底层实现)。
>知识混乱就是因为没有组织：
	>组织就是关键字树：几个单词就是每层上的每个节点的内容；
	>组织也可以看作逻辑树：有逻辑关系，逻辑顺序，逻辑联系的关键字的层层集合。层层囊括更精细的范围，层层划分范围。
>推进理解的属性发展拓展、问题延展：重要方式；
>什么是架构：架构也是从抽象到具体的考虑和描述；树形延展开来，可以写满非常大的黑板和巨大的脑图！！sharding-jdbc,dubbo,spring都可以这样方式来展现它的架构！！它的抽象到具体的考虑---本身才是架构！！！而不是什么模块、模式之类！！
>抽象设计：则某一层就不管上一层的含义和下一层的含义，即更抽象的含义或者更具体的含义；而是实现本层的含义；完成本层的含义指定的功能；。如网络协议的架构设计；	
>面向设计来理解，面向架构设计来理解，面向架构问题一层一层来理解它：面向设计来理解，所以按照面向对象设计的方式，看其中的对象、行为属性、流程环节逻辑。	
>找不到知识/描述 所对应的问题 ， 那么看书将没有条理纲领，变得零散琐碎没有组织。	
>不是按概念方式组织，而是按架构、问题方式来组织 笔记，书本内容。架构顺序，问题层次顺序。	
>架构不是设计出来的，也不是演进出来的(甚至不是迭代出来的--尽可能避免迭代)：而是问出来的。	
>每个方法方案都从属于一颗树，所以找到一个方法巧妙方法仅仅是第一步--找到从属的层次树 有更大的价值；(无论是谁想到的方法/概念，都要这样更进一步)
>解决问题的办法就是提出问题：类似递归和动态规划；。。权衡就是线性规划；	优势劣势在一定场景下也是劣势优势；
>一个词，到一句话，两句话，一段话，一篇文章；这个就是抽象总结，层次总结；越简洁，站得越高
--在网络、搜索引擎、推荐系统 三方面的专家；作为系统方面的独特优势/拔高优势；(网络-查询-推荐)
	
----有且只有响应，通信端才知道连接是否成功；。浏览器自动扩展。
----维持连接，并发连接，都是软件的实现，物理上看都是一条出口；从响应就是维护连接的角度看，不存在需要维护什么连接，维护就是维护连接数据而已；只要发送响应，连接就活了；在网络端口出口，可以连续发送不同目的地的响应报文，这就是并行；所以完全可以用队列来接收请求数据包；而用队列缓存发送响应数据包；多核使用起来，来并行大批量的发送和接收；不存在要维护和持续占用“端口”网络出口这种概念---完全没必要，用完即走 就可；	
	>或者不存在连接这个概念：所有的事情就是接收数据包和发送数据包(接送/发送缓冲区)。(连接 是 软件臆造出来的概念，不要和物理对应；和物理对应就会束缚思想，就会很多事情理解不了不知道原因)
	>连接的状态转移图；
	>应用的固定端口：实际上是建立新TCP连接的请求的处理的端口，请求到达这个端口--后面建立一个独立的TCP连接---来负责和客户端通信-交互数据；
----UML：为什么类继承关系图---因为这就是具体到一般的概念对象抽象过程。自上而下是能力顺序，能力组合；	
----说话和介绍：语速不要快，快就是掩盖问题，掩盖过程步骤；直接导致别人认为思路不清晰，表达不清楚，东拉西扯；也不利于自己思路的成长和扩展和自己主动发现问题，且必然导致不简洁--废话很多；
	>介绍需要先纲目后具体：抽象到具体；而不是张口就是罗列枚举---内容没有结构--全是线性结构；
	>描述更精简：一个字一个词，一句话，两句话，一段话；
----大事和吏治：大事 就像西天取经；吏治就像管理四人；


--计划：nginx/tomcat-->计算机系统-->架构-->自己的系统架构方案:专题研究、大提问、大总结。大简化/模型图化；
>一个进程看作一个消息，代码计划/任务计划；；都是异步隔离；	
	>程序启动点/执行点：可以多个，看作是并行的；(一个机器上，多个程序文件里)；可以留下执行点/新增执行点；可以删除执行点/减少执行点；
	>函数式编程为什么好：因为每个精细环节清晰描述确定了下来；使得充分配置和指明动作；
	>如何看待对象的方法：所有的对象都是被动的；主动的只有cpu/并行点；
	>程序的执行要想象为人在执行；多线程则是交接执行权给其他人执行；
	
----未知和迷惑的地方：痛点	；
----关键和核心的地方：要点

--混乱的答案，宁可不说；只回答真正掌握的；。没有逻辑，因为没有进行抽象；没有找到所在的流程环节、模型中的位置
--系统、中间件的介绍，不是一来就是组成结构；这层次已经太细了太具体了太里面了，必须要从最简洁最抽象最上层开始；最表面最近开始；务实，不僵硬，不突然，要自然，不要忽视和没注意没意识和跳过很多步；而是从问题出发、从困难出发、从疑惑出发
	>从问题出发：先明确问题；先明确表达出问题、疑惑点、黑箱、痛点、矛盾点、难点，表述的范围可以很大(完全不知道是什么怎么办)后面逐渐具体问；无论多少问题，先明确下来；尤其要全部且完整的描述下来；
		>问题的提出：先明确背景，自然衍生、过渡、转折、演化，逻辑关系上，什么时候什么事情什么人，事情什么阶段遇到的什么问题、阻碍、阻挠、缺陷、瓶颈、不够简洁、不够简便、不够方便、不够优雅、离目标远、离理想情况远、离期望/极限效果远；不够抽象的地方；把它们充分描述完整叙述结构式组织起来。
			>问题抽象：归结为一类问题；去除具体和细节而明确问题模型；
		>问题产生原因：过程；条件；	
		>问题导致的恶果：阻碍、损失；
		>理想的方案特征/效果/必做必不做的动作&事情/应当改变的环节: 
			>这种特征/必做必不做的前提、必要条件、必然要求、必然说明、必然指示、必然可以确定的更多的事情/结论：
				>一系列结论、约束得到之后(结合条件/问题/情况本身)逐渐可以清晰看到/归结出该具体问题符合的/满足的通用/一般的/一类的问题模型/函数模型/服务模型/IO模型/请求响应模型的轮廓：若干个具体模型
					>方案的装饰/补充: 补充可靠性/稳定性/高性能(从而高可用/高并发)：因为暂时只是一个裸机、容易受到伤害、有功能但没有抵抗力(仅为打火机的火而不是熊熊大火)
							>方案的用法规则：在请求缓存前使用
		>能将具体方案进行分类的维度/情况/模型/环节/流程/抽象表述 的确定：然后使用 抽象-具体 的方法来得到新方案；					
		>普通的方案：已有的方案；方案的抽象，方案的取值选择评价；方案的表象缺陷、劣势；。。模型、数据结构和算法、协议约定分担 维度 上考虑；
	>任何事情/事物都有顺序/逻辑：且几乎都是几种常见逻辑中的一种: 时间先后、空间远近、因果环扣、程度递增
--大总结：含义包括：重新 深刻理解：
--通用的建模架构能力+Flink深度强化学习的推荐系统。。。。而不是做简单的业务逻辑开发；用深度强化学习来做应用/解决实际问题(用户的识别问题和抉择问题)；用抽象建模架构出逻辑完整的方案(工具方案/服务方案)；
--一体两翼的发展模型：底座：增强操作系统、网络、搜索、推荐能力； 两翼：普通项目：则架构建模；特殊项目：则深度强化学习；。。四大基础+两大实践(应用/使用)。。基础：是为了解决自己的问题；实践：为了解决别人的问题(用户的问题/大众)；
--一次彻底弄懂，而不是 反复低温加热。看架构书和源码书，不看使用书。
--对话中胜利：一个是提问，二个是不断的输出-高能输出。
--牢固的观念: 系统都是被使用的。
--任何一个系统、产品、服务、方案、东西、事情，它要解决的核心问题是什么？理想的形态效果影响应该是什么？市面上对应的哪些产品达到了或者没达到或者很难达到？没达到是为什么是否有我们的机会？是否还有我们可以满足的缺口。找市场缺口。
--从缝纫机原理看方案所属的分类和方案内的环节。抽象出分类和环节。
--把自己当做cpu,调/使用各个服务/接口/类/系统。
--全新学习掌握方法：先定问题体系，先提问，定逻辑路径，后开始找答案--推导和思考和查阅资料。
	>旧方法：还是盲目阅读，还是从头到尾的阅读一遍的阅读。


--商业经营才能：(全新的解决问题的方法：提出问题)

>举动-痛点：资源管理、资源调度、多核设计 和 容错机制
	>解法/解决方案： 
		>计算机系统的组成：
			>处理器：
				>内部寄存器：
					>存储器地址寄存器：MAR 存确定下一次读写的存储器地址
					>存储器缓冲寄存器：MBR 存要写入存储器的数据或者读出存储器的数据。
					>IO地址寄存器：IO AR 用于确定一个特定的输入输出设备
					>IO缓冲寄存器：IO BR IO模块和处理器之间减缓数据。
			>内存：
			>IO模块：
				
					
			>总线：
		>处理器执行一条指令的步骤：
		>处理器如何和为何利用中断：注册中断、设置中断、检测中断、响应中断。程序注册中断后释放，硬件设置中断后cpu检测到而响应中断。
			>中断：中断的是处理器。IO设备/程序/时钟模块都可以产生中断信号。
				>例子：外部设备发出中断信号，处理器收到后暂停当前处理程序，而转去处理服务于特定I/O设备的程序---中断处理程序；处理完成后恢复原先程序的执行；
			>处理器如何检测中断：每次执行指令后，都去检查中断	
			>上下文的保存：系统栈/控制栈。
			>中断优先级：多个中断发生时的执行顺序。
		>计算机存储体系的每一层：
			>存储器：容量、速度、价格。
				>高速缓存：对os不可见？。包含：若干个槽，每个槽K个字，每个槽一个标签--高c位地址，其余位地址表示的地址范围数据放在槽中(可能64个)，
					>映射函数：块占用哪个高速缓冲单元的映射算法。
					>置换函数：选择块从高速缓冲中移除。
						>写策略：如果块已经修改，则需要在移除前写回内存。策略1：更新后就回写。策略2：置换时才回写。
		>直接内存存取：DMA.。处理器的委托 和 IO设备 传输数据(会占用总线)，处理器不需要中断，只需要开始告诉DMA和谁IO，DMA则独立和IO设备交互，而完成后向处理器发送中断信号；
		>多核计算机组织结构：对称多处理器SMP.。一个芯片上多个处理器--每个都独有L2，共享L3
			>连接：总线互联。共享内存/IO设备
			>高速缓冲一致性问题：一个高速缓存失效后必须通知其他高速缓存失效；---硬件来解决而不是操作系统。
			>快速通道互联：QPI: 点对点的电气互联规范；----在相连的多个处理器芯片间实现高速通信；速率：单向：12.8GB/s
		>局部性概念：多级存储体系的性能
		>栈对过程调用和返回的支持：
		>操作系统：应用程序和计算机硬件之间的接口。
			>目标：更充分有效(压榨)的利用计算机资源，更方便的使用(计算机资源)	，更方便的开发新的系统功能；
			>本质：
				>1.(为开发提供)共享功能/共享库程序：创建程序/管理文件/控制IO设备。。。(调用过程：就是转向的过程--应用程序自己编译后可以直接是指令集指令,也可以是操作提供的函数代码入口指令)。
				>2.(为程序)运行代理：操作系统解释执行。
				>3.(为运行中的应用)系统资源访问的协调(解决竞争时的冲突问题)。
				>4.(为运行中的应用)检测错误和清除错误，如硬件错误、设备故障，使得对运行中的程序影响最小。如中止出错的程序、重试、直接报告错误。
				>5.(为各个阶段)资源利用率等各种性能参数的统计和监控，以调整系统和提高性能。
			>意图：给处理器提供指令，告诉如何使用其他系统资源(和控制其他程序的执行时机)(告诉做什么和怎么做)	(操作系统能自己主动做一些事情，也能执行用户让执行的事情)
				>os可以看作是主动方：而处理器、磁盘、文件等都是服务方/资源--等待被使用。
				>内存中：内核程序+其他部分os程序。+用户程序+数据。
				>os为什么需要模块化：专门做某件事的程序为一个模块，供其他模块调用，从而被复用。减少重复代码和相似功能代码。每个模块又可以自己升级和优化。
			>历史：
				>监控程序：常驻内存，当用户程序执行中，可能会执行到特权指令---直接发送错误--而转到监控程序；例如IO指令；转到监控程序，则监控程序控制IO设备。
					>内存保护：当用户程序试图改变监控程序的内存区域，处理器硬件发现错误将控制权转给监控程序。。。转：就是根据条件跳转到新的执行指令地址。
						>可以访问受保护的内存区域+执行特权指令：则程序处于  内核模式/系统态。如监控程序。
				>多道程序设计：
					>批处理：内存中有多个用户程序，则一个在IO时，处理器可以切换去执行另一个用户程序。充分利用处理器。		
						>切换的实现：调度算法。
						>新问题：内存管理：因为多个作业保存在了内存中。
					>分时系统：不等特殊条件，程序每次只被分配 固定的执行时间 就释放。	减少响应时间。
						>交替执行的实现：定时中断，如0.2s一次的中断，每次中断时os恢复控制权，然后告诉处理器执行哪个用户程序，之前在执行的被挂起--写出到磁盘。
			>主要挑战：
				>进程：
					>信号机制：
						>正确的同步---一个进程执行到某个命令时激发另一个进程开始。
						>正确的互斥：一个进程在访问一个资源，其他进程则不能再访问。相当于抑制其他进程。
						>正确的进程调度顺序：可能影响特定程序的输出结果。
						>避免死锁：资源分配和释放的时机安排。
					>内容：程序+数据+上下文
						>上下文：处理器+寄存器的内容，程序计数器+数据寄存器。进程优先级等。进程被中断时就需要保存上下文和恢复上下文。
					>建立和维护的进程表：	
				>内存管理：
					>进程隔离：防止相互干扰各自的存储空间。
					>自动分配和管理：给作业分配存储空间。
					>支持模块化程序设计：程序员定义程序模块，并动态的创建和销毁模块，动态改变模块的大小；
					>保护和访问控制：部分内存空间是可以共享访问的。
					>长期存储：文件系统实现长期存储。
						>虚存：利用了动态映射硬件实现的虚地址(页号+页中偏移量)--内存中的实地址 之间的动态映射。
							>一个进程：可能多个页。且各个页在内存中不同区域。
								>进程执行时：部分页调入内存；要访问的页不在内存--检测到后 安排 载入这个缺页
				>调度和资源管理：属于运筹问题。
					>可用资源：内存空间/IO设备/处理器
					>使用可用资源的主体：活动进程。
					>将可用资源分配给使用资源的主体：有策略。
						>策略特征：
							>公平性：同等和公平的访问同一资源。
							>有差别的响应性：作业的服务要求不同/紧急程度/服务后的收益大小
							>有效性：因为 吞吐量、响应时间、容纳的用户量，是相互制约的。
				>信息保护和安全；
					>可用性：保护系统不被中断；
					>保密性：保证用户不能读取未授权访问的数据
					>数据完整性：保护数据不被未授权修改；
					>认证：用户身份的正确认证和消息/数据的合法性；
				--可用性： MTTF/(MTTR+MTTF) 平均正常运行时间，平均失效时间。	
				--容错性：增加冗余度来实现：
					>空间冗余：物理冗余。多个组件同时执行相同功能；设置一个备份的可用组件。增加多条并行线路。
					>时间冗余：遇到错误重试。对临时错误有效，对永久错误无效；如重传数据。重新调用。
					>信息冗余：冗余位 来修复位数据；差错控制编码电路。
					--操作系统实现的容错性：
						>进程隔离： 
						>并发控制：
						>虚拟机：更高程度的应用隔离和错误隔离；
						>检测点和回滚机制：
				--windows:
					>内核模式组件：
						>执行体：操作系统核心服务：内存管理、进程和线程管理、安全、IO和进程间通信
						>内核：线程调度、进程切换、异常和中断处理、多处理器同步。是不可抢占或分页的部分。
						>硬件抽象层：对先定义好的统一的逻辑层-系统总线/直接存储器访问控制器、中断控制器、系统计时器和存储控制器，这些服务和接口，不同的硬件有不同的指令集，实现这些服务和功能和接口的程序指令就是不同的，统一接口+每套实现 都包含在硬件抽象层中。
						>设备驱动：怎么刺激(提问)(询问/听得懂的语言/可以理解接受的指令)设备和解读响应的程序指令集合。包含在动态库里。扩展了执行体。以及利用硬件实现的更加复杂的功能的程序--比如文件系统(利用磁盘)和网络协议(利用网卡/网络)。
						>窗口和图形系统：
					>面向对象的设计：把数据和方法封装在了一起。而面向过程则仅仅封装了函数。即还涉及到了保存数据，而函数本身只是计算--不保存数据--调用者集中保存数据/状态。而面向对象，就自然而然按归属 分散保存数据。	
				--unix: 一切服务都是/都要想象成 指令和数据。可以加载指令和数据到内存，可以执行指令。
				--linux: 高度模块化 且易于配置。
					>单体内核：可加载模块结构---特征：动态链接&可堆叠模块。模块有依赖，所以一般级联加载。
						>模块的组织结构：链表(每个元素为模块表)。模块如：FAT,VFAT
					>内核组件：	
						>信号：被内核使用来联系进程，告诉一些信息。内核如虚拟内存、系统调用、陷阱和错误， 都调用信号 来 告知进程。
							>内容：一般都是 来自硬件的情况描述/异常描述。
						>系统调用：几百个，分类：文件系统、进程、进程间通信、套接字、调度。。。
						>进程和调度器；创建管理和调度进程。
						>虚存： 
						>文件系统： 
						>网络协议：
						>字符设备驱动：
						>块设备驱动；
						>网络设备驱动：
						>陷阱和错误：
						>物理内存：
						>中断：
				--android: 系统内核+中间件+关键应用的软件栈。对传感器处理的很好。		
					>应用：
					>应用框架：
						>各种应用管理器：
					>系统库 & android runtime: 
						>系统库：SSL/OPenGL/SQLite
						>DVM, 一个应用有一个自己的DVM
					--硬件抽象层：HAL	
					>Linux内核：硬件和软件中间的抽象层的角色。
						>各种驱动：
		>进程： 操作系统一方面可以看作：资源的管理、分配(被调用而去使用资源)、监控和保护。
			---处理器是唯一的主动方。操作系统就是 资源的 使用说明书(方案书，而不止是死命令)(处理器解释)(命令可以是转向命令--如用户程序中包含的转向os A库指令起始地址的指令)，处理器可以看懂这本说明书并且一直在查阅这本说明书。资源包括：内存、硬盘、网络、IO设备。
			---用户程序(可以简单的想象为分段的几段代码--先cpu相关指令/后存储器相关指令/后IO设备访问指令/)
			---最开始是操作系统调用用户程序，用户程序执行时可以调系统函数而已。处理器主动直接做的事： 检测中断位+查询os代码。
			>定义：
				>表征：标识符+状态+程序计数器；各种指针地址+上下文数据(处理器寄存器数据)+IO状态信息(进程使用/占用的文件列表)。优先级。
			>进程控制块：进程表征存储在的数据结构。
				>保证可以中断进程和恢复进程：而不出错。
				>os支持多进程的关键工具：
			>进程状态和之间的转换：
				>两状态模型：
					>进程生命周期：创建和终止。创建：os负责实际执行(创建过程：是否就像提交一个任务一样，提交一个进程控制块到队列里？)(然后等待被调度执行)
						>进程派生：运行中的进程上的应用也可以创建新进程。
						>进程终止条件：正常结束+各种故障/限制指令非法越界/父进程终止	
				>五状态模型：新建-->就绪-->运行-->阻塞-->退出
					>新建：仅在进程表中有记录，程序还在磁盘。
					>退出：先保留进程表中记录，后删除。
					--队列：就绪队列(按优先级又分为多个队列)+阻塞队列(按等待事件1/事件2/事件3分多个队列)
					>阻塞：可能先被换出(部分/全部)到磁盘。
					>就绪：低优先级的就绪态进程可能部分换出到磁盘。
			>管理进程所用的数据结构：进程控制块+调用栈(用户栈/内核栈)+程序+局部变量
				>进程映像：
					>位置：内存或者部分在外存。
					>记录内容：每个进程的每页的位置。
				>执行模式：处理器里2位CPL当前特权状态 寄存器PSR。0为最高级别。模式是安全机制。
					>模式切换：用户模式切换到内核模式，保存模式上下文，但是没有切换进程--还在当前的用户进程内执行(同一进程中切换模式)。
				>进程切换：
					>时机：发生什么事件时：时钟中断()、IO中断(阻塞态转就绪态)、内存失效(发出调入内存块的IO请求后，内存失效的进程进入阻塞态)
				>进程创建：内核系统调用fork()实现。	
			>os对进程控制的需求：
				>资源管理： 
					>内存： 内存表来管理。表里记载：分配给进程的内存/外存(及其保护属性)。
					>IO: IO表 来管理。IO设备/通道 ---- 进程  的映射。IO的源/目标 的内存单元；IO操作的状态；
					>文件：文件表。文件外存位置/当前状态
					>进程：进程表。资源---进程标志符。
			>进程管理模式：
		>线程：没有资源所有权的单位(专门有独占的虚拟地址空间和对资源的映射)。一个进程内支持多个并发执行路径的能力。	
			>特征：与进程内的其他线程共享内存和对资源的访问。每个线程：线程控制块+用户栈+内核栈
				>创建和终止：都快。
				>线程切换：快。
				>线程间通信：无需内核介入---共享内存和文件。而进程间通信需要内核介入。
			>线程控制块：就绪、运行阻塞队列。
			>分类： 
				>用户级线程：ULT，内核意识不到线程的存在，还是一个内核进程在执行；线程库实现的用户级线程(调度)。用户空间中实现。内核继续以进程为单位调度。但是无法利用多核。且一个系统调用引起整个进程阻塞。
					>套管技术：将阻塞的系统调用转为非阻塞的系统调用；
				>内核级线程：KLT，内核为进程和进程内每个线程维护上下文信息；调度由内核基于线程完成。从而利用多处理器，和一个线程阻塞不会影响其他线程。缺点为：线程切换 需要先切换到内核模式。
					>混合方法：m个用户线程 映射到 n个内核线程上(排队)，线程库调度+内核调度结合。m>n
				--solaris 中采用的3层线程架构：用户级线程--轻量级进程--内核线程。	
				--linux 克隆新进程：共享同一内存空间，但创建独立的栈空间。
				--android: 一个应用多个活动，全部压入栈中。栈顶的活动的窗口信息显示在屏幕上，通过返回按钮弹出活动。
				--mac: gcd任务并发。
		>并发性：互斥和同步
			>竞争条件：进程会获得、等待、释放资源。
				>控制问题：
					>死锁：
					>饥饿：
			>互斥需求：一段代码还在执行中则其他进程不能执行。就是进程互斥。在临界区互斥。互斥粒度。
				>互斥粒度太小(如一行代码)：可能造成 数据一致性问题。
				>实现互斥：
					>硬件支持：CMS指令---不接受中断。exchange指令XCHG
					>信号量： 01互斥量。
					--生产者消费者问题：其实最好：就是 两个只增大的数表示队列头和尾：head,tail. 生产者增加head, 消费者增加tail,生产者和消费者都保证head-tail<=n, 否则就要阻塞(已空已满，在非空非满两个条件下等待)(等待非空，激活非满)。
			>信号量：整数值。初始化、递增、递减。
				>互斥量：二元信号量。加锁和解锁的进程必须为同一进程。(无重入概念)(为什么要可重入，因为同步块里如果调用某个方法，这个方法还在其他方法下被调用，那么这个方法就被共享了---所以如果为了也变为临界区--就需要再次同步--如果再使用同一个锁--就是重入)
			>管程：java有实现。任何时候只有一个进程在管程中执行---其他进程调用则被阻塞--直到管程可用。
				>java实现：就是同步块里主动条件等待(入队)和唤醒/wait/notify。唤醒调用后，也要等待唤醒线程退出后，被唤醒线程才能醒来。
			>进程间通信：
				>消息交换：无阻塞send不能确定 消息 是否被消费。无阻塞received则不能及时收到消息。。。引入中间者 信箱 。
				>一写多读问题：读写锁。。进程到x条件的队列中等待，被唤醒后执行操作，后唤醒队列中下一个进程。可以交叉在多个条件上等待和唤醒。
					>写者优先：非常形象的，三个条件队列：write-队列，read-队列，y-队列；写者：先在y-条件队列下等待，到顶后到read-队列等待，来等待所有的读进程先执行完，又到队列顶后(此时在2个队列顶)唤醒y队列顶，来到write-队列等待，又到顶后(此时在write/read队列的顶)--所以此时读进程和写进程都没有在执行--所以可以开始写数据了，写完后优先激活写队列的下一个进程，然后到y-队列等待(此时继续占领read-队列顶部/不可读)，到队顶后 如果没有写者了-则激活read-队列下一个进程，后固定激活y队列下一个。(是只有write-队列最后一个进程才会激活read-队列下一个元素---所以叫写者优先)
					>消息交换方式：控制进程--三个邮箱：读/写/finish, 接收三种请求。读请求 进程 则1个邮箱，写请求进程也是。处理读，-1，处理写-100，处理finish+1>。。。每轮依次finish,write,read邮箱轮询--但只一个实际接收；每轮结束，count<0则要等待接收finished到count==0才开始下一轮；==0，则要发write/并等待接收后count=100
						>轮询+事件等待队列：可以实现无锁无阻塞并发。
			>资源共享与竞争：
			>多个进程活动的同步：
		>并发：死锁和饥饿。
			>死锁产生的条件：某个时期占有资源A1而阻塞等待释放资源A2事件。但每个进程都阻塞，没有释放资源事件触发，导致无限等待。
				>联合进程图：
				>进程占有/阻塞时间轴图：每个进程一个轴，占有资源(请求成功为占有)为加实线，等待资源(请求失败为等待)为加波浪线/虚线
				>死锁例子：可重用资源--磁盘/IO, 可消耗资源--信号/消息/中断
					>请求独占磁盘和磁带两个资源：如果各个进程请求顺序不同，一先磁盘一先磁带，就发生死锁。
					>请求两块内存资源：各个进程各自先成功请求了一块，又等待下一块；但是剩余空间不足了。
					>互相等待对方的消息：死锁。你发了我才发。
				>三个死锁存在的必要条件：
					>互斥：一个资源一次只被一个进程使用
					>占有且等待：进程等待资源时，继续占有已占资源
					>不可抢占：不能抢占其他进程占有的资源
					--条件4：循环等待：进程组中，每个占有资源的进程所等待的资源都已被组内进程占有。四个条件可以构成一个 死锁产生的充分条件。三个条件是存在的可能性；四个条件则是存在的必然性。			
			>死锁预防：消除4个必要条件之一的出现。
				>策略：保守：预提交资源
					>一次性请求所有资源：必须知道将来的资源请求。
					>抢占：占有一个，则可以抢占另一个。一成一败--按优先级。就是主动提出要抢它的资源--比较获取资源的优先级。
					>资源排序：请求的资源的排序顺序，必须一个一个按资源顺序请求多个资源。
				>间接预防：3个条件的防止
					>互斥：不可避免
					>占有且等待的破坏：不占有的等待---即一次性请求所需的所有的资源。可能不知道资源；知道了可能很久都没使用；
					>不可抢占的破坏：可抢占；请求资源时，如果资源被优先级低的进程占有，则强制获取资源--调os来抢占；例如请求处理器资源；但是要求资源状态必须容易保存和恢复。
				>直接预防：第四个条件的防止
					>循环等待的破坏：线程占有Ri资源后只能请求Rj资源，其中i<j, Ri排在Rj后面；Ri<Rj;
			>死锁避免：基于资源分配状态做动态选择。主动发现安全路径，或者主动放弃请求部分资源；主动等待；
				>允许三个必要条件：只是恰当选择 而不达到死锁点；
				>资源分配前要判断：该请求是否可能造成死锁。如果一个请求会导致死锁，进程不启动；如果进程已经启动，则不允许这一资源分配；
				--需求/分配矩阵：Claim/Allocation:..。总量/可用向量：R/V。分配<需求<总量。总量=需求+可用。。。。死锁检测：只看新增线程的资源需求+已有线程的资源需求 <= 资源总量 成立，才启动；
				--银行家算法：n进程+m资源的系统
					>安全状态：至少一个资源分配序列不会导致死锁；就是V向量表明的剩下的资源，先分配给谁，再给谁，后给谁，每个谁都能顺利执行完毕。这个执行路径/序列的寻找。显然，需要看C-A 得到的还需矩阵。然后看V能满足哪行/哪些行，然后回收资源后又可以满足剩下的哪行/哪些行,....知道全部行都得到了满足；如果中间有不能的，则说明该分配路径会造成死锁要丢弃；如果所有路径都没有找到可以全部行满足的，则无法避免死锁；
						>本质：是分配策略和释放策略；。。无需抢占和回滚进程。仅仅必要的悬挂进程；
			>死锁检测：jstack 查看。测试已经发生的死锁，并破坏死锁。
				>事后检测：事后破坏。资源请求时进行。但会消耗相当多的处理器时间；
				>算法：标记未死锁的过程
					>策略：查找 当前可用资源 可以满足资源需求的进程，找到则标记，然后回收它占有的资源；尝试标记下一个；。。第一个为标记尚未分配资源的进程；
				>检测后的恢复：
					>取消死锁进程：
					>回滚重启进程：
					>逐个取消死锁进程：直到不存在死锁；
					>逐个抢占资源：来满足进程需求，直到可以满足剩下的进程；被抢占资源的进程则回滚；
			>综合方案：
				>对 可交换空间：一次性分配所请求的资源：
				>对 进程资源：死锁避免/死锁预防策略；(优先级先占用)
				>对 内存： 基于抢占的预防；抢占其他进程占用的内存，则被抢占的进程则置换到外存；
				>对 内部资源： 可以使用基于资源排序的预防策略；
			>资源分配图：资源(节点)/进程(节点)/占有(线)/请求(线)	
			>哲学家就餐问题：
				>基于信号量：等待条件：左叉子/右叉子； 吃饭； 激发条件:左叉子/右叉子；
				>基于管程：保证不会出现死锁；因为保证一次可以拿到两把；
			>UNIX并发机制：
				>管道：进程间传递消息
					>内容： 一个环形缓冲区。允许两个进程以 生产者/消费者 模型 进行通信；。类似Disruptor, head/tail; 读空了则阻塞；写满了也阻塞；
					>匿名管道：血缘关系的进程可以共享；
					>命名管道：不相关的进程可以共享；
				>信号量：
					>内容： 当前值 + owner(最后一个操作进程的id) + 等待信号量的值大于当前值的进程数 + 等待信号量的值等于0的进程数；；；相关：等待在该信号量上的进程队列
					>信号量集合：
					>操作信号量：
						>sem_op > 0: 内核增加信号量的值，唤醒所有等待该信号量的值增加的进程 
						>sem_op ==0: 内核检测信号量的值，如果=0 则继续其他信号量操作，否则增加等待该值=0的进程数，并将该进程阻塞在信号量值=0事件上；
						...
				>信号：用于向一个进程通知发生异步事件；进程之间可以互相发送信号；内核也可以内部发送信号；
					>信号的传递：
					>信号的处理：进程做出响应---执行信号处理函数/终止进程/忽略该信号
				>共享内存：进程间传递消息，速度最快；
					>内容：为虚存中多个进程共享的公共内存块；进程读写这块空间 用的指令 同 读写 虚存 其他空间；
				>消息：进程间传递消息
					>每个进程配一个消息队列：。。系统调用 msgsnd , msgrcv 来将消息发送到对方消息队列或者读取自身消息队列；
			>LINUX内核并发机制：独有---实时信号；多个信号能进行排队；
				>原子操作：保证对变量的原子操作；--用来避免简单的竞争条件；执行期间 线程不会被中断；多处理器中则原子操作的变量被锁住--避免被其他进程访问；
					>针对整数变量：
					>针对位图中某一位的位图操作：
					---实现：某些计算机体系结构：对应有汇编指令；某些计算机体系结构中：通过锁住内存总线的方式来保证操作的原子性；	
					---实现api: 原子整数操作：atomic_t, 原子位图操作：
				>基于原子操作的锁机制：
					>自旋锁：spinlock: 检查 一个整数值 == 0 ？ 是则更新为1， 获得锁；否则自旋；释放锁：更新为0；
					>读写自旋锁：
				>内核信号量：
					>二元信号量：MUTEX互斥信号量； init_MUTEX, init_MUTEX_LOCKED 函数初始化； 
					>计数信号量：
					>读写信号量：多个并发读 和 一个 写者；实际：对读者--计数信号量；对写者--二元信号量；使用不可中断睡眠；
				>屏障：	
					>内存访问 指令 的 重排序：
					>内存屏障：rmb()操作 保证 之前的代码 中 的读操作 都会在rmb()操作之前(拦截读)；之后的代码中的读操作也在rmb()之后；类似的，wmb()是写屏障的实现；。mb()则是装载和存储屏障；	
						>功能1：可以指示 编译器的行为：编译期间不要重排序指令；
						>功能2：可以指示 处理器的行为：指示流水线上在屏障前的指令必须在屏障之后的指令开始执行之前提交；。。。barrier()仅仅控制编译器的行为；
						>其他：smp_rmb, smp_wmb, smp_mb 操作能优化SMP上编译的代码；在SMP结构，这些指令定义为内存屏障，UP结构则仅仅作为编译器屏障：barrier()；
			>Solaris 线程同步原语：			
			>Win 7 的并发机制：锁也是服务(全套方法集合)。。使用内部锁操作来实现同步原语；内部锁操作可以实现更复杂的锁无关原语；
				>分派器对象：
				>临界区：
			>Android进程间通信：连接器----传递两个进程之间的交互。进程组件-->连接器-->目标进程的目标组件。接力一样；		
		>内存管理： 有效的分配内存来保证 适当数量的 就绪进程 能占用 这些 可用的 处理器时间。
			>基本概念：
				>页框：内存中 固定长度的块；
				>页：固定长度的数据块；存储在二级存储器中--磁盘；数据页可以临时复制到内存的页框中；
				>段：变长数据块；存储在二级存储器中；整个段可以临时复制到内存的一个可用区域(分段)；或可以将一个段 分为 许多页，然后每页单独复制到内存中；
			>内存管理的需求：
				>重定位：进程换出 后重新换入时，重定位到不同的内存区域。
					>程序代码中的内存访问：转换为 实际的物理内存地址；
				>逻辑组织：分模块；模块级别只执行只读；
				>物理组织：2级：内存外存(大慢久)；
				>共享：合作完成同一个任务的进程可能需要共享访问相同的数据结构；
				>保护：其他进程不能访问本进程的内存空间；操作系统的部分更不能访问；。由处理器硬件满足 内存保护的需求。
			>分页：进程的(部分/所有)页装入内存的页框；多对多
				>页框： 操作系统维护 空闲 页框 列表；
				>页表： 操作系统为 每个进程 维护一个 页表；---该进程每页所对应的页框位置(页号--页框号 的映射)；逻辑地址：页号+页中的偏移量。。给出逻辑地址(页号+偏移量)后，处理器使用页表产生 物理地址(页框号+偏移量)
					>大小：为方便：页框和页大小是2的整数次方，以便容易的表示出相对地址；
					>地址：16位；6位为页号，10位为偏移量；
					>动态地址转换：硬件实现；。。地址-->页号-->页表-->页框号k-->起始物理地址=k*2^m...。。由页框号和偏移量 算 物理地址；
			>分段：进程的(部分/所有)段装入内存的动态分区中；多对多
				>段：大小可以不同；程序和数据分段；段号+偏移量。所有段都要载入内存；但可以不连续。
				>段表：进程有段表；系统维护空闲块列表；段表项：段在内存中的起始地址+段的长度
				>地址映射过程：段号+偏移量：n+m,  则从段表找到该段的 段号n的起始物理地址， 偏移量和段长度比较，不大则有效；
			>分区：对用户内存空间进行分区。进程占据分区，若分区中的进程都未就绪或者运行态，则换出；
				>动态分区：换入换出后，最终产生很多空洞；外部碎片。
				>固定分区：内存空间利用率低。内部碎片。
				>伙伴系统：分配2^K个字，刚好大于需求s的2的整数次方个字；
				--换入换出：指令和数据单元的位置会发生改变；
					>逻辑地址：
					>相对地址：程序使用相对地址；。硬件机制：将相对地址转为物理地址；---使用基地址寄存器--指明程序开始的内存地址；界限寄存器---则指明程序的终止位置；；；换入时 需要重新设置这两个寄存器；。。处理器执行时：会将基地址寄存器的值+相对地址值 得到绝对地址，再和 界限寄存器比较，在范围内 则继续该指令的执行，
					>物理地址：
			>装载：
				>创建活动进程：程序装入内存，创建一个进程映像--->二进制代码时刻的程序还是使用的逻辑地址/相对地址；
				>寻址需求：
					>绝对加载--给定模块总被加载到内存中同一地址；但最好是用符号表示 程序中的内存访问；。(编程时写死地址，编译时编为死地址)
					>可重定位加载-：加载时确定具体的内存地址。加载模块到内存时 才解析 外部访问；然后动态链接模块附加到加载模块后；动态地址计算。
			>链接：链接器的功能：输入一组目标模块，产生一个包含完整程序和数据模块的加载模块，并传递给加载器。
				>每个目标模块中：有到其他模块的访问，都是符号访问；。所以链接器会创建一个 单独的加载模块， 它把所有的目标模块逐个链接起来；即将符号引用转为相对地址引用
				>动态连接器：某些外部模块的链接可以推迟到创建加载模块之后；。即一个应用模块被加载，如果它引用了一个外部模块，则加载程序查找目标模块加载它，再修改符号引用为相对引用；
					>代码共享：操作系统可以识别出有多个应用程序使用了相同的目标代码；从而只加载这个代码的一个副本；。运行时加载的动态模块，链接到调用模块；这些模板被称为动态链接库DLL--windows
		>虚拟内存：
			>支持虚拟内存的硬件和控制结构：
				>处理器访问不在内存中的逻辑地址时(即页表中某页的页框号暂时没有)：会产生一个中断，操作系统介入(即处理器转而执行操作系统)，将进程置为阻塞态--->后将产生一个IO读请求，调IO程序处理--将需要的进程块读入内存，此工作不一定是操作系统在做，操作系统可能去做其他进程调度的事情，当IO程序将进程块载入内存后产生一个IO中断，操作系统才将被阻塞的进程置为就绪态；。。
				>只加载程序部分模块到内存的好处：可以保留更多进程在内存；程序可以比内存空间还大；换入换出进程更快更省(代码执行覆盖率更高)。。部分载入程序+需要时再从磁盘加载 就是虚拟内存机制；。。简单分页，所有页要载入内存；虚拟分页，则部分页载入，需要时再载入；
				>页表项：P--页是否在内存，M位--页从载入到现在是否改变过；页框号；。。
				>页表指针寄存器：
				>页表太大的问题：即当程序太大时的问题：虚存中保存页表；方案2：页表的页表---两级方案；根页表-页表-偏移量：10位-10位-12位
				>倒排页表：key=页号的m位散列函数值，value=进程标识符/页号/控制位/下一页的链指针
				>虚存访问的实际过程： 先 取 页表项 --> 再取需要的数据
					>转换检测缓冲区：TLB 高速缓存；给定一个虚拟地址-->处理器先用页号查TLB,查到则找到页框号从而+偏移量得到实际地址。否则-->查找进程页表，如果P置位页在内存，则映射到页框号+偏移量得到实际地址,并更新TLB；未置位，则产生中断，os开始介入，执行IO程序，加载缺的页后(如果内存不够，则页面置换出去)，IO中断，Os更新页表和TLB。。所以TLB就是进程页表的高速缓冲；
					>使用实际地址：如果高速缓冲中有包含实际地址的块，则返回cpu，没有则从内存中检索加载这个字(块/缓存行)；
					
			>实现虚拟内存的各种操作系统机制：
				>读取策略：进程首次启动--预先分页，后来 请求分页。
				>放置策略：决定进程块驻留在实存中什么位置。NUMA系统则 自动放置系统--分配到提供最佳性能的内存；
				>置换策略：每个进程分配多少页框；计划置换的页集中，选择换出哪一页；
					>页框锁定：被锁定的页框中的页不被置换；操作系统和重要的控制结构就在锁定的页框中；
					>LRU:
					>FIFO:
					>时钟策略：页框01标记；。表示未被访问过/访问过。还有修改标记01，表示修改过(要先写回辅存)，未修改过。00，01都可以置换出去；
					>空闲页链表/修改页链表：
				>驻留集管理：
					>固定分配策略：为进程分配固定数量的页框；
					>可变分配策略：分配的页框在进程生命周期中不断变化；
					>置换范围：局部(保留驻留集)/全局。。缺页中断--空闲页框/置换页(产生一个空闲页框)
					>工作集大小：W(t,delta), delta是观察进程的时间窗口；每个进程有一个工作集；。。。发现缺页率低-->减少驻留集-->其他进程得到更多页框；
						>缺页中断频率算法：PFF算法：
						>可变采样间隔的工作集策略：
				>清除策略：何时将已修改的页写回辅存；
					>请求式清除：页被用于置换时才写回辅存；
					>预约式清除：在需要使用它们占据的页框之前成批写回辅存；
				>加载控制：如果内存中进程太少---则同时处于阻塞的概率就大--则很多时间花费在交换上。如果内存中进程太多--则平均每个进程的驻留集大小将不够用--频繁发生缺页中断--导致系统抖动；
					>频繁的处理缺页中断  还是 频繁的 因进程阻塞而交换：
					>L=S准则：调整系统并发度，使得缺页中断之间的时间 =  处理一次缺页中断 所需的时间；
			--局部空闲块的合并：
			>虚拟内存管理机制：
				>段页式：用户地址空间被程序员划分为多个段，每个段内许多固定大小的页，。。段偏移量=页号+页偏移量；
					>此时：段表项：存段号--页表地址；页表项：还是 页号--页框号；
					>分段：有助于实现保护和共享机制。因为段表项：基地址+长度 保证不轻易过界；。。共享：一个段 可能被多个进程的段表引用。
			>linux内存管理：
				>虚存寻址：三级页表结构；全局目录-中间目录-页表-偏移量
				>页面分配：连续的页分配到连续的页框中；使用了伙伴系统；
				>分配页：slab分配方案：
			>windows内存管理：
				>2g内核空间+2g用户空间：
				>页状态：可用-保留-提交
				>太多页的进程总会被os注意到：而移走该进程最近未使用的页面；。。
			----内存中：进程数量多还是进程的驻留集页多的权衡选择分配的问题；	