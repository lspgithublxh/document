---------读书战略：自顶向下，从应用层到底层细节。先熟悉的常用的，后底层的不常用的。精读好书---《深入理解系列》
--------es的处理思想都对应有 相应的“某种举动 及其导致 的问题”
>需求背景-痛点陈述：现实开发中遇到了什么痛点导致XXX的开发？  
>那么痛点的原因、产生的条件：分析是什么环境、什么动作 什么效果什么目的 等精准形容词的事实描述 导致了痛点的必然发生，难以避免？。条件-痛点。原因-结果。
>则可以消除痛点的最简单的精准事实陈述是什么：修改“条件-痛点”陈述的哪一部分就可以导致没有痛点产生。 要做的根本事情是什么：
>那么新陈述表明的解决动作是什么：
>新情况的新痛点是什么：新举动、新环境会产生的新痛点描述出来， 继续上述4条操作。

1.举动-痛点：搜索-索引。全文搜索、处理同义词、根据相关性给文档打分？同一份数据生成分析和聚合的结果？在没有大量工作进程的情况下能做到对数据的实时处理？
	>解法/处理思想：实时分布式搜索和分析引擎(前所未有的速度处理大数据)、全文搜索、结构化搜索、分析、分布式数据库。在数百服务器上处理PB级别的数据。
		>lucene:  最先进、性能最好、功能最全的搜索引擎库。
		>elasticearch: 内部使用lucene来搜索和索引，对外提供restful api接口来让使用者输入简单易懂的搜索和索引请求，内部会接收并转化为复杂的参数来调用lucene完成实际的功能。
		 >分布式的实时文件存储：每个字段都被索引而可被搜索。
		 >分布式的实时分析搜索引擎：
		 >扩展到上百台服务器：处理PB级别的结构化-非结构化数据。
		 >高级特性：
		>java客户端：可以加入集群，也可以纯粹是一个请求发送方：使用elastaicsearch传输协议。9300端口。
		>restful api: 基于http协议，json为数据交互格式。curl自然也可以。 
		 >查询格式：curl -X<GET/POST/...> '协议://host/path?query_string' -d 'json格式请求主体'  。 如计算集群中文档的数量：curl -XGET 'https://localhost:9200/_count?pretty' -d '{"query":{"match_all":{}}}'
			返回格式：body里的内容：一个json格式的数据：{"count":0, "_shards":{"total":5, "successful":5, "failed":0}}
		>面向文档存储：直接存储一个对象类型的json格式文档。并且可以索引每个文档的内容。可以对每个文档进行搜索、索引、排序、过滤。JSON格式是NoSQL领域的标准数据格式。
		>搜索-索引实例：es--->indexes--->types--->documents----->fields
		 >索引：动词：是存储文档。名词：是存储各类文档的地方。倒排索引：使用来加速检索。默认情况下，文档中所有的字段都会被索引---拥有一个倒排索引。
		  >命令：PUT /索引名/类型名/文档ID序号 {文档JSON内容}
		 >检索：检索单个文档。
		  >命令：GET /索引名/类型名/文档ID序号 。。返回内容包括文档的元信息， 文档的内容包含在"_source"字段里。
		 >简单搜索：
		  >搜索全部员工：GET /索引名/类型名/_search  返回结果为3层Json: 第一层键：耗时、分片之类；"hits"键的json结构值为第二层键：命中文档总数、最大分值等，"hits"键的json结构值为第三层键：为一个数组：对象即检索文档返回的结果。
		  >搜索名为Smith员工： GET /索引名/类型名/_search?q=last_name:Smith 返回结构同上。
		 >结构化搜索：DSL语句查询。查询参数为json格式。
		  >搜索名为Smith员工：GET /索引名/类型名/_search {"query":{"match":{"last_name":"Smith"}}}
		   >增加年龄>30的限制：json查询参数上：使用：query-->filtered--->filter-->range:{"age":{"gt":30}} 结构。同时query--->filtered--->query--->match依然成立。	
		 >全文搜索：语法上同上。但是对于文本很长的字段，会有“不完全匹配”也能搜索到的效果，只是分值低，排序在后面。相关性排序的结果。
		 >短语搜索：语法上，仅仅将match改为match_phase。这样，必须是完全匹配--包含才可以，不会进行分词匹配仅仅单个的那种文档。
		 >高亮展示：意义不大，语法为：query级别："highlight"-->fields-->字段：{} 结构。返回结果为和“_source”同级别，"highlight"--->字段名--->["内容，匹配到的部分为<em>标签包围"]
		 >聚合：对数组类型field 分别统计其中各个item出现在多少个文档中：相当于group by + count()函数：query级别，"aggs"-->"all_interests"-->terms-->field:字段名称。返回结果：hits同级别： "aggregations":{"all_interests":{"buckets":["key":"","doc_count":1]}}
		        二字段分组：比如group by age, name 或者说是在上一级group by出的doc组里，按其他字段统计--但是不分组-相当于增加统计函数：则query上，在“terms”层，"aggs"-->"avg_age"-->"avg"-->"field":字段名称。
		 
2.举动-痛点：扩展节点之后，客户端请求操作是一样的。
	>解法/处理思想：分片、集群发现。		 
		>文档存储：底层将分区到合适的分片中，一种分片可以有多个拷贝而存储在多个节点上。
		>分配索引和搜索负载：在集群的不同节点平衡分片。
		>复制每个节点提供数据冗余：防止硬件故障造成数据丢失。
		>从集群的任意节点路由到感兴趣的节点：
		>集群需要扩展或者恢复节点：无缝整合新节点。横向扩展。高扩展和高可用。
		>集群、节点、分片：
		 >空节点的集群：一个集群一个节点，且节点无数据。
		 >节点：一个节点就是一个es实例。一个集群里的节点分享数据和负载。新的节点加入，集群会感知，并且平衡数据。
		  >主节点：集群选举出来的一个节点。管理集群的变更：新建删除索引、增加移除节点。不参与文档级别的修改和搜索。集群只有一个节点，则是主节点。任何一个节点知道所有文档存在哪些节点上，从而可以转发到这些节点上，将数据收集后一起返回给客户端。
		 >监控统计：
		  >集群健康：GET /_cluster/health  返回集群中节点数、主分片数、集群健康状态、未分配的分片数(可能因为当前节点已经分片满了，需要新的节点)
		   >集群状态：green(主分片和复制分片都全可用), yellow(主分片可用，复制分片有的不行；可以接收任何请求), red(不是所有的主分片都可用), 
		 >分片：最小级别的工作单元。存储一个索引的一部分数据。一个分片是一个Lucene实例。即本身就是一个完整的搜索引擎。文档存储和被索引在分片中。当作数据的容器，可以在节点之间迁移分片。分片分配在节点上。
		  >主分片：每个文档都属于一个主分片。所以主分片的个数决定了能存储多少数据。
		   >性能指标：硬件存储大小、文档大小和复杂度、如何索引和支持文档、期望的响应时间。
		  >复制分片：主分片的副本，用于提供数据的冗余副本。硬件故障后提供数据保护。服务于搜索和检索等只读请求。数量随时间变化。
		 >索引：只是指向多个分片的一个逻辑命名空间。因为用户程序不知道如何和分片通信，所以转向和索引通信。
		  >创建索引：并指定主分片个数和每个主分片的复制分片个数：put /索引名 {"settings":{"number_of_shards":3, "number_of_replicas":1}} 
		   >主分片个数：决定了数据量有多大。而复制分片决定了能承载的搜索吞吐量有多大----但是会使得节点的负载增加--所以还受节点上的分片数的影响。主分片数量在创建索引时已经定了，但是复制分片数量可以修改。
		>双节点集群：启动两个节点且同cluster.name之后，就启动了双节点集群。新的文档先存储在主节点，然后平行复制到关联的复制节点上。
		>三节点集群：再启动一个节点且同cluster.name。集群会感知，而加入到集群中，并且会重新分配(转移)分片(主/复制)到新节点上。均衡分配之后，那么每个节点的性能表现就会更好。
		  >修改复制分片的个数：put /索引名/_settings {"number_of_replicas":2}
		  >杀掉主节点：集群先选举一个主节点。然后新主节点提升丢失的主分片的副本分片为主分片。
		   >重启旧主节点：如果有旧节点的分片，则会利用并且从其他节点复制故障期间变更的数据。
		 
3.举动-痛点：基本知识再认识
	>解法/处理思想：
		>文档：文档元数据---_index文档存储的地址(叫索引更好)，_type文档代表的对象的类型，_id文档的唯一标识。新增文档：用自己的id可以--如果系统的就是22位UUID。_version版本号，文档变更次数的标记。
		 >文档更新：内部只是将旧文档标记为删除状态(索引更多数据时会被删除) ，而新增一条新的完整的文档。同时会并发复制到其他节点(做冗余)。
		  >更新方法：乐观锁定：cmpxchg类型，先比较再更新。比较的时_version字段。
		   >比如创建一个新的博文：PUT /索引/类型/_version版本/_create {...}  这里的_version就是新的版本。如果创建时指定了_verison=1, 然后执行一次更新：put /索引/类型/docid?version=1 {} 会成功，且_version会自增1，这里的version=1其实就是expectVal----相当于cas中的。所以，如果此时再次执行相同的更新，是不会更新进去的，会返回一个更新不成功的信息。更新和删除请求都接收version参数。
		    >外部版本号：在更新参数里用version_type=external来指定， 需要是整数，检查只检查是否大于旧版本号。(因为会传递新版本号)(等于也不行)
		    >文档本身不能被更改：只是被替换了而已。会因此而重建索引。更新可新增字段。
		    >使用脚本局部更新：groovy进行。运行在沙盒中。 POST /索引/类型/docid/_update {"script":"ctx._source.tags+=new_tag", "params":{"new_tag":"search"}}则会给tags数组属性新增一个元素new_tag。。。不存在的字段也可以新增并赋予初始值：改params为："upsert":{"views":1}
		    >冲突重试：..._update?retry_on_conflict=5  (检索和重建索引阶段知道是否版本冲突)
		 >批量检索：get /_mget 
		 >批量创建、索引、更新、删除：bulk----参数是json对象流--通过\n分割。{action:{metadata}}\n{requestbody}\n
		   
		   
		   
		    
		 
		 
参考资料：
https://max.book118.com/html/2018/0130/151233686.shtm(深入理解elasticsearch)