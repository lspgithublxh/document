---------读书战略：自顶向下，从应用层到底层细节。先熟悉的常用的，后底层的不常用的。精读好书---《深入理解系列》
--------es的处理思想都对应有 相应的“某种举动 及其导致 的问题”
>需求背景-痛点陈述：现实开发中遇到了什么痛点导致XXX的开发？  
>那么痛点的原因、产生的条件：分析是什么环境、什么动作 什么效果什么目的 等精准形容词的事实描述 导致了痛点的必然发生，难以避免？。条件-痛点。原因-结果。
>则可以消除痛点的最简单的精准事实陈述是什么：修改“条件-痛点”陈述的哪一部分就可以导致没有痛点产生。 要做的根本事情是什么：
>那么新陈述表明的解决动作是什么：
>新情况的新痛点是什么：新举动、新环境会产生的新痛点描述出来， 继续上述4条操作。

1.举动-痛点：搜索-索引。全文搜索、处理同义词、根据相关性给文档打分？同一份数据生成分析和聚合的结果？在没有大量工作进程的情况下能做到对数据的实时处理？
	>解法/处理思想：实时分布式搜索和分析引擎(前所未有的速度处理大数据)、全文搜索、结构化搜索、分析、分布式数据库。在数百服务器上处理PB级别的数据。
		>lucene:  最先进、性能最好、功能最全的搜索引擎库。
		>elasticearch: 内部使用lucene来搜索和索引，对外提供restful api接口来让使用者输入简单易懂的搜索和索引请求，内部会接收并转化为复杂的参数来调用lucene完成实际的功能。
		 >分布式的实时文件存储：每个字段都被索引而可被搜索。
		 >分布式的实时分析搜索引擎：
		 >扩展到上百台服务器：处理PB级别的结构化-非结构化数据。
		 >高级特性：
		>java客户端：可以加入集群，也可以纯粹是一个请求发送方：使用elastaicsearch传输协议。9300端口。
		>restful api: 基于http协议，json为数据交互格式。curl自然也可以。 
		 >查询格式：curl -X<GET/POST/...> '协议://host/path?query_string' -d 'json格式请求主体'  。 如计算集群中文档的数量：curl -XGET 'https://localhost:9200/_count?pretty' -d '{"query":{"match_all":{}}}'
			返回格式：body里的内容：一个json格式的数据：{"count":0, "_shards":{"total":5, "successful":5, "failed":0}}
		>面向文档存储：直接存储一个对象类型的json格式文档。并且可以索引每个文档的内容。可以对每个文档进行搜索、索引、排序、过滤。JSON格式是NoSQL领域的标准数据格式。
		>搜索-索引实例：es--->indexes--->types--->documents----->fields
		 >索引：动词：是存储文档。名词：是存储各类文档的地方。倒排索引：使用来加速检索。默认情况下，文档中所有的字段都会被索引---拥有一个倒排索引。
		  >命令：PUT /索引名/类型名/文档ID序号 {文档JSON内容}
		 >检索：检索单个文档。
		  >命令：GET /索引名/类型名/文档ID序号 。。返回内容包括文档的元信息， 文档的内容包含在"_source"字段里。
		 >简单搜索：
		  >搜索全部员工：GET /索引名/类型名/_search  返回结果为3层Json: 第一层键：耗时、分片之类；"hits"键的json结构值为第二层键：命中文档总数、最大分值等，"hits"键的json结构值为第三层键：为一个数组：对象即检索文档返回的结果。
		  >搜索名为Smith员工： GET /索引名/类型名/_search?q=last_name:Smith 返回结构同上。
		 >结构化搜索：DSL语句查询。查询参数为json格式。
		  >搜索名为Smith员工：GET /索引名/类型名/_search {"query":{"match":{"last_name":"Smith"}}}
		   >增加年龄>30的限制：json查询参数上：使用：query-->filtered--->filter-->range:{"age":{"gt":30}} 结构。同时query--->filtered--->query--->match依然成立。	
		 >全文搜索：语法上同上。但是对于文本很长的字段，会有“不完全匹配”也能搜索到的效果，只是分值低，排序在后面。相关性排序的结果。
		 >短语搜索：语法上，仅仅将match改为match_phase。这样，必须是完全匹配--包含才可以，不会进行分词匹配仅仅单个的那种文档。
		 >高亮展示：意义不大，语法为：query级别："highlight"-->fields-->字段：{} 结构。返回结果为和“_source”同级别，"highlight"--->字段名--->["内容，匹配到的部分为<em>标签包围"]
		 >聚合：对数组类型field 分别统计其中各个item出现在多少个文档中：相当于group by + count()函数：query级别，"aggs"-->"all_interests"-->terms-->field:字段名称。返回结果：hits同级别： "aggregations":{"all_interests":{"buckets":["key":"","doc_count":1]}}
		        二字段分组：比如group by age, name 或者说是在上一级group by出的doc组里，按其他字段统计--但是不分组-相当于增加统计函数：则query上，在“terms”层，"aggs"-->"avg_age"-->"avg"-->"field":字段名称。
		 
2.举动-痛点：扩展节点之后，客户端请求操作是一样的。
	>解法/处理思想：分片、集群发现。		 
		>文档存储：底层将分区到合适的分片中，一种分片可以有多个拷贝而存储在多个节点上。
		>分配索引和搜索负载：在集群的不同节点平衡分片。
		>复制每个节点提供数据冗余：防止硬件故障造成数据丢失。
		>从集群的任意节点路由到感兴趣的节点：
		>集群需要扩展或者恢复节点：无缝整合新节点。横向扩展。高扩展和高可用。
		>集群、节点、分片：
		 >空节点的集群：一个集群一个节点，且节点无数据。
		 >节点：一个节点就是一个es实例。一个集群里的节点分享数据和负载。新的节点加入，集群会感知，并且平衡数据。
		  >主节点：集群选举出来的一个节点。管理集群的变更：新建删除索引、增加移除节点。不参与文档级别的修改和搜索。集群只有一个节点，则是主节点。任何一个节点知道所有文档存在哪些节点上，从而可以转发到这些节点上，将数据收集后一起返回给客户端。
		 >监控统计：
		  >集群健康：GET /_cluster/health  返回集群中节点数、主分片数、集群健康状态、未分配的分片数(可能因为当前节点已经分片满了，需要新的节点)
		   >集群状态：green(主分片和复制分片都全可用), yellow(主分片可用，复制分片有的不行；可以接收任何请求), red(不是所有的主分片都可用), 
		 >分片：最小级别的工作单元。存储一个索引的一部分数据。一个分片是一个Lucene实例。即本身就是一个完整的搜索引擎。文档存储和被索引在分片中。当作数据的容器，可以在节点之间迁移分片。分片分配在节点上。
		  >主分片：每个文档都属于一个主分片。所以主分片的个数决定了能存储多少数据。
		   >性能指标：硬件存储大小、文档大小和复杂度、如何索引和支持文档、期望的响应时间。
		  >复制分片：主分片的副本，用于提供数据的冗余副本。硬件故障后提供数据保护。服务于搜索和检索等只读请求。数量随时间变化。
		 >索引：只是指向多个分片的一个逻辑命名空间。因为用户程序不知道如何和分片通信，所以转向和索引通信。
		  >创建索引：并指定主分片个数和每个主分片的复制分片个数：put /索引名 {"settings":{"number_of_shards":3, "number_of_replicas":1}} 
		   >主分片个数：决定了数据量有多大。而复制分片决定了能承载的搜索吞吐量有多大----但是会使得节点的负载增加--所以还受节点上的分片数的影响。主分片数量在创建索引时已经定了，但是复制分片数量可以修改。
		>双节点集群：启动两个节点且同cluster.name之后，就启动了双节点集群。新的文档先存储在主节点，然后平行复制到关联的复制节点上。
		>三节点集群：再启动一个节点且同cluster.name。集群会感知，而加入到集群中，并且会重新分配(转移)分片(主/复制)到新节点上。均衡分配之后，那么每个节点的性能表现就会更好。
		  >修改复制分片的个数：put /索引名/_settings {"number_of_replicas":2}
		  >杀掉主节点：集群先选举一个主节点。然后新主节点提升丢失的主分片的副本分片为主分片。
		   >重启旧主节点：如果有旧节点的分片，则会利用并且从其他节点复制故障期间变更的数据。
		 
3.举动-痛点：基本知识再认识
	>解法/处理思想：
		>文档：文档元数据---_index文档存储的地址(叫索引更好)，_type文档代表的对象的类型，_id文档的唯一标识。新增文档：用自己的id可以--如果系统的就是22位UUID。_version版本号，文档变更次数的标记。
		 >文档更新：内部只是将旧文档标记为删除状态(索引更多数据时会被删除) ，而新增一条新的完整的文档。同时会并发复制到其他节点(做冗余)。
		  >更新方法：乐观锁定：cmpxchg类型，先比较再更新。比较的时_version字段。
		   >比如创建一个新的博文：PUT /索引/类型/_version版本/_create {...}  这里的_version就是新的版本。如果创建时指定了_verison=1, 然后执行一次更新：put /索引/类型/docid?version=1 {} 会成功，且_version会自增1，这里的version=1其实就是expectVal----相当于cas中的。所以，如果此时再次执行相同的更新，是不会更新进去的，会返回一个更新不成功的信息。更新和删除请求都接收version参数。
		    >外部版本号：在更新参数里用version_type=external来指定， 需要是整数，检查只检查是否大于旧版本号。(因为会传递新版本号)(等于也不行)
		    >文档本身不能被更改：只是被替换了而已。会因此而重建索引。更新可新增字段。
		    >使用脚本局部更新：groovy进行。运行在沙盒中。 POST /索引/类型/docid/_update {"script":"ctx._source.tags+=new_tag", "params":{"new_tag":"search"}}则会给tags数组属性新增一个元素new_tag。。。不存在的字段也可以新增并赋予初始值：改params为："upsert":{"views":1}
		    >冲突重试：..._update?retry_on_conflict=5  (检索和重建索引阶段知道是否版本冲突)
		 >批量检索：get /_mget 
		 >批量创建、索引、更新、删除：bulk----参数是json对象流--通过\n分割。{action:{metadata}}\n{requestbody}\n
		 >文档所在的分片号：shard = hash(routing) % number_of_primary_shards 分片号=文档主键的hash % 主分片数。所以说主分片数在索引创建时就确定了，后面也不能修改。
		 >文档增加、更新和删除的过程：客户端请求发送到节点1---->节点1哈希运算得到文档分片号，转发请求给该分片号主分片1所在的节点2--->节点2处理请求成功后，将转发请求给主分片1的复制分片所在的节点1、节点3--->复制分片所在的节点处理成功回禀给节点2，节点2回禀给客户端请求的节点，该节点再回禀给客户端。
		   >consistency: 一致性要求。在写入时，可用的主分片数和复制分片数的总和要超过设置的一半。(一般还同时有规定：同一个分片的主分片和各个复制分片都不在一个节点上)
		 >文档检索的过程：客户都请求发送到节点1-->节点1哈希运算得到文档分片号，转发请求给该分片号的分片列表中的一个所在的节点2(采用robin循环算法)---->该节点处理请求回禀给客户端请求的节点---->此节点回禀给客户端。
		 >文档局部更新的过程：类似于上述的更新过程，只是在转发给了所在的主分片后，主分片会先检索出要更新的数据，修改它们的_source然后在主分片上重建索引，如果有其他进程重新修改了文档，则会retry_on_conflict次数重复“检索-重建索引”， 然后转发新版本文档给复制节点来重建索引。
		>搜索：映射、分析、领域特定语言查询
		 >空搜索：GET /_search 
		  >_score: 相关性得分，文档与查询的匹配程度。
		 >搜索条件：描述：**索引 ** 类型 都可以既具体又匹配地描述。
		  >分页：分布式系统不适合分页：因为如果要搜索1000 - 1010的结果，那么每个节点都需要返回1010个，然后聚合排序取10个，消耗非常大，所以from, size 中from不适合非常大，size也不适合非常大。
		  >简单搜索： 索引/类型/_search?q=字段：包含的取值 + 字段2：包含的取值
		              索引/类型/_search?q=所有字段包含的取值：即全文方式 。。基于的数据结构：索引每个文档时，会将每个字段的字符值 拼在一起形成一个新的_all的额外字符串字段。
		  >文档的索引过程：
		   >映射：查看一个索引的某个类型的_mapping :  GET 索引/_mapping/类型   如果事先没有定义_mapping, 那么es会动态猜测字段的类型，生成一个_mapping 结果json。。。
		    >日期类型和字符类型索引方式的不同：
			>全文类型和确切类型如字符类型索引方式的不同：确切值相当于一种常量类型，确切值的不同---尽管差异非常小。确切值的搜索：是二进制比较，相同才返回。全文的搜索：是相关度计算后有关的都返回(同义词、包含、复数单数-同根词、单词有相交、大小写不同)。
			 >文本分析：字符过滤器、分词器、标准化-表征过滤器(停用词也会删除)， 而形成一个 单词*文档id 交叉值为词是否在文档中出现的 矩阵。 存在优化合并同义词行、同根词行、大小写词行的过程，删除停用词行的过程。
			 >建立倒排索引：
			 >简单相关度算法：单词匹配的个数多 则匹配度高。
			 >查询时对全文查询文本的分词：同索引。全文搜索的方式：
			 >查看分析：GET /_analyze?analyzer=stanard 返回包括整个文档中每个被索引村粗的词、词出现的词序数、起止位置
			 >数据类型：字符串、数字、浮点、布尔、日期
			  >mapping里说明的信息：type:类型，index:索引的方式--全文、定值、无索引， analyzer: 分析器-标准、空格符、简单。
			  >创建索引：PUT /索引 {映射实体}   之后可以更新。
		      >数组的索引：普通字段。
			  >空字段：不被索引。
			  >层级对象的索引：从根层级到基本类型属性，之间用.分割形成一个字符串作为索引的键：即会扁平化、拉平："user.tweet.name":"lishaoping"
			  >添加新字段：需要加入到stash字段里。stash--->newfield
		   >复合子句查询：
		    >must: and 
			>must_not: not 
			>should: 或的关系or
			>bool: 
			>match:
			>multi_match: 条件同，但是允许查询多个字段：fields: ["user.name", "producer.name"]
			>match_all: 未指定查询范围的默认查询。
		   >查询过滤语句：filter:{}
		    >term: 精确匹配
			>terms: 多个匹配条件
			>range: 范围过滤 gte ,  lt之类语法。
			>exists/missing:包含或者没有包含某个字段。  	
		   >组合过滤条件和查询条件：filtered:{}  整体就是：query-->filtered--->filter--term/query--match
		   >语法验证：GET /索引/类型/_validate?query?explain 查询语句json
		   >相关性排序：耗时。当用sort指定列排序时，不会用到相关性排序。此时score是null  .  sort--->order/mode
		    >相关性分值计算：一个文档中的词频高则相关性高。词出现在文档中的次数/总次数 高则集中化高而相关性高。词所在字段越短则集中化高而意思更相关而相关性更高。
		   >设置settings: 设置分析器。。创建自定义分析器---设置过滤器、转换器、停用词组、分词器。
		  >Lucene的索引: 没有类型type的概念，只是给每个文档增加一个_type类型名字段，再用来筛选文档。
			>映射：是在es这一层 起作用，起到建立倒排索引时使用什么分析器的(可以配置：如whitespace分析器、english分析器，spanish分析器)。	
			>动态模板：
		  >创建索引别名：put /索引/_alias/索引别名
		
>举动-痛点：深入理解
	>解法/处理思想：重新明确定义一些基本概念：
		>倒排索引：一个类型的某个字段的倒排索引 是 一张词项-文档id list 映射表(词项就是所有的该字段的值分词后的单词)
		 >倒排索引的生成：从文档中转换而成，被称为“分析”，由分析器完成。每个字段，可以使用不同的分析器。
		  >分析器：分词器、过滤器、字符映射器。
		   >分词器：将文本--切割为 词条流。(词条含义比词项更丰富，含有单词出现的位置、长度)
		   >过滤器：承接分词器推送过来的一个个的词条。进行移除、修改、新增词条的操作。修改：小写过滤器--转换为小写，同义词过滤器--转换为同义词，还原词干过滤器--还原为词干。移除：ASCLL过滤器--移除非ASCLL字符，
		   >字符映射器：分词器之前的文本预处理操作。HTML文本的去标签处理。
		>段：每个索引由多个段组成。
		 >段合并：耗IO, 可以消除已经被删除的文档。
		>查询字符串：被查询分析器分析。前缀查询不被分析，匹配查询会被分析。以下讨论查询语句的编写
		 >查询中可以包含布尔操作符：用于连接词项，表达目标文档与词项之间的包含关系。AND  OR NOT 。 也可以+ - 空格(表示可出现可不出现)。。比如：title:+ab +cd 就表示搜索那些文档的title字段既包含ab词项又包含cd词项的文档。
		 >查询中的通配符、模糊匹配: 通配符? *,  模糊匹配：~整数，修饰词项则表示允许的多的字符数，修饰短语表示词项之间最多间隔单词数。对词项加权^double:提高词项的重要程度。
		 >查询中的范围查询：title:[20 to 30]
		 >查询中的特殊字符：转义处理。abc\"efg
		>查询期和索引期的文本分析：都应该使用相同的分析器，那么查询分析出来的词项和索引的词项才能匹配。
		>集群：是es最大的优势。
		>文档写入索引：之前需要分析。
		>分片：是一个名词。一个Lucene索引是一个分片。散布分片的过程是分片处理。
		>网关：集群状态、索引配置信息都会被收集起来，在网关中被持久化。
		>映射：自定义的文档结构。是主分片进行索引一个文档时的参考，也是搜索文档时至少在分析阶段的参考。
		>es架构：
		 >合理的默认配置：自动配置的发现等，用户直接使用。
		 >默认的分布式工作模式：启动节点就会加入某个集群。
		 >对等架构p2p：可以避免单点故障。节点自动连接到集群其他节点，进行相互的数据交互和监控操作。如索引分片的自动复制。
		 >易于向集群中扩充新节点：增加数据容量----增加新类型(主分片固定了就不再改变)，增加读的吞吐量，单一节点分片更少从而压力对上面的分片访问更小性能更高，复制分片更多可靠性更高。
		 >不限制索引中的数据结构：支持一个索引中存在多个数据类型。
		 >准实时搜索和版本同步：虽然查询延迟和节点之间临时的数据不同步。es的处理机制：
		>节点启动过程：在所在内网中组播，遇到es节点则会响应，并从响应中获知该节点所属的集群，如果和自己的集群一致，则与它们连接。集群中的管理节点：集群状态管理和集群拓扑结构变化时分发分片到集群的相应节点上(如分片的创建和分发)。
		>集群故障检测：定期ping健康检查-超时断开。断开后的处理：选主分片、补充副本分片。集群状态：红色、黄色、绿色。
		>用户API： 都是RESTFUL接口，UDP协议或HTTP协议推送和检索数据等。java API还有集群发现功能。
		 >创建索引：将一个文档推送特定的索引。单一推送，或者bulk api , udp bulk api批量推送。第四种：河流river---在es节点上运行，插件方式发送数据--从外部系统获取数据。
		  >内部通信过程：会先转发到所属分片的主分片所在的节点上。主节点处理好了再分发给副本分片。
		 >查询数据：基本查询：词项、范围、通配查询。组合查询：复合查询。文档过滤、文档的相似文档。特定短语的查询建议和拼写检查。使用切面构建动态导航和各种统计量。
		  >内部通信过程： 分散阶段：将查询分发到包含相关文档的多个节点中去执行查询，合并阶段：从众多分片中收集返回结果，然后合并、排序、后续处理再返回给用户。
		>节点之间通信API：同上 Java API。
		 
举动-痛点：评分公式
	>解法/处理思想：过滤器、切面计算机制
		>默认评分机制：文档得分：文档和查询的匹配程度。TF/IDF(词频/逆文档频率)
		 >文档得分依赖因子：权重、查询结构、匹配的词项数目、词项所在的字段、用于查询规范化的匹配类型等。
		   >文档权重：索引期间赋予的。
		   >字段权重：查询期间赋予的。
		   >协调因子：词项命中个数的协调因子。
		   >逆文档频率：词项罕见度 ，正相关。
		   >长度范数：索引期间计算：字段包含词项个数的因子，反相关。
		   >词频：词项在文档中出现次数。
		   >查询范数：查询中词项的权重平方和。
		 >TF/IDF公式理论形式：
		 >TF/IDF公式实际实现形式：score(q,d) = coord(q,d) * queryNorm(q)*∑(tf(t in d) * idf(t)^2 * boost(t) * norm(t, d)) 前两项是因子，求和中，每一项的tf()是某term的词频，idf是逆文档频率，boost是词项权重、norm是长度范数。逆文档就是词项的罕见度(类似推荐次数为0很新鲜)。所以越多罕见的、权重大的字段短的文档得分越高。词多罕见，权重字短。
		>自主控制评分：
		>二次评分：用户定制业务逻辑---在原始查询返回的文档的子集上计算/排序。过程：先截取返回的N个文档，然后重新计算得分。不能和sort排序一起使用。排序发生更早。
		 >rescore: 将返回的文档的得分改写：rescore--->query--->rescore_query--->custom_score---->query/script 。。可以将查询保存在一个json文件中query.json  然后使用：../_search?pretty -d @query.json来查询执行。
		 >二次评分参数设置：window_size窗口大小---每个分片上参与二次评分的文档数，query_weight, rescore_query_weight原始评分得分、二次评分得分的权重值，rescore_mode二次评分模式---描述利用原始得分和二次评分各自加权后 得出一个新的分值的计算函数：total, max, min, multiply,avg。
		>查询改写：
		 >前缀查询例子：query--->prefix--->field/rewrite。。rewrite的值：scoring_boolean, constant_score_boolean, constant_score_filter, top_term_N, top_term_boost_N:
		>一个完整的查询过程：从语句分析到集群分片。如以某个查询为例。
		>批量操作：允许在对一个索引的查询中对其他索引下的文档进行一并搜索。批量索引、批量搜索。curl中可以：--data-binary使得不保留换行符。
		>排序：sort--->field 或者field --> order/mode(多值字段的取值方式min,max,avg) 或者sort-->field--->order/mode。多字段排序： 。地理排序：field--->loc/unit/mode。。
		  >嵌套对象排序：sort--->field1.field2.field3--->order/mode 方法二：sort--->field3--->nested_path:field1.field2 /order / mode 
		>新增文档：每个字段都会被分析而存入相应的倒排索引，显然这是一个不可逆的过程，即不可能从倒排索引还原出所有的历史字段值，因此索引不能更新文档，做法是文档的_source字段的修改，然后向索引提供一个新文档---进行分析和存入倒排索引。只能单条更新。
		>更新文档：_update更新指定字段的文档：doc--->fielda/fieldb  
		>按条件更新文档：使用脚本方式： _update    script:"脚本逻辑" , params:{脚本中涉及的变量-值映射对}
		>更新而插入文档：更新某个文档的某个字段，如果这个文档不存在，则新建，且设置某字段的值。 doc --> field:val  , upsert --> field2: val。。可以使用脚本方式删除某个文档：_update  script:"ctx.op = \"delete\""
		>过滤器：查询的结果会被es缓存。query-->filtered--->query/filter--->term--->field:val 所以结合了过滤器的查询，过滤器筛选的数据会被缓存起来，以后的查询使用。有的过滤器不缓存---对于要实时更新的那种。
		 >设置缓存键：filter--->term--->field/_cache_key:"ss"(手动设置方便后来手动清理) ,  关闭查询的词项过滤器缓存：只需要将_cache_key:false即可。缓存的内容就是文档id
		 >es优先在本地执行词项查询：避免网络开销。
		 >词项缓存：快速的LRU算法---最近最少使用算法。10mb大小。固定大小的队列方法：直接将数据插入链表---有访问则取出放到链表头。
		>切面计算：并列于filter。 如范围的切面计算：facets--->field--->range--->field/range-->to/from...。不受独立于查询的过滤器影响---即只受查询的影响。
		 >切面中使用切面过滤器：facet_filter
		 >切面中使用全局切面作用域：facet--->field--->global:true, 则根查询无关，会对全部文档根据切面条件进行统计计算设定字段的min/max/mean/文档count数。
		>不同索引的文档有无可能存在同一个分片里？：有可能的，毕竟索引的主分片数是固定的，而机器上的分片数也有限制，因为一个分片对应一个Lucene来索引。
		>倒排索引表中词项通过B+树来组织的？：有可能的，这样搜索词项就直接走B+树，就像mysql主键一样。
		
举动-痛点：底层索引控制. 如何使用不同的评分公式？不同的倒排表格式？如何处理准实时搜索？段合并、索引合并策略？
	>解法/处理思想：
		>新增相似度模型：
		  >Okapi BM25模型：估计文档和给定哈讯匹配的概率。适用于短文本文档。BM25
		  >随机偏离模型：适用于自然语言文本文档。DFR
		  >基于信息的模型：适用于类似自然语言的文本文档。IB模型。
		>在建立类型的mappings时指定某个字段使用上述的某个相似度模型：mappings-->post--->properties--->field--->type/store/index/similarity:BM25
		  >相似度模型本身的配置：settings--->index--->similarity--->自定义的名称如mastering_similarity--->type/discount_overlaps  ,则在mappings中可以在similarity:mastering_similarity。。。此外，系统提供了两个名字：default, base代表了两种经典的评分公式:未使用/使用了query_norm, coord评分因子。
		   >TF/IDF相似度模型配置：discount_laps:true表示位置增量为0的词条在计算评分时不会被考虑进去。
		   >OKapi BM25模型配置：k1:控制饱和度，词频归一化的非线性项。b:控制文档长度对词频的影响。discount_laps同上
		   >DFR模型配置：basic_model, after_affect, nomalization
		   >IB相似度模型配置：distribution, lambuda
		>索引文件的编码方式：倒排索引的写入格式，以便提高性能。配置某个字段的编解码器：properties--->field--->type/index/store/postings_format:pulsing
		>可用的倒排表格式：
		 >default: 提供词项向量压缩功能和存储字段压缩功能。
		  >属性：min_block_size将多个词项编码为块的词项个数, max_block_size。。25--48
		 >pulsing: 将高基字段中的倒排表编码为词项数组，减少Lucene搜索文档时的查找操作。
		  >属性：freq_cut_off:词项对应的文档频率小于等于该阈值，词项对应的倒排链将写入词典。
		 >direct: 词项和倒排表数组都存在内存。提升常用字段的查询性能。词项载入词典。
		  >属性：min_skip_size允许写入跳表指针的具有相同前缀的词项的最小数量。Low_freq_cutoff
		 >memory: 所有数据写入磁盘。读取时使用FST结构直接将词项和倒排表载入内存。Lucene通过FST确定词项在词典中的位置。
		  >属性：pack_fst: 用来确认保存倒排链的内存结构是否被打包为FST----打包则可以减少保存数据所需要的内存量。...
			>FSA: 有限状态接收器
			>FST: 用来紧凑的唯一性存储字符串和高效的搜索字符串：（如主键存储）。可称为 字母分枝树。即字母在分枝上，分叉点表示不同的字符串从这里开始分开，节点就是一个结束的字符串的位置(到这个节点的分枝连成的字符串就是一个存储的字符串)。
		 >bloom_default: 扩展default, 增加了bloom fiter : 更快断定判断不存在，高概率判断字符串存在。
		  >属性：delegate:确认被包装的编码器.ffp
		 >bloom_pulsing: 扩展pulsing, 增加了bloom filter.同上。
		>配置编解码器：settings-->index--->codec--->postings_format--->自定义名称--->type/min_block_size/max_block_size. 然后再在properties--->field--->postings_format:自定义名称  来使用。
		>新索引的文档是否能被立即搜索到：机制在于：
		  >真正生效的时间：
		   >索引段：是独立的Lucene索引段。索引期，新文档写入索引段。新增的索引段，不时会添加到可被搜索的索引段集合中。新增的索引段segments_N---此文件列举了索引的索引段。添加过程被称为提交，提交一次创建一个索引段，也可能同时触发索引段的合并。然而提交之后，也要等到Searcher实例重新打开--即刷新 之后才会生效，刷新默认1s一次，。。也可以强行刷新_refresh接口，也可以设置刷新时间：index--->refresh_interval
		   >可被搜索的索引段集合：
		   >保证索引的一致性：索引更改以原子方式写入索引。
		>事务日志：保存所有未提交的事务。也会在错误发生时检查事务日志---必要时再次执行某些操作。
		 >事务日志刷新：就是事务日志中的数据更改同步到索引的一次同步过程，确保写入了索引--然后清空事务日志。 api接口：_flush。。确保事务做完。
		 >相关配置：强行事务日志定期刷新时间。数据更改次数阈值达到后刷新。
		>实时读取：从索引中读取时，先看事务日志中是否有新版本，有则读事务中的。搜索方式一样，?pretty
	    >将一个文档推入索引后es做的事情：
		  >源文档存放 和 各个字段文本分析更新到字段的倒排索引表中：文本分析：token分割---->过滤器：同义词、停用词、无意义词--->映射器：词根化、大小写转化--->
		  >可以查看源文档某字段的词条流：各个词项的起止位置和词项位置。
		  >同一个字段：mappings上设置可以lang-->type:string, 并列于lang, 设置type:multi_field , field: i18n/org  来在索引时保存在两个子字段对应的两个分析器对应的倒排索引里。
		>搜索时es根据条件的不同做的不同的事情：
		  >词项查询query-term: 会使用文本分析，从字段的倒排索引中找到相应词项的文档列表。
		  >匹配查询query-match: 不会使用文本分析，只是严格的和源文档中对应字段的值进行匹配比较。
		  >搜索时指定分析器：
		>索引段合并：小索引段复制到更大的索引段，然后删除小索引段的过程。拷贝时，被标记为删除的文档不拷贝。段合并有IO代价。
		  >合并策略：index.merge.policy.type设置。
		   >tiered: 合并目标：回收更多删除的文档 和产生更小的索引段
		   >log_byte_size: 合并目标： 保持较少的索引段数量并且极小化短索引合并的代价。类似一种字节数最小索引段先全部合并的策略，动态的计算而选择下一轮合并的段。
		   >log_doc: 合并目标类似上述：但是以索引段内的文档数为计算单位而不是索引段的字节数。
	      >合并策略执行方式：调度器。index.merge.schedualer.type: concurrent/serial
		   >并发合并调度器：多线程进行段的合并。
		>补充内容：
		  >安装wiki的river插件：/bin/plugin -install xxx ..执行一些操作，则自动开始从wiki上下载文档并索引。
		  >查询建议：根据编辑距离进行----得出建议的词语。
		  >字段重要性: 可以在fields:['field1^100', 'field2^10']来表明field1比field2重要。
	    >一层一层的查询条件：本质上可以当作是一层层的逻辑条件，即整体是一个条件表达式。当作条件表达式来看。if(条件表达式)。。搜索查询就是查找满足这个 条件表达式的文档。从倒排索引表的词项上去搜或者从源文档字段上去搜。
		  >与条件表达式的对应：must/should/must_not 就相当于 与 或 非 条件关联逻辑关系。 to , from 就相当于大于小于。还有更复杂的api关系 允许存在，如contains包含对应的全文搜索，因为还要指定返回的结果的排序，所以额外有排序部分的描述-----根据字段本身-字母序 + 相关性得分计算规则-指定相关性模型 + 字段权重指定^100等。
		   >词项偏旁部首的精细匹配度搜索：query--->query_string--->query/default_field:field.ngram/minimum_should_match:85%
		  >文档范围指定部分：url
		  >筛选部分：query,filter
		  >排序部分：
		  >分组部分：
		  >切面计算部分：词项切面计算。facets--->category_facet--->terms--->field/size 
		  >聚合计算部分：aggs--->category_agg--->terms--->field/size
	
举动-痛点：分片、路由
	>解法/处理思想：
		>分片创建：为每个新建的索引，索引创建之后不能分割。一个分片一个Lucene索引对应，同一个索引的不同分片应该在不同的机器上(由分片部署意识决定，es不会将主分片和副本分片放到具有相同部署意识属性值node.group的节点上)。主分片多可以存储超过单个节点容量的数据，副本分片多对查询性能和数据安全有提升。。
		>索引文档：同一个用户的文档应该索引在同一个分片里，这样方便查询快速而不用聚合。而此时定位到那个分片就需要路由。
		  >路由：单个索引 有多个分片，就需要。
		  >索引文档时向es提供路由信息： URI参数上加一个routing=A 那么索引的这个文档就会加到同一个分片上。批量索引时，并列于_index/_type有_routing参数设置为A即可。也可以Mappings + 文档中加_routing字段来实现。
		   >索引级别的指定部署意识：从而索引的文档只会放到某个组下。index.routing.allocation.require.group:groupA（一个groupA组里的分片是在不同的节点上，一个ip下或者严格的说--里面可以有多个节点）。。一个索引的主分片数：index.routing.allocation.total_shards_per_node:4
		   >分片--->节点--->节点组: 一个索引可以配置指定在哪个节点组下。节点组下的节点分布在不同的ip下。节点和节点组之间有include/exclude/require三种关系。
		   >基于磁盘使用情况来配置分配意识：根据磁盘使用情况来判断要不要在一个节点上继续分配分片cluster.routing.allocation.disk.watermark.low。也根据磁盘使用情况决定要不要将节点中的分片迁出cluster.routing.allocation.disk.watermark.high。
		  >搜索时指定路由来查询：URI参数上加routing=A参数。
		>处理查询：
	
举动-痛点：发现节点和组成集群
	>解法/处理思想：
		>启动ES节点：组播，发现es节点，过滤找到同group的es节点，从中找出主节点，和主节点通信加入集群。主节点会分配分片过来，分片均衡一下。如果没有主节点，自己成为主节点。这个过程称为发现--模块负责选主和发现集群新节点。
		 >发现模块的实现：
		  >Zen发现：默认发现实现。组播。问题：节点的意外加入，网络原因不可用，组播产生了大量不必要的通信。单播方式：ping请求发送给指定的配置的地址，加入后会获得集群的拓扑信息。
		   >组播配置：discovery.zen.ping.multicast.address/port: 用来通信的网络接口/端口号。 group/需要发送到的地址。buffer_size组播消息需要用到的缓冲区大小。ttl组播消息的生存时间3---消息包通过的路由器个数。
		   >单播配置：discovery.zen.ping.unicast.hosts: 集群初始节点列表。连接上集群中的一个节点即可获取到集群的拓扑信息。
		  >发现模块的主节点选举功能：只存在一个活跃的主节点。可以配置只持有数据的节点：node.master: false  \r\n node.data: true 配置只作为主节点自然---会使得它这节点不持有数据。只聚合查询节点结果的查询节点：既不是数据节点也不是主节点。
		   >脑裂：一个集群因为网络故障导致n台机器中有m台不可访问了，但是m台互相之间可以访问，从而m台选出了一个主节点而组成了一个新集群，集群名和原来的一样。discovery.zen.minnum_master_nodes配置为组建集群至少需要的互相连接的候选主节点个数，通常>n/2+1
		   >Zen发现的故障检测：两个检测进程。一个进程为主节点发送ping请求到集群中其他所有节点---检测是否可用--健康检测。第二个进程为：普通节点向主节点发送ping检测主节点是否工作正常。可以设置ping的请求周期、ping请求发送后的等待回应的时间、ping请求发送-接收失败后的重试次数。discovery.zen.fd.ping_interval/ping_timeout/ping_retries
		   >云部署：EC2上。安装EC2的API来实现单播和组播。安装之后，配置discovery.type: ec2。其他的配置：cloud.aws.region;
		 >主节点：监控和管理集群中的其他节点。
		>恢复阶段：在集群建立之后--主节点选出来之后。从网关读取元数据和索引。保存在主分片里，主分片恢复完成，可以响应外部请求了，开始恢复副本。
		 >网关模块: 允许索引数据、元数据和索引的映射数据。集群的状态也会通过网关模块持久化。配置：集群组建后有多少个节点才启动恢复过程：gateway.recovery_after_nodes  多少个数据节点/主节点/等待时间：data_nodes/master_nodes/time。。。还可以配置立刻启动而无需等待的最小节点数：gateway.expected_data_nodes
		  >查看回复过程的信息：_recovery?pretty
		>人性化的Cat API:表格形式返回数据---而不是json. curl -XGET 'localhost:9200/_cat'
		>备份与恢复：es提供的快照/还原 功能。
		 >备份：集群数据推送到集群外部的仓库：亚马逊/微软的云仓库：HDFS仓库。推送API:插件。在hadoop集群上建立一个仓库：curl -XPUT 'http://localhost:9200/_snapshot/hdfs_repository' -d {'type':'hdfs' , 'settings':{"path":"snapshots"}}
		>联盟搜索：部落节点
		 >创建一个部落节点：需要一个新的Es节点：配置：tribe.mastering_one.cluster.name: cluster_one  , tribel.mastering_two.cluster.name: cluster_two 默认采用多播方式发现两个集群。当然可以配置修改为使用单播方式。
		 >在部落节点中读取数据：和在单一集群上使用的查询方式一样。不能创建索引。也不能多个集群中的同名索引。屏蔽写请求和禁止元数据修改。
		
举动-痛点：es性能调优
	>解法/处理思想：基准测试、热点线程、
		>字段数据缓存：排序和聚合时使用字段缓存。倒排索引缓存到内存。
		>doc Values: lucene中基于列的数据结构。不将数据保存在倒排索引中，而是保存在基于文档的数据结构里，存储在磁盘上。索引数据时: properties--->token--->dov_values:true  这种方式下索引文件更大---但是排序时不用字段数据缓存。
		>关闭内存交换：避免OS将RAM中的内容回写到磁盘然后又加载到内存的性能开销。boostrap.mlockall: true
		>优化查询的性能：基准测试方式启动一个节点：--node.bench true 启动参数设置。查询使用_bench?pretty 来发送设定了请求数和并发度的查询。filtered query 好于post_filter
		>热点线程API: (消耗cpu最多的线程为热点线程)当集群负荷高的时候使用---提供问题根源的信息：如查询的执行或者索引段的合并----通过es的热点代码。查看：_nodes/hot_threads
		 >线程类型：search/recovery_stream/cache/merge/index
		>扩展：垂直扩展：更好的cpu和内存---是质量上的提升。而水平扩展：直接增加机器：是数量上的提升。还可以设置自动扩展它的版本。
		>对于一个物理机上的多台虚拟机：避免一个集群的主分片和副本分片在一个物理机上。可以指定：node.server_name:abc 同时：cluster.routing.allocation.awareness.attributes:server_name
		  >候选主节点： node.data: false node.master:true  node.enable:false
		>冗余和高可用：
		>刷新频率：决定索引后多久可以被查询。频率低可以提高查询性能和索引性能。
		>索引的索引段数：多则索引快，但是RAM更高和查询更慢。
		>段合并限流：如20MB/s
		>过滤器缓存：如占内存量10%
		>分片数据缓存：聚合和提示词的时候用。
		>路由使用：因为使用路由使得文档在一个分片上。
		>预写日志大小的设置：translog :5000/200MB比如。
		
举动-痛点：开发扩展es分析能力的自定义分析插件
	>解法/处理思想：
		>扩展org.elasticsearch.rest.BaseRestHandler类：负责处理REST请求
		>扩展org.elasticsearch.plugin.AbstractPlugin
		>分析器自定义：扩展org.apache.lucene.analysis.TokenFilter等。
		
高级趣味而不是低级趣味。一辈子都活得不开心。很多人总是被表面现象所骗所恐惧所惊慌而止步不前、。心态平衡，专心工作。心理平衡建设。
科技和计算机世界：只看好坏，不看对错。方法一般，对了也没什么大不了--代价太高。可以问对方自己的缺点和对方的犹豫是什么/需要提高的是什么---无论通过没通过--您觉得我可以在哪方面做些改进。
		 
参考资料：
https://max.book118.com/html/2018/0130/151233686.shtm(深入理解elasticsearch)
《Elasticsearch server》