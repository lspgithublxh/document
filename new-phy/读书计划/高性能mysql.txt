--------mysql的处理思想都对应有 相应的“某种举动 及其导致 的问题”
>需求背景-痛点陈述：现实开发中遇到了什么痛点导致XXX的开发？  
>那么痛点的原因、产生的条件：分析是什么环境、什么动作 什么效果什么目的 等精准形容词的事实描述 导致了痛点的必然发生，难以避免？。条件-痛点。原因-结果。
>则可以消除痛点的最简单的精准事实陈述是什么：修改“条件-痛点”陈述的哪一部分就可以导致没有痛点产生。 要做的根本事情是什么：
>那么新陈述表明的解决动作是什么：
>新情况的新痛点是什么：新举动、新环境会产生的新痛点描述出来， 继续上述4条操作。

1.举动-痛点：支持数据仓库、在线事务处理系统、web应用的数据库。
	>解法/处理思想：
		>方案: 查询/连接线程/授权认证处理、查询解析(查询执行引擎)-内置函数-视图-触发器-缓存-优化、存储引擎(实现了通用的API)(数据的存储和提取)-插件(API, 扩展功能)。服务器层-存储引擎层。
			>痛点1与方案：读写并发控制--读写锁/共享排他锁(锁类别)，控制锁定的数据量-最少(锁粒度)，表锁(表上加锁，开销小)行锁(行上加锁，开销大，引擎层实现InnoDB)(锁策略)。 分析：锁的开销：获取锁、检查锁、释放锁都是开销。
				>事务：一组有特殊执行要求的操作序列。特殊要求就是数据库执行这组操作序列的时候要让这序列满足ACID标准。数据库：事务处理系统。一个数据库在处理事务时，不能让事务具有ACID特征，它就不是一个成功的事务处理系统，对事务的支持是低质量的。
					>A: 强调成功的标准：”全部“被执行，失败的要求：“已做的”全部被回滚。
					>C: 强调数据库的一致性变化。//是数据库对用户的一种保障和承诺。
					>I: 强调做中的事务对数据库的修改不能被另一个事务看到,另一个事务看到的还是原来的数据。直到事务提交成功。
					>D: 强调提交成功之后数据库的数据发生不受重启崩溃影响的其他事务可见的永久变化。
					----体现了：过程特征：隔离不可见， 结果特征：全部执行、一致性变化、持久性变化。//对CPU、内存、磁盘都有更高要求。但用户可以Look Tables语句不用事务而提供一定程度的保护。
				>事务之间的隔离级别：在SQL标准中制定的。隔离级别高，开销大。一个事务的修改，另一个事务何时可见、可见哪些。
					>读未提交：一般不建议使用。导致脏读。开销也不小。
					>读已提交：一般默认级别。读的都是其他事务提交之后的修改内容。但可能另一个事务先后两次读的内容不同--即在事务提交前和后分别读了一次，即另一个事务有不可重复读的问题。
					>可重复读：Mysql默认隔离级别。一个事务内所有的读都一样(都是提交前？)。但是，如果是范围式阅读，则前读n条，某事务插入一条，从而本事务再读读出了n+1条，这样的幻读问题。但是InnoDB貌似现在已经解决了。
					>可串行化：事务序列化执行，行上加锁，没有并发，实际很少使用。没有幻读。有加锁读？
			>痛点2与方案：两个事务陷入互相等待释放锁的死锁状态。
				>死锁检测与死锁超时释放机制：存储引擎将持有最少行级排他锁的事务回滚。
			>痛点3与方案：事务效率问题。使用修改表的内存拷贝 + 写操作行为到事务日志。即不是每次都将修改的数据持久化到磁盘。而是等后台慢慢将表的修改刷回磁盘。
				>事务日志：磁盘上，每次写直接顺序刷入磁盘。称为WAL预写日志。
			>痛点4与方案：Mysql事务的默认设置：自动提交autocommit--每次查询开启一个事务; 如果显式设置为手动提交，则手动打开事务、提交事务。InnoDB 和NDB Cluster
				>强制活动事务提交：在如Alter table执行之前，会commit当前活动事务。
				>每张表建议使用同一种存储引擎：因为事务是在存储引擎上实现的。
				>隐式锁定：InnoDB根据执行自动加锁
				>显式锁定：SELECT... LOCK IN SHARE MODE 。。。LOCK TABLES 是服务器层实现的----在InnoDB上无需使用--因为行级锁工作得很好，此命令也不建议执行。
			>痛点5与方案：必要时加锁，MVCC多版本并发控制。某个时间点有数据库的快照，辅助MVCC的实现。
				>MVCC: InnoDB存储引擎在可重复读/读已提交隔离级别下的实现， 使得读操作基本不加锁。每行添加了额外两列：创建版本号 和 删除版本号。存储的是系统版本号，新增一个事务使得系统版本号加1。UPDATE操作实际上新增了一行，从而创建版本号为新的系统版本号。
		>方案的证明：论证，考察。应用架构的鲁棒性
			
	
2.举动-痛点2：Mysql存储引擎。InnoDB设计来处理大量的短期事务。InnoDB: 热备份、行锁、事务、聚簇索引。MyisAM崩溃后无法安全恢复--损坏多恢复慢，压力上升后的锁竞争问题。
	>解法/处理思想：	
		>对表的处理：.frm文件保存表的定义信息，在数据库目录下。
		>表的存储文件：Myisam 的一个表存储在.myd 和 .myi数据文件和索引文件中。存储行记录数受限于OS单个文件的最大尺寸；无事务但可以加表锁。
		>压缩表: 表转换为压缩表，只读，提高读的性能，索引也只是读；提高性能原因在于解压一行远快于IO
		>Myisam 使用场景：日志型应用。Select 和INSERT比较多的场景；但是崩溃会丢失数据也是问题，备份只能关闭服务器--InnoDB可以热备份。InnoDB唯一缺点：空间占用更高\开销更大。
			>写入数据库的安全性：并不会直接写入磁盘，而是写到内存；等操作系统自己定期刷出到磁盘上。
		>NDB集群存储引擎：配合NDB集群数据库使用。
		>全文索引：InnoDB + Sphinx
		>数据仓库：10TB以上的数据库数据，建立数据仓库，采用Infobright 存储引擎。偶尔用TokuDB
		>指标特征：InnoDB ,全部数据在内存,2.5G;  内存200G> 足够， cpu 2*6*2 每个cpu支持2个线程
			>并发量：在32并发线程数时达到最大的并发事务数：7000/s
		
3.举动-痛点3：基准测试。针对系统设计的一种压力测试。 一定负载-->系统-->性能表现
	>解法/处理思想： sysbench, tpcc-mysql 
		>目的：在压力下测试系统的容量，测试系统需要怎样的网络和硬件。
		>指标：
			>吞吐量TPS：每秒事务数
			>响应时间分布：统计所有的请求的响应时间的分布情况，类似t分布。
			>并发性: 负载强度，同时到mysql数据库的请求数/并发请求数。
			>可拓展性：提供2倍的资源(比如cpu或者内存，具体看瓶颈)，期待获得2倍的吞吐量---即线性扩展。资源的增加，吞吐量的增加。
		>设计基准测试：测试方法
			>系统预热：吞吐量趋于稳定时?
			>一般测试过程：创建数据仓库(每个700M可以)， 将数据导入到Mysql数据库，并行多线程执行不断创建的事务，统计每分钟内执行完的事务、响应时间的分布等上述指标信息。
				(也有文件系统和磁盘的基准测试: 如磁盘每秒执行多少次随机读：如14000次随机读)

举动-痛点4：使用mysql中的常见问题：语句执行慢想优化，服务器是否达到了最佳性能状态还是还有改善的空间， 以及系统出现的停顿、卡死等现象
	>解法/处理思想：性能剖析profing, 直接查看时间都花在哪里了的一个分析报告--测量报告。
		>性能度量：查询时间。因为影响cpu利用率的因素很多()	
					>执行时间和等待时间：一个任务的花费的时间的构成。
		>测量依赖：测量根据-数据
			>慢查询日志：秒级别或者微秒级别。分析工具：pt-query-digest
			>tcp抓包记录每次查询：tcpdump分析工具
			>
		>执行计划：
			>查看各项动作耗费：set profiling = 1; 然后执行一条select语句；然后 show profiles; 可以看出每条语句的执行时间。对每条语句，可以show profile for query 查询语句id 来查看mysql执行这条语句而做的先后所有的动作以及每个动作的执行时间。
						方法2：查看INFOMATION_SCHEMA.PROFILING表，从而可以对执行动作的耗时进行排序，以便找到最耗时的几个。
			>查看各个动作执行次数：show status....比如可以得到没有使用索引的读操作的执行次数：Handler_read_rnd_next的值。EXPLAIN一般不建议使用---但是可以查看到是否使用了索引。
			>查看等待的各种原因事件和等待时间总计：从events_waits_summary_global表里查询出来。比如innodb_log_file日志事件、写数据文件事件、缓存状态改变事件、....
			>数据库命令级别的查询：mysqladmin ext -i1 | awk.... 查看每秒的查询数、线程连接数、正在执行查询的线程数
				>查看线程是否有不正常的状态和特征：mysql -e 'show processlist\G'... 如果状态为freeing items的量比较多则有问题。Sending data没问题。
				>
		>耗时所在：
			>未使用索引：子查询创建的临时表没有索引--如果和其他表联合就会更加的耗时。
举动-痛点5：建立表的数据类型的选择：
	>解法/处理思想： 
		>常见规则：索引列最好是整数。连字符串都不好。如果是UUID，还建议转换为整数UNHEX()来保存在BINNARY(16)这样的16字节的整数中。比如IP地址，保存为整数：INET_ATON() 和 INET_NTOA()来转换。
				   不适合宽表，几千个字段，会导致行解码的时候消耗太多CPU。
			>范式：非常重视一张表内 其他字段 和主键的直接依赖关系，间接依赖关系则要提出来专门建立新的直接依赖关系的表。所谓第二范式，最重要的。
				>更新多的场景。
				>优点：省内存，方便更新。缺点：查询需要关联表，导致索引策略失效。查询效率log(n^k) 关联表越多效率越低。
			>反范式：有冗余，可能导致更新多处，从而代价更高。但为了性能需要有一定的冗余。
				>查询多的场景。
				>优点：多个字段同一个表中，使得 where, orderby 上如果用了联合索引，那么都可以使用到索引，性能大大提升。缺点：更新比较慢，有冗余，但更新问题可以使用触发器来实现。数据错误问题可以修复，但性能只能改变结构来提升。
					  性能的提升，索引、冗余列减少关联表、缓存表、汇总统计表。写慢了，但是高性能的数据库设计，这是常用的技巧。
			>避免：使用mysql遗弃的特性，如指定浮点数精度，整数的显示宽度。不使用bit, set, enum这些类型。alter table会锁表和重建表，性能开销大。
		>版本数据的保存：create table a like b; rename table a to b_new, b to b_old。来新产生一个表，旧表保存好那个时间节点之前的数据。
			>某个字段数据的自增：直接使用一条update就可以了：update a set a.column = a.column + 1;不用重新去阅读数据。并且是原子的。如果需要提高性能，可以采用冗余，多行保存同样的信息--最后求和，这样可以随机rand()选择一行来自增。
			>日期的插入：可以使用mysql自带的。比如datetime有数据格式，timestamp整数方便索引，current_date取年-月-天来保存。
			>不存在插入存在则更新用一条语句实现：利用on duplicate key 这个逻辑条件关联符连接insert语句和update语句：insert into A values(current_date, rand()*100, times) on duplicate key update set times = times + 1;插入多个值或许也可以---从而都用一条语句旧完成了。
			>更新表的高级操作：可以inner join 另一个表，using(key) 来实现关联，从而在set 分支的时候可以 set a.col1 = if(a.col2 = b.col2, val1, val2) 来实现一个更新上的如果那么操作。
					>例子：update a inner join b using (key_a_b) set a.col1 = if(a.col2 = b.col2, val1,val2) 想象数据表中的数据是规律存储的。
			>只修改表的某列的默认值：alter table a alter column b set default 5; 其中alter column , modify column , change column都是不一样的。
			
举动-痛点6：索引的创建规则：解释和反问。
	>解法/处理思想：
		>索引基本：在存储引擎层实现，而不是服务器层实现。
		>索引用到：最左原则。like 'L%'也可以(因为本质是比较操作)。order by 中也可以用到(条件是：字段顺序同联合索引顺序，且排序方向一致；连表时要求字段都是第一个表的)------这样可以利用索引进行排序---而不是额外的再次排序；或者第一列被指定为一个常数。
			>不能用到：函数参数中、表达式中、不等关系
				>如果是> <, between and 这些不等关系，那么这列可以使用索引，但是后面的列就不能再使用索引了。in后面的列则依然可以。
			>前缀索引：可以where,不能order by 和Group by。创建字符串字段的前缀索引add index column(length)
			>and: 相关列可以做联合索引 add key(col1, col2)----当然是把选择性更强的放在前面。or相关语句则可以改为union的方式---因为直接or两个单列索引都不会被用到。explain + 返回时间 可以看出来。
			>in: 是范围查询--从explain type列的值range来看---当个数多8个时候即便做了唯一索引也会导致all扫描，也看作是查询联合，所以不宜太多的值。当然In中的每个可以进行索引。
			>能创建主键、唯一索引尽量创建：不能只是普通索引。
		>覆盖索引：查询的字段也在索引里---联合索引里--即where上的字段和查询的字段和order排序字段构成了一个联合索引，那么通过查这个索引就直接获取了结果，而不用回表---用主键id再去查；同时也用索引完成了排序。
			>explain中的extra字段解释：值为Using where---说明where上使用了索引，Using filesort-----mysql额外进行了排序--使用了文件排序效率低--最好不要出现；Using index ----使用了覆盖索引--查询效率最高--查询字段和比较字段和排序字段构成的联合索引被使用了。
		>索引类型：除了B+树索引，可以在建表时指定索引类型：比如create table aaa(....  key using hash(columnname)) 就使用了hash索引。。memory引擎就支持hash索引-------键是列值的hashcode, 值是行id；。NDB引擎也是。使用场景最好就是列值是字符串且比较长，这时候hash处理后可以减少存储空间----毕竟也不会进行范围查找。
					常用hash函数：crc_32  结果是整数值。索引不能用sha1()和hash()这样产生的是字符串的hash函数。---毕竟不需要尽可能消除冲突，但要求整数为结果。可以将md5()生成的字符的右半部转换为整数，效果也不错。
					              fnv64也可以。
				  >触发器可以用来直接更新新增的列的其他列的值：在begin end 之间直接set new.column2 = crc32(new.column1);即可。而且存储过程和触发器中设置变量值都要set 关键字；都要用delimiter 来做起止分割。
		>超大型的表：索引开销也大。替换技术：分区技术、块级别元数据技术
			>增删改查之后大量的表文件碎片：optimize table 来整理碎片空间。
		>不建议操作：主键更新、非顺序增加行，使用uuid作为主键---会非顺序插入和索引占用更大空间。auto increment的缺点是高并发下的插入----会有竞争的问题。
		>orderby 和 limit同时出现时：当心先抛弃再排序，即先limit后再orderby的情形。
		>压缩索引：
		>冗余索引：
		>查询每个索引的使用频率：
		>where过滤时间：在服务器层。而在存储引擎层，只是返回数据。
		>连表：用索引字段
		>索引常用策略：联合索引 + 覆盖索引查询方式。实现查询和排序都利用到索引。select ... from tableA inner join (覆盖索引的查询)as B Using(key)
			>三大类可优化的场景：扫描了太多行，额外的文件排序，使用了临时表。回表查询、 随机IO.
		>找到损坏的表并修复：check table ; repair table ;
		
举动-痛点7：查询优化，语句本身中的痛点\冗余的动作。。设计库表、设计索引、设计查询语句-------高性能mysql设计三大方面。
	>解法/处理思想：
		>查询的子任务：数量和每个的运行时间
		>慢查询表现：查询的行和列太多---取出全部列和全部行，有很多是不必要的又被用户抛弃。扫描的行数/返回的行数 比值太大。
		>explain type: 访问类型---全表扫描all、索引扫描、范围扫描、唯一索引查询、常数引用ref。 值：const, eq_ref, ref, range, index, all
		>explain rows: 预估存储引擎的扫描行数，结果会返回给服务器层。
		>explain Extra: 对存储引擎返回的结果用什么方式过滤，Using where表示服务器层用where条件来筛选存储引擎返回的结果。如果使用了覆盖索引就可以返回结果，那么Using index而不用回表查询了---也在服务器层完成。最好的，就是直接存储引擎层就用索引来过滤结果。
		>mysql查询性能消耗大头所在：不是常规认为的建立和断开网络连接、解析查询。而往往是联表查询而建立临时表、未使用索引和覆盖索引
			>mysql服务器：每秒10w查询，内部每秒扫描上百万行数据。
			>删除建议：分多次删除。即delete from ....limit 1000; 这样多次执行。
		>join: 会建立临时表？group by , order by , union 都会建立临时表。
		>in：如果()参数里是子查询，那么会被优化为exists( ...)形式，所以建议直接用exists()来代替in的写法；或者用inner join来代替。因为这样就可以利用到索引传递---两个表的索引都被使用；但no exists需要用left/inner join 来代替：子查询要慢些。常量呢？
		>查询过程：四大阶段：从用户发起查询到mysql服务器，到服务器返回用户数据
			>查询缓存: 大小写敏感的hash查找实现的。
			>解析、预处理：语法规则验证,schema存在验证，权限验证；
			>优化器生成执行计划：各个执行计划的成本估计，
				>静态优化：
				>动态优化：调整关联顺序、外连接转内连接、where运算规则等价简化、一个联合查询分解为多个执行计划、逻辑优化-存在/不存在立即返回、IN的值的排序优化、
				 >联合查询和where的结合的执行计划：是一个两层while循环迭代取数据的过程，外层通过where查找出的每个结果，都在内层循环里当作条件去查找出 外联内联
			>执行计划中调用存储引擎API: 传递给存储引擎的是指令树，一颗左侧深度优先的树---因为join是层层嵌套执行的。explain extended 之后执行show warnings之后可以看出重构的查询。
				>handler api只有几十个：提供基础的功能。执行 执行计划中 某些操作才会调用这些存储引擎的接口。
			---结果返回：是增量式的，产生即缓存和封包返回。从而加快响应。
			---mysql不能并行执行。
		>用户查询连接线程的状态：show full processlist 	。Sleep正在等待客户端连接，Query执行查询或者把结果发送给客户端，Locked在执行计划的执行中调用存储引擎API遇到的等待表锁，Analize and statistics 生成执行计划中，copying to tmp table 复制数据到临时表中，
			>预估成本：last_query_cost 
			>关联查询的成本优化角度考虑：因为先扫描一张表、再试图走索引来嵌套循环地搜索下一个连表的数据；所以会选择扫描成本低的作为扫描表。
			>排序：文件排序，再内存中是快速排序；数据量大就分成多个块，对每块快速排序然后回写，最后对排好序的块两两合并----合并算法比较简单的。
				>排序算法：冒泡排序、快速排序---一次交换、双指针排序---有一次指针传递、二叉树排序、类似二叉树原理的一次遍历--每次遍历时取出数据放在新的“排序数组”中--二分查找找到放数据的位置、分段二分排序再合并。
					>快速排序：left, right, tmp三个指针，tmp存储基准值，left, right分别从首尾开始，tmp存right的值，从left开始，比基准大的left的值覆盖到right, 再从right开始，比基准小的放到left， 再从left开始，，，如此直到left==right，这个位置的值设置为tmp，两边开始递归进行排序。这种方式不需要新空间也能n*logn的复杂度，而遍历-二分查找插入法则需要一个同样长度的新数组---尽管也是n*logn的复杂度--且时固定的最大的。
					>bitmap排序：不重复的数据的排序。直接放到相应的位置：但是需要计算数值。
					>归并排序：假设总共4n个，分成n组，每组4个，每组再中间分成2半，则因为两个数据肯定排好序，合并即可，需要最多3次，形成4个排好序的，共有n个，再次两两合并，n/2 * (7)=3.5n 同样合并之后，再次两两合并：n/4 * 15=3.75n，可以认为大约=4n，那么总共有log(4n)次，所以复杂度会小于4n * log(4n)即：复杂度小于n*logn级别。！！
					>基数排序：整数一串，先补0为等长数，然后从个位开始开始n轮排序，每次排序：0-9个slot下，对应放相应那个位上对应的数字，相同则先后放，然后从0开始，取出数据--得出该轮排好序的数据。这种方式空间消耗大，但是只需要 位数 * 数量n, 所以复杂度非常低；根本不需要比较。
					>计数排序：整数一串，遍历一遍得出最大值和最小值，最大值减去最小值得出范围k, 每个值-最小值得出的值是>=0当作新开辟数组的下标，在相应的下标元素里加上元素，新的同长数组相应位置是出现次数。那么再次遍历完就填满了这两个新的数组；再次遍历，就可以打印出全部排好序的元素了。
				>单次传输排序：新版本采用，查询的列和排序列都先查出来，然后按照排序字段排序，最后返回数据。
				>两次传输排序：旧版本采用，只查排序列，排序好后再去查选择的数据列。
				
		>同时对一个表更新和查询：mysql不允许，但是可以通过 update tableA inner join (temp table) 的方式实现----即临时表的方式。
		>优化器提示参数：若干如SQL_BUFFER_RESULT...。。有的最好不使用：比如for update 和 lock in share mode。。。USE index, ignore index, force index可以使用---但是对新版本的mysql反而不好。
		>优化特定类型的查询： 寻找代价最低的更好方案。
			>count(): 行数 、列的有值结果数--非NULL。。count(*)其实优化了，就是结果集的行数。NULL值不算。所以 select count(if col1=val2 or null)，count(...) from table 就可以统计出一列的多个值的分别个数，或者多列的多个值的个数。另一个函数sum(if(col2 = val2, 2, 0))也可以用来统计值的个数
				>补集：减少扫描的行数。比如 a > 10的个数可以转化为 all - a <= 10
			>union ： 小表在前，只在第二个表的关联字段加索引，order by 和 group by 只能全部是一个表的字段。union all 显然更好更快，没有去重的检查。
			>子查询： 用关联查询代替。因为子查询创建的临时表没有索引
			>group by 和distinct: 字段上用索引，主键索引、唯一索引。增加order by null 来不再排序。
			>limit： 延迟关联，即limit先放在一个使用了覆盖索引的子查询语句里，再外层内联而取其他字段。
						试图用一个字段来转化为一个 区间查询。或者 区间查询 + limit 20 这样的通用有一个指示字段的查询----下一页的方式通过查询21条而返回客户端20条的方式来看是否还有下一页--那么就不用查询总量了。 
			>自定义变量：set @a=1 的目的可以帮助在select 方面使用来辅助计算。又可以辅助计算on duplicate key 的冲突总量----利用 + 0 *xxx 既运算赋值又不影响结果的方式。
				统计来辅助决策。
			>where上的通用：在函数比较之前，先用可以用到索引的比较条件来过滤，这样可以大大缩小筛选范围。索引条件辅助筛选！！！
		>删除可以恢复：只是用delete from 删除才可以--因为才写日志。drop 和 truncate都不会。	
举动-痛点8： 高级特性的利用
	>解法/处理思想：
			>避免大事务产生过多的undo: 如导出数据到新的表：先create table new_table like old_table ,然后..., 所以需要手动开始事务、小任务做完、提交事务。不能默认一条语句来全部功能完成 而等待自动提交。
			>分区表：创建分区表时带上：partition by range columns(col1)， 各个分区独立索引。插入数据，数据就会根据分区列而存到不同的分区中，查询时优化器则会选择过滤哪些分区----只要直接使用分区列来进行过滤。
			>合并表：将被淘汰，略。
			>视图：不能创建触发器。查询视图的实现算法：合并算法---将查询语句和视图创建中的查询语句合并--然后去底层表查询数据返回。临时表算法----先执行视图查询语句查出数据放到临时表中，后将查询语句转为等价的查询临时表的语句；通过explain type字段可以看出采用的临时表delivered---临时表算法视图不能被更新。。
					>create algorithm=temptable view as select * from table1 一般有group by ,union  就不能更新视图。
					>用途：不影响查询结果而更改视图的表结构；给表列赋权。因为没有索引-----所以也可以用来当作连表的第一个表。
			>存储过程：能在应用程序中就不放到服务器端。
			>触发器：可能导致死锁和锁等待----从而导致原来的sql执行失败。一个事务里，所以一起成功或者失败。
			>事件：即定时任务。create event abc on schedule every 1 week do begin xxx end;
			>取锁和释放锁：之前可以增加：declare continue handler for sqlexception begin end;
				>取锁：get_lock(),,,,, 释放锁release_lock()
			>游标：declare  name cursor for select ..... ; open name ..... fetch name into var;用loop end loop或者repeat until done end repeat;可以实现循环。
			>绑定变量：使得sql语句解析一次，而缓存执行计划，后面客户端直接传递参数和句柄即可---且是二进制形式。
				>SQL接口绑定变量：prepare name from @带?的sql字符串， set @var=val; execute name from @var;deallocate prepare name;相当于一种动态sql的功能。
			>用户自定义函数：UDF常常由C语言编写。一般当作计算工具用
			>插件：
			>字符集：character_set_connection, character_set_client, character_set_result 等多种字符集设置变量；同时，字符集设置级别：库-表-列。
			>全文索引： 索引列、关键词、关键词所在的文档id、关键词和各个文档的相关度--出现次数、关键词对应所在的文档总个数和出现总次数。
				>查看：show index from tablename; 返回列中有：index type: fulltext就是全文索引
				>增加：alter table name add fulltext key(colname);//
				>查询相似度：select match(colname1, colname2) against('text content') from tablename where match(col) against('text content');返回的就是匹配的相似度,匹配的文本内容中的单词数多则相似度高-文本相似也高些。最好不要加在order by 上进行排序。
				>布尔搜索：select title, right(title, 20) from tablename where match(title) against('+text1 +text2') in boolean mode
				>短语搜索：against('"短语"') 这样可以精确匹配，返回结果。
				>缺点：相关度的度量只有词频，不能出现位置。
			>XA事务：在多个服务器之间同步数据的方法。
			>查询缓存：直接缓存查询的结果，且有失效机制。如果有实时数据不确定数据则不会缓存。
			
举动-痛点9：优化服务器配置
	>解法/处理思想：
		>服务器资源：内存大小、cpu核数
		>设计目标：工作负载、数据量、应用需求/类型
		>配置文件位置：/etc/mysql/my.cnf
		>查看：show global variables;
		>常见配置选项：服务端：数据路径、日志路径、慢查询日志路径。。4G内存，1000个连接？---设置文件句柄open_files_limit超过一万比如6万多。
		>高性能事务处理：innodb_flush_log_at_trx_commit=1 并且日志文件放到一个有电池保护的写缓存的RAID卷中。
					innodb调用fsync()来刷新数据和日志文件到磁盘。
		>双写缓冲：最近写回页。Innodb从缓冲池刷新页面到磁盘时，先刷到双写缓冲，再到磁盘。大概100页。
		>优先级设置：写低于读：low_priority_updates;
		>监控工具：innotop
		>压缩后存储：compress()
		>建议配置：expire_logs_days 日志失效天数
					max_allowed_packet 最大允许接收发送包大小
					max_connect_errors 抵御蛮力攻击
					skip_name_resolve 关闭DNS查找

举动-痛点10：操作系统和cpu的影响
	>解法/处理思想：
		>缓存：最近使用的数据和相邻数据，或许都是下一步需要的数据。
			>多次内存修改一次磁盘刷新：
		>顺序IO: 每秒5kw字节50MB，而随机IO,则1W字节10KB。内存顺序5亿字节500MB，随机IO则2.5kw字节25MB。所以磁盘顺序想当快。
			>预写日志WAL：就是缓存后连续顺序的写入日志。把随机IO变为连续IO, 把同步写变为异步写。
		>读取单位：内存到高速缓存是缓存行、磁盘到内存是数据页。
		>闪存：磁盘并发是个问题，闪存则更多。随机IO支持更好。但是写入存满过数据的闪存需要擦除块512k之类---没有空闲块而等待擦除完成比较耗时--几ms, 写入0.3ms。
			>运行在闪存上的mysql:
		>RAID: 运行在RAID上的mysql存储引擎。就是多个磁盘构成的磁盘组--如10个，可以提高并行度。
		>SAN: 由FC交换机连接存储阵列和服务器主机构成的网络---存储区域网络。一种专用网络存储系统。
			>DAS: 应用软件、文件系统、外部存储设备 都在服务器上。直连存储。
			>NAS: 应用软件 在本地， 文件系统+外部存储设备 在另一个地方；通过网络连接访问。就像访问网盘。网络存储器。
			>SAN：应用软件+文件系统在本地，外部村粗设备独立部署，通过FC交换机连接。可以多个FC交换机，多个应用服务器连接。一个或多个存储设备。网络为高速网络--光纤，ATM协议在此网络之上。
		>innodb的事务日志不同于binlog二进制日志：
		>tcp积压问题：mysql的back_log选项配置，sysctl的tcp_max_syn_back_log也要查看--这个是系统的配置。MRTG多路由流量绘图器--监控工具。
		>系统问题诊断工具：Dtrace, SystemTap,火焰图。	
		>vmstat : 可以查看cpu时间的操作分布，交换区的统计分布、进程运行等待数。
		>iostat: 每秒合并的读请求和写请求数，每秒镀锡的扇区数。每个请求花费的毫秒数。
	

举动-痛点11：复制。主备复制的问题和过程。
	>解法/处理思想：
		>复制方式：主库记录二进制日志(语句或者数据行)，备库重放日志。因此， 因为通信时间数据传输解析，会有时间延迟。第二，因为是执行成功了才发送，所以语句执行时间
		>主备目的：分布在各个数据中心---就近查询。
					每个备库可以查---读负载均衡。
					数据备份---天然。
					避免单点失败---主备切换。故障切换。
					新版本升级测试---备库的mysql版本可以更高。
					--如果用一个备库不对外提供服务---那么还可以用来当作开发测试。
		>主备复制过程：主库把数据更改事件记录到二进制文件binary log 里(准备提交事务之前将数据更新事件记录到binlog, 即按照事务提交顺序记录的)；---> 备库IO线程远程请求主库的dump线程读取数据更改事件记录日志binary log 日志写到自己的中继日志relay log里；----> 备库的SQL线程读取relay log重放事件。
		>配置复制：对一个已经运行的主库配置一个备库。两个库上都创一个新用户并赋权：grant replication slave, replication client on *.* to repl@'192.168.0.%'	 identified by 'password';	 以方便主备切换角色。		
			>主库打开二进制日志并配置serverID: 在my.cnf中增加：log_bin = mysql-bin    和 server_id = 10 如果show master status没有看到之前配置的log-bin,那么需要重启服务器。
			>备库配置：log_bin = mysql-bin  server_id = 2 relay_log = /var/lib/mysql/mysql-relay-bin  log_slave_updates = 1 read_only = 1  (重放事件记录到自己的二进制文件中，方便主备切换时)
				>备库启动：change master to master_host='server1',master_user='repl', master_password='password',master_log_file='mysql-bin.000001',master_log_pos=0（从头开始复制）
				>备库复制动态：show slave status查看  show processlist 查看三个线程。
			>运行已久的主库同步复制到新的备库：主库在某个时间点的数据快照 + 主库二进制日志文件在某个时间点的偏移量 = 日志文件坐标。从而快照 + 二进制文件从快照时间开始的日志 就可以恢复出数据。
				>其他复制方法：mysqldump数据库转储。mysqlhotcopy rsync来热备份。
		>语句复制的问题：current_date, current_user都不一样。		
		>基于行的复制：直接记录变更的数据到二进制文件。崩溃后很难找到问题所在--很难继续，几乎只能重新开始。		
		>双主结构：灾备方便。两个主，都启动了二进制日志记录和中继日志。一台上的变更都会发送给另一方，另一方又会发送给原来的方---原来的方检查serverId为自己则忽略。		
		>双主双从：增加了冗余。
		>分发主库：专门代理主库的分发复制给其他备库。blackhole存储引擎-----不存储实际数据---但是会写二进制文件。
		>监控复制情况：show master status
			>show master logs; show binlog events in 'mysql-bin.000223' from 13634;
			>show slave status---展示复制落后了多少
			>pt-table-checksum 确认备库和主库数据是否一致。
			>pt-table-sync 比较主库和备库的差异。
		>多个备库一个备库提升为主库后：其他备库还是要手动change master to 来改变主库同步源。
		>切换主库的过程：1.主库停止写入set global read_only=1或者flush tables with read lock;  2. 备库赶上主库日志 select master_pos_wait() 3.提升一个备库为主库 set global read_only =8; 4.其他备库改变主库为新的主库 change master to 。
		>备库相关工作：select into outfile ; load data infile;
		>mysql其他存储引擎：自带可用如federated
		
举动-痛点12：可扩展的mysql
	>解法/处理思想：
		>几个指标：响应时间多久---性能； 一天内多少时间都能够响应？--可用性；可以水平扩展到支撑多少容量多少用户同时访问还保持高性能高可用(增加资源提升容量的能力)。---可扩展性。
		>真实容量：在性能能够接收的条件下能够达到的最大吞吐量。
		>吞吐量：每秒事务数、每秒查询数都可以。
		>扩展策略和扩展方案：增加机器--垂直扩展；任务分配--水平扩展;
			>从单台机器到分片部署：单台机器---> 一主多备 --> 按功能分区存储(每个功能区相对独立，无需联表，独立数据库存储;主备结构) ---> 功能区内的数据分片存储(用一个map之类结构；id-cluster的方式指示存储在哪个集群上，每个集群主主结构)
				>分区方法确定分区键：实体-关系模型利用。
				>单个数据库对一张表分片：a_23这样来分到多张表上存储。
				>数据分配方法：固定分配：直接计算hash/crc32等得出一个分区键值来决定放到哪个分区。动态分配：类似先知道各个键在已有分区中是否存在，来选择要不要存到新的分区上；或者可以建立一个分区策略表--userid-shardid这样还方便动态修改。
		>全局ID：利用mysql的一张表的autoincrement生成，memcached incr()或者redis。 mysql 的uuid_short()也可以连续生成。	
				>或者复合键：比如复合的整数：物理机号+物理机hash值+docker分配号+时间戳+自增号, 每个固定位数。
		>向分片分配数据：hibernate shards 可以提供。sphinx是一个全文检索引擎。
		>mysql部署适合策略：cpu24, mem128G最好采用部署多个mysql实例---不同端口或者绑定不同ip，每个负责一个分片；多分片部署。更能利用机器的硬件资源。
		>云计算好处--集群弹性扩展：
		>mysql的缺点在扩展性：而nosql则就是为了扩展性设计的。NDB cluster ---前端使用mysql存储引擎来支持sql +NDB数据库。
		>数据库关键四种特性：高可扩展性(资源-容量图来描述)、高性能、高可用、事务性。。。其他：容错--节点间数据分片、分布式(查询分发，节点并发)、高并发-高负载、是否支持复杂sql如连表---数据仓库的基础，
			>clustrix
		>归档-清理：冷热数据而分表、基于时间分区-动态分片。
		>负载均衡：最多使用硬件负载均衡, 少TCP代理。
		>负载均衡2：使用虚拟地址，Pacemaker.。虚拟一个Ip地址，在服务器之间转移。---即一个不通走另一个。LVS, wackamole
		>软件中间代理负载均衡：HAProxy， 部署在应用服务器集群和数据库集群之间，负责负载均衡。
			>负载均衡器：首先不知道各个节点的真实负载---所以负载效果不均衡不是很好。另外，单个会话的请求可能不会分发到同一个mysql服务器上/应用服务器上。
			>负载均衡器的健康和负载检查：mysql服务器上部署一个http服务器软件来代理检测Mysql服务器上的：操作系统负载/proc/loadavg、复制状态、mysql连接数。这个http服务器软件需要执行一个脚本来实现此功能。当然可以纯粹写一个监听80端口并响应数据，或者配置xinetd来调用脚本程序，则连服务器软件都不用安装了。
			>负载均衡算法：首先会记录有各个服务器的信息(静态资源+动态负载信息)：连接数、响应时间平均值、cpu数服务器本身性能差异。。也有请求的信息：ip地址、url信息...。
				>看作是纯粹仅仅只对服务器选择的过程：则有随机、轮询算法, 权重算法--不同cpu数而性能不同而安排不同的流量上去，最小连接数算法--打到当前连接数最小的服务器上。
				>当作是请求特征对服务器的映射过程：对请求url进行hash算法，得出一个值映射到服务器上，对请求取ip地址算法---得出一个值映射到服务器上。
				>极端情况保护负载：每台服务器最大n个事务连接，那么都达到数目之后不再接收请求，请求先放到一个队列里----如mch阻塞排队。
				>新增机器：启动、预热、修改负载均衡器配置、保留足够未使用的容量缓冲
		
举动-痛点13：高可用性
	>解法/处理思想：
		>常用定义方式：一年可用时间/一年的总时间。比如99.999%就是一年只有5min宕机时间。不可用，就是宕机，或者完全超时无响应。
		>增强的成本和不可用的代价：是增加成本，还是容许不可用的损失，取一个平衡。看ROI.
		>高的原因：良好的架构,,,,预防和恢复。
			>宕机的原因：系统资源消耗-cpu/mem/网络入口出口流量/系统线程数/文件句柄数/磁盘。
						sql查询性能提高，更新语句的优化。
						复制问题--主备复制。
						过载、断电、bug损坏。
		>高的方案：共享存储或者磁盘复制。通过冗余方式获得高可用性。冗余的方式实现故障转移和故障恢复。故障转移--故障切换。
			>减少原因出现--减少失效时间：更规范开发，增加监控统计报警
			>补救措施--减少恢复时间：增加冗余，进行故障转移。
		>DRBD: Linux内核模块方式实现的同步复制技术。主服务器通过DRBD将每个块复制发送到备用服务器，在磁盘块层进行复制。秒级。
			>脑裂综合征：两个备用服务器同时提升自己为主服务器。高可用集群中的心跳线断开，导致互相认为对方出了故障，而提升自己为主库，争用共享资源。
				>解法：增加串行电缆作为heartbeat心跳线，ping一下参考ip----来确认自己的网络是否是通的。
		>mysql同步复制：主库上的事务在备库上提交之后才能被认为执行完成--否则依然认为事务处理失败。这样保证没有事务丢失，至少一个备库有完整的数据。
			>模式：主动-主动模式。
			>实现技术：mysql cluster ..集群级别保持ACID。中的D----持久性，节点崩溃而不丢失数据。节点崩溃而依然可以提供服务。
			>写入集合的复制技术：基于行的二进制日志事件编码。
		>故障转移：
			>工具：high avaliability linux项目里的工具。pacemaker
			>虚拟IP：
				>ARP协议：每台主机都有一个ARP高速缓存，保存着所在同一个网络内的所有主机的ip地址--mac地址的映射表，这个表里既有真实的主机的Ip地址--及其mac地址映射，也有虚IP---某台机器的ip地址这样一对映射，这个映射中的ip地址就是虚拟ip地址，mac地址就是实际落实这个ip地址服务的机器的mac地址，当这个机器宕机之后，配置的另一台同网络内的主机就会向网络内所有主机广播发送一个ARP数据包，里面就有一个这个虚拟Ip地址---自己的mac地址 这样一对映射；从而发送到虚ip的数据会被发送到这台机器上。困境在ARP缓存时间可能比较久。
					>工作地址：即虚拟ip地址，主机地址即主机的真正被分配的ip地址。
					>地址漂移：工作地址从一台机器转移到了另一台机器。即所在原来的机器故障了，而另一台机器向网络内发送了一个ARP数据包改变了工作地址的mac地址。
			>常用方法：代理、端口转发、网络地址转换NAT、硬件负载均衡。
				>代理：将web服务器连接打到另一个数据中心的和源数据中心保持数据同步复制的mysql集群。
		>实现目标：数据服务可用(增加两次故障之间时间，减少一次故障恢复时间)、数据不丢失、数据一致性变化。		
			
举动-痛点14：云中的mysql
	>解法/处理思想：云托管平台。基于商业考虑而使用云。
		>iaas: 提供基础设施，用户自己安装mysql和os，并进行响应的配置。
		>DBaas: 提供mysql服务，用户也可进行一些mysql配置。但是服务器上的非mysql部分看不到。
		>云：即用即付。用运营成本代理硬件成本和维护成本。相当于购买专家搭建的平台。
		 >是对基础设施的另一种思考方式：通过api来定义和调用和控制的资源。
		 >扩展对象：web服务器，这样的无状态服务器。但是对于数据库服务器，是有状态的持久化的组件，本身难以扩展。
		 >缺点：磁盘速度慢。CPU/RAM都是。但网络性能不是。mysql云上的thread running  可能仅仅在8-12就性能开始变差了。同时mysql希望有24核心的cpu，但是云可能不能提供。
		  >原因：虚拟化开销。
		>DBaas上的mysql: Amazon RDS : 使用 mysql + EC2 + EBS的集合。修改了mysql,使得用户通过mysql访问服务器的文件系统受到了限制。
		>天生的云数据库：自动扩展。
		
举动-痛点15：应用层优化
	>解法/处理思想：让数据库做还是让应用做，合理分配一个任务。
		>mysql的嵌套关联不一定是最好的：可以在应用中进行关联。对于复杂的计算和正则匹配也可以。
		>直接连接到具体的数据库：在编写连接数据库的http时。
		>处理请求：web的最佳方式是使用队列，先将请求放到队列里。web服务器根据并发度--cpu核数和IO情况自适应地从队列里取下一个请求过来处理。
			>pt-tcp-model:从tcp转储中测量和建模分析系统的可扩展性和性能特征。
		>缓存：对内容粒度的选择和对缓存时间的选择。缓存好处：并行读。
		 >被动缓存：memcached。缓存没有就返回空。
		 >主动缓存：squid, guava。缓存没有命中就做其他事情来来请求生成结果来缓存。
		>HandlerSocket: 直接访问Innodb 引擎层。memcached也可以。
		>redis队列：实现方法？
		
举动-痛点16:：备份和恢复
	>解法/处理思想：数据还原和系统恢复。 	
		>备份系统：日常备份。
		>恢复系统：危及恢复。
		>备份mysql: 基于快照的备份。生产服务器和备份服务器。
			>基于故障时间点的恢复：expire_logs_days设置的足够长。
			>验证备份是否正常：
			>恢复所需要的资源和时间： 	
			>备份方式：将二进制日志保存在独立的SAN卷或者使用DRBD磁盘复制。最大问题：使用flush tables with read lock会导致mysql关闭并锁住所有的表。
				>逻辑备份：语句备份/符号分割文件。耗时耗空间，浮点数结果可能还不一样。恢复也慢。mysqldump   符号分割文件----15000w行---800M左右。几十秒导入，几百秒导出。
				>物理备份：文件备份。innodb原始文件也大。文件也可能出问题。使用mysqlcheck验证物理备份是否正确。
			>有主备复制的备份：二进制日志、中继日志等。 可以先flush logs	
			>增量备份和差异备份：增量备份：是对上一次全备份以来的差异记录。差异备份：是对上一次无论是全备份或者差异备份以来的差异记录。
				>恢复时间更长。
			>ZFS文件管理程序：有去重特性。
			>一致性备份：对于订单和扣款服务。如果不是事务型，那么需要Lock tables 锁表来进行备份，侵入性更大。如果是事务型，则只需要repeatable read可重复读级别就可以了，会有一致性和基于时间点的快照，而开始备份后不会阻塞后续的工作。
				>LVM系统来获取数据和日志文件的一致性快照。
				>STOP---CONT两个命令即可。
				>使用备库来备份。(备库用做只读常常)
			>mysqlbinlog: 查看二进制日志的内容
			>符号分割文件：导出：select * info outfile '/a/b/c' ...... 导入：load data infile '/a/b/c'
			>LVM快照：创建文件系统的快照、文件系统的镜像。某个时间点的一致性快照。快照只是差异数据，不是完整的一个副本备份。
				>方式：LVM通过写时复制copy-on-write的技术来创建快照。整个卷的某个瞬间的逻辑副本。
				>写时复制：多个调用者对同一份数据，读时共享，写时修改它时产生一个副本。其他调用者看到的仍然是原始版本。
					>共享被访问的页面：有task修改时，内存管理单元MMU会抛出一个异常，内核捕获异常而创建一个物理内存，将数据复制到这个新物理内存，然后重新向MMU发出执行这个的task的命令。
				>查看系统逻辑卷和卷组：lvs， vgs
				>创建一个快照：lvcreate --size 16G --snapshot --name backup_mysql /dev/vg/mysql 写时复制空间16G， 名称和来源逻辑卷都表明。lvs查看实际上是创建了一个新的逻辑卷。lvremove删除快照。
					>监控设备的状态：Nagios系统。watch 'lvs | grep backup'
					>挂载：就是将设备文件的顶级目录连接到Linux系统的某个目录下，从而访问这个目录就等同于访问到设备文件/目录。
							>最好选择linux下某个空的目录，因为目录下的文件都会被隐藏---在当作挂载点的过程中。
			>在线备份：flush table with read lock;show master status;来不释放锁；然后获取LVM快照，释放锁，--unlock tables;
			>Innodb引擎的mysql快照：对事务日志文件和数据文件都要做快照。因为innodb引擎时，提交事务先到事务日志文件里，然后再从事务日志文件中读取事务并应用到数据文件里。
			>无锁备份：
			>恢复逻辑备份：可加--skip-networking。。停止mysql服务器，将数据从备份移动到目录，载入逻辑备份文件，检查和重放二进制文件。以完全权限重启服务器。	
				>set sql_log_bin=0;source abc.sql set sql_log_bin=1
				>gunzip -c abc.sql.gz | mysql 
				>grep 'insert into abc ' | mysql shujukuming	
				>对于一般的分隔符号文件：可以用mysqlimport来导入。
			>恢复物理备份：直接简单的将文件复制到正确位置。innodb引擎则还是需要重启。
			>注意使用建表中的默认值：default current_timestamp on update current_timestamp
			>对有害语句做回滚操作：比如不小心执行了drop table;
				>先复制数据库到同一个服务器的其他地方：flush tables with read lock;
														server1# cp -a /var/lib/mysql/sakila /backup/sakila;
														flush logs;
														server1# mysql -e "show master status" --vertical > /backup/master.info;
														unlock tables;
				>然后有人执行了删除表：use sakila; drop table sakila.payment;
				>恢复：停mysql ->移动mysql目录下的salika库到一个临时文件-->从备份里将salika移动到mysql目录-->对my.cnf添加配置禁止连接 --> 安全启动mysql
						server1# /etc/init.d/mysql stop; -->  mv /var/lib/mysql/salika /var/lib/mysql/salika.tmp --> mv /bakcpu/sakila /var/lib/mysql/ -->skip-networking ;socket=/tmp/mysql_recover.sock --> server1# /etc/init.d/mysql start
						查看drop语句所在的起止位置-->重放二进制日志文件到drop开始位置停止，再从drop结束位置开始继续执行到末尾-->
						mysqlbinlog --database=salika /var/log/mysql/mysql-bin.000215 | grep -B3 -i 'drop table sakila.payment';--->
					    mysqlbinlog --database=salika /var/log/mysql/mysql-bin.000215 --stop-position=352 | mysql -uroot -p
						mysqlbinlog --database=salika /var/log/mysql/mysql-bin.000215 --start-position=429 | mysql -uroot -p
						检查数据没有问题-->关闭服务器-->撤销对my.cnf添加的配置--->重启服务器
				>基于时间点的恢复：延时的备库来恢复：备库上用start slave until相关来处理。
									使用日志服务器来恢复：需要一个记录所有日志的日志服务器A, 和A的备库B, 但是B的配置里新增：replicate-do-table=salika.payment 
				>对于数据事务服务：关闭 硬盘驱动器的回写缓存。确保数据持久化问题。
				>恢复损坏的Innodb数据：
					>二级索引损坏：optimize table 
				>备份工具：快照备份：mylvmbackup  热备份：percona xtrabackup
					>mysqldump: 逻辑备份。服务器之间复制表：
				>备份脚本化：bash
					>use strict;set -u; set -e;
					>
	
举动-痛点17：mysql工具集
	>解法/处理思想：percona toolkit  开发工具
		>监测工具：Zabbix ； Nagios ;Cacti; Zenoss; OpenNMS;
				MoNyog; New Relic ; 
		>实时视图：innotop
		>空转等待：innodb_sync_spin_loops
		>等待关系图：
		>大文件传输：1.普通方式：压缩->传输-->解压缩： gzip -c /abc/a.myd > a.myd.gz ; scp a.myd.gz root@server2:/var/lib/mysql/mydb/   ; gunzip /var/lib/mysql/mydb/a.myd.gz 
		                      特征: 顺序执行， 既读又写。
					2. ssh一步到位方式：管道+ssh 本地读异地写: gzip -c /abc/a.myd | ssh root@server2 "gunzip -c - > /var/ lib/mysql/mydb/mytabe.myd > /var/lib"
					3.更快的方式--nc非交互操作方式：发送监听方式：接收方：nc -l -p 12345 | gunzip -c - > /var/lib/mysql/mydb/mytable.myd  发送方： gzip -c - /abc/a.myd | nc -q 1 server2 12345 
																	tar方式：nc -l -p 12345 | tar xvzf  发送方： tar cvzf - /abc/a.myd | nc -q 1 server2 12345
					4.rsync 方式 ，监控：vmstat -n 5 
		>explain的执行含义：返回执行计划而不是实际的执行
			>查询执行计划：左侧深度优先树
			>update: update table1 inner join table2 是可以的。
			>各个字段的含义：type----访问类型 ； ref----语句中出现的关联中的其他表的列； rows-检查的行的估计 ； filtered----表里符合要求的记录数
					Extra: 需要展示的其他信息。Using index使用了覆盖索引， Using where 存储引擎检索行之后过滤。
					
		>锁的竞争：用锁来控制资源共享的系统
			>表锁：服务器层的。Lock table xxx read;/write也可以。就可以获取到。
					隐式锁：select sleep(30) from dual;//会创建锁并阻塞其他隐式锁和读写表锁。
					查看谁持有锁：mysqladmin debug
			>全局读锁：flush tables with read lock;
			>命名锁：rename table时候会和表锁冲突而等待。
			>用户锁：get_lock('abc', time)是字符串锁， 用字符串来同步等待。
			>行锁： select *** from .... limit 1  for update; 那么就会在表的第一行增加锁。。show innodb status查看。
				>使用复杂查询可以查出等待了多久，等待线程和锁进程。
		>Sphinx: 使用：先创建配置文件---主要是索引的sql中的列；然后执行./indexer name 来创建最初的全文索引数据文件。然后启动searchd后台进程来同步这些变更。
			>相关度排序：BM25权重函数
				>相关性得分：首先：每个Query有多个语素，搜索结果是多个文档
									一个Query和一个文档的相关度定义为=Score(Q,d)= ∑R(qi,d) * wi 即每个语素和该文档的相关性得分的加权和。
											wi权重只和Query的那个语素和全部的文档有关：wi = IDF(qi)=log((N - n(qi) + 0.5)/(n(qi) + 0.5))  N就是文档总数，n(qi)就是包含了qi的文档数。
											R(qi,d) = fi * (k1 + 1) / (fi + K) * qfi(k2 + 1)/(qfi + k2) , K=k1 * (1 - b + b * dl/avgdl), k1,k2,b是调节因子，dl为文档d的长度，avgdl为所有文档的平均长度，qfi为qi在Query中出现的频次。
										---得出Query对每个文档的相关性得分后，自然就可以用这个得分进行排序了。
				>短语近似度：即Query的最大完整长度在文档中出现的次数多分值更大。
				>BM25权重函数:
			>性能：关键字索引搜索/全文搜索，或者全文扫描都比mysql快。
			>搜索方式：伪关键字，筛选。根据选择性和覆盖面决定。对where搜索。
			>mysql性能差的两个地方：无索引的order by 和 Limit n,m 占用内存而丢弃多和文件排序慢。但sphinx优化了。
			>对group by 查询优化：·1亿行的分组也可以。尤其对一组内求函数值的某行。	
			>将多个查询放在一起发送给sphinx,它或许会进行优化。而一次返回给用户各个结果。且多个查询可以使用到多个cpu.。而且不需要同步----并发查询时mysql需要因此才性能瓶颈。
				>分片数据：就是分组存数据，存到不同的物理服务器。	    
			>主程序Indexer和searchd:  indexer---输入一个文档建立n个列的n个索引。searchd--查询indexer创建的索引。
				>使用：源码编译程序configure && make && make install -->配置--->初始化索引-->启动searchd, 定时运行indexer更新索引。
			>mysql建表使用sphinx引擎：engine=sphinx connection="sphinx://localhost:3312/test"
				>搜索： select * from tableA where query="test;mode=all"
				>索引和查询：索引建立的太多，导致插入和更新都很慢。因为需要更新索引。所以采用sphinx。
			>数据库设计的经典痛点：为数据的联动。数据的依赖关系。如果一个表新增一条数据，而导致另一张表要增加很多条数据，则这是个痛点；要让另一张表只增加一条数据或者不增加数据，则要考虑一个表中的数据是不是要映射到另一张表的类别---，
								数据之间的耦合关系，数据独立变化的各种可能情况----对其他数据/依赖它的数据。量大的数据不能直接依赖量大且经常变化的数据。
								在一个范围内动态增减的数据，可以将另一组数据的关联关联到这个范围上。如果没有范围， 可以尝试给它们指定一个范围-一个标记-一个类标记-一个类别标记-一个组标记。同理，可以给另一写数据指定一个组-小组，然后建立这个小组和另一个小组的关系；；这样，两个小组内的成员可以独立变化， 而之间仍然保持着对应关系----且不用直接对他们直接做关联---从而减少不少工作。
								
x.举动-痛点： SQL优化高级特性
	


		
参考资料：
1.mysql手册
2.https://www.cnblogs.com/welhzh/p/9221155.html
3.https://www.jianshu.com/p/00660a56cc2c(虚拟Ip参考)
4.https://blog.csdn.net/z_lbj/article/details/8068874(BM25查询与文档的相关性得分)