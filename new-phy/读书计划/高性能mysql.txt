--------mysql的处理思想都对应有 相应的“某种举动 及其导致 的问题”
>需求背景-痛点陈述：现实开发中遇到了什么痛点导致XXX的开发？  
>那么痛点的原因、产生的条件：分析是什么环境、什么动作 什么效果什么目的 等精准形容词的事实描述 导致了痛点的必然发生，难以避免？。条件-痛点。原因-结果。
>则可以消除痛点的最简单的精准事实陈述是什么：修改“条件-痛点”陈述的哪一部分就可以导致没有痛点产生。 要做的根本事情是什么：
>那么新陈述表明的解决动作是什么：
>新情况的新痛点是什么：新举动、新环境会产生的新痛点描述出来， 继续上述4条操作。

1.举动-痛点：支持数据仓库、在线事务处理系统、web应用的数据库。
	>解法/处理思想：
		>方案: 查询/连接线程/授权认证处理、查询解析(查询执行引擎)-内置函数-视图-触发器-缓存-优化、存储引擎(实现了通用的API)(数据的存储和提取)-插件(API, 扩展功能)。服务器层-存储引擎层。
			>痛点1与方案：读写并发控制--读写锁/共享排他锁(锁类别)，控制锁定的数据量-最少(锁粒度)，表锁(表上加锁，开销小)行锁(行上加锁，开销大，引擎层实现InnoDB)(锁策略)。 分析：锁的开销：获取锁、检查锁、释放锁都是开销。
				>事务：一组有特殊执行要求的操作序列。特殊要求就是数据库执行这组操作序列的时候要让这序列满足ACID标准。数据库：事务处理系统。一个数据库在处理事务时，不能让事务具有ACID特征，它就不是一个成功的事务处理系统，对事务的支持是低质量的。
					>A: 强调成功的标准：”全部“被执行，失败的要求：“已做的”全部被回滚。
					>C: 强调数据库的一致性变化。//是数据库对用户的一种保障和承诺。
					>I: 强调做中的事务对数据库的修改不能被另一个事务看到,另一个事务看到的还是原来的数据。直到事务提交成功。
					>D: 强调提交成功之后数据库的数据发生不受重启崩溃影响的其他事务可见的永久变化。
					----体现了：过程特征：隔离不可见， 结果特征：全部执行、一致性变化、持久性变化。//对CPU、内存、磁盘都有更高要求。但用户可以Look Tables语句不用事务而提供一定程度的保护。
				>事务之间的隔离级别：在SQL标准中制定的。隔离级别高，开销大。一个事务的修改，另一个事务何时可见、可见哪些。
					>读未提交：一般不建议使用。导致脏读。开销也不小。
					>读已提交：一般默认级别。读的都是其他事务提交之后的修改内容。但可能另一个事务先后两次读的内容不同--即在事务提交前和后分别读了一次，即另一个事务有不可重复读的问题。
					>可重复读：Mysql默认隔离级别。一个事务内所有的读都一样(都是提交前？)。但是，如果是范围式阅读，则前读n条，某事务插入一条，从而本事务再读读出了n+1条，这样的幻读问题。但是InnoDB貌似现在已经解决了。
					>可串行化：事务序列化执行，行上加锁，没有并发，实际很少使用。没有幻读。有加锁读？
			>痛点2与方案：两个事务陷入互相等待释放锁的死锁状态。
				>死锁检测与死锁超时释放机制：存储引擎将持有最少行级排他锁的事务回滚。
			>痛点3与方案：事务效率问题。使用修改表的内存拷贝 + 写操作行为到事务日志。即不是每次都将修改的数据持久化到磁盘。而是等后台慢慢将表的修改刷回磁盘。
				>事务日志：磁盘上，每次写直接顺序刷入磁盘。称为WAL预写日志。
			>痛点4与方案：Mysql事务的默认设置：自动提交autocommit--每次查询开启一个事务; 如果显式设置为手动提交，则手动打开事务、提交事务。InnoDB 和NDB Cluster
				>强制活动事务提交：在如Alter table执行之前，会commit当前活动事务。
				>每张表建议使用同一种存储引擎：因为事务是在存储引擎上实现的。
				>隐式锁定：InnoDB根据执行自动加锁
				>显式锁定：SELECT... LOCK IN SHARE MODE 。。。LOCK TABLES 是服务器层实现的----在InnoDB上无需使用--因为行级锁工作得很好，此命令也不建议执行。
			>痛点5与方案：必要时加锁，MVCC多版本并发控制。某个时间点有数据库的快照，辅助MVCC的实现。
				>MVCC: InnoDB存储引擎在可重复读/读已提交隔离级别下的实现， 使得读操作基本不加锁。每行添加了额外两列：创建版本号 和 删除版本号。存储的是系统版本号，新增一个事务使得系统版本号加1。UPDATE操作实际上新增了一行，从而创建版本号为新的系统版本号。
		>方案的证明：论证，考察。应用架构的鲁棒性
			
	
2.举动-痛点2：Mysql存储引擎。InnoDB设计来处理大量的短期事务。InnoDB: 热备份、行锁、事务、聚簇索引。MyisAM崩溃后无法安全恢复--损坏多恢复慢，压力上升后的锁竞争问题。
	>解法/处理思想：	
		>对表的处理：.frm文件保存表的定义信息，在数据库目录下。
		>表的存储文件：Myisam 的一个表存储在.myd 和 .myi数据文件和索引文件中。存储行记录数受限于OS单个文件的最大尺寸；无事务但可以加表锁。
		>压缩表: 表转换为压缩表，只读，提高读的性能，索引也只是读；提高性能原因在于解压一行远快于IO
		>Myisam 使用场景：日志型应用。Select 和INSERT比较多的场景；但是崩溃会丢失数据也是问题，备份只能关闭服务器--InnoDB可以热备份。InnoDB唯一缺点：空间占用更高\开销更大。
			>写入数据库的安全性：并不会直接写入磁盘，而是写到内存；等操作系统自己定期刷出到磁盘上。
		>NDB集群存储引擎：配合NDB集群数据库使用。
		>全文索引：InnoDB + Sphinx
		>数据仓库：10TB以上的数据库数据，建立数据仓库，采用Infobright 存储引擎。偶尔用TokuDB
		>指标特征：InnoDB ,全部数据在内存,2.5G;  内存200G> 足够， cpu 2*6*2 每个cpu支持2个线程
			>并发量：在32并发线程数时达到最大的并发事务数：7000/s
		
3.举动-痛点3：基准测试。针对系统设计的一种压力测试。 一定负载-->系统-->性能表现
	>解法/处理思想： sysbench
		>目的：在压力下测试系统的容量，测试系统需要怎样的网络和硬件。
		>指标：
			>吞吐量TPS：每秒事务数
			>响应时间分布：统计所有的请求的响应时间的分布情况，类似t分布。
			>并发性: 负载强度，同时到mysql数据库的请求数/并发请求数。
			>可拓展性：提供2倍的资源(比如cpu或者内存，具体看瓶颈)，期待获得2倍的吞吐量---即线性扩展。资源的增加，吞吐量的增加。
		>设计基准测试：测试方法
			>系统预热：吞吐量趋于稳定时?
			>一般测试过程：创建数据仓库(每个700M可以)， 将数据导入到Mysql数据库，并行多线程执行不断创建的事务，统计每分钟内执行完的事务、响应时间的分布等上述指标信息。
				(也有文件系统和磁盘的基准测试: 如磁盘每秒执行多少次随机读：如14000次随机读)

举动-痛点4：使用mysql中的常见问题：语句执行慢想优化，服务器是否达到了最佳性能状态还是还有改善的空间， 以及系统出现的停顿、卡死等现象
	>解法/处理思想：性能剖析profing, 直接查看时间都花在哪里了的一个分析报告--测量报告。
		>性能度量：查询时间。因为影响cpu利用率的因素很多()	
					>执行时间和等待时间：一个任务的花费的时间的构成。
		>测量依赖：测量根据-数据
			>慢查询日志：秒级别或者微秒级别。分析工具：pt-query-digest
			>tcp抓包记录每次查询：tcpdump分析工具
			>
		>执行计划：
			>查看各项动作耗费：set profiling = 1; 然后执行一条select语句；然后 show profiles; 可以看出每条语句的执行时间。对每条语句，可以show profile for query 查询语句id 来查看mysql执行这条语句而做的先后所有的动作以及每个动作的执行时间。
						方法2：查看INFOMATION_SCHEMA.PROFILING表，从而可以对执行动作的耗时进行排序，以便找到最耗时的几个。
			>查看各个动作执行次数：show status....比如可以得到没有使用索引的读操作的执行次数：Handler_read_rnd_next的值。EXPLAIN一般不建议使用---但是可以查看到是否使用了索引。
			>查看等待的各种原因事件和等待时间总计：从events_waits_summary_global表里查询出来。比如innodb_log_file日志事件、写数据文件事件、缓存状态改变事件、....
			>数据库命令级别的查询：mysqladmin ext -i1 | awk.... 查看每秒的查询数、线程连接数、正在执行查询的线程数
				>查看线程是否有不正常的状态和特征：mysql -e 'show processlist\G'... 如果状态为freeing items的量比较多则有问题。Sending data没问题。
				>
		>耗时所在：
			>未使用索引：子查询创建的临时表没有索引--如果和其他表联合就会更加的耗时。
举动-痛点5：建立表的数据类型的选择：
	>解法/处理思想： 
		>常见规则：索引列最好是整数。连字符串都不好。如果是UUID，还建议转换为整数UNHEX()来保存在BINNARY(16)这样的16字节的整数中。比如IP地址，保存为整数：INET_ATON() 和 INET_NTOA()来转换。
				   不适合宽表，几千个字段，会导致行解码的时候消耗太多CPU。
			>范式：非常重视一张表内 其他字段 和主键的直接依赖关系，间接依赖关系则要提出来专门建立新的直接依赖关系的表。所谓第二范式，最重要的。
				>更新多的场景。
				>优点：省内存，方便更新。缺点：查询需要关联表，导致索引策略失效。查询效率log(n^k) 关联表越多效率越低。
			>反范式：有冗余，可能导致更新多处，从而代价更高。但为了性能需要有一定的冗余。
				>查询多的场景。
				>优点：多个字段同一个表中，使得 where, orderby 上如果用了联合索引，那么都可以使用到索引，性能大大提升。缺点：更新比较慢，有冗余，但更新问题可以使用触发器来实现。数据错误问题可以修复，但性能只能改变结构来提升。
					  性能的提升，索引、冗余列减少关联表、缓存表、汇总统计表。写慢了，但是高性能的数据库设计，这是常用的技巧。
			>避免：使用mysql遗弃的特性，如指定浮点数精度，整数的显示宽度。不使用bit, set, enum这些类型。alter table会锁表和重建表，性能开销大。
		>版本数据的保存：create table a like b; rename table a to b_new, b to b_old。来新产生一个表，旧表保存好那个时间节点之前的数据。
			>某个字段数据的自增：直接使用一条update就可以了：update a set a.column = a.column + 1;不用重新去阅读数据。并且是原子的。如果需要提高性能，可以采用冗余，多行保存同样的信息--最后求和，这样可以随机rand()选择一行来自增。
			>日期的插入：可以使用mysql自带的。比如datetime有数据格式，timestamp整数方便索引，current_date取年-月-天来保存。
			>不存在插入存在则更新用一条语句实现：利用on duplicate key 这个逻辑条件关联符连接insert语句和update语句：insert into A values(current_date, rand()*100, times) on duplicate key update set times = times + 1;插入多个值或许也可以---从而都用一条语句旧完成了。
			>更新表的高级操作：可以inner join 另一个表，using(key) 来实现关联，从而在set 分支的时候可以 set a.col1 = if(a.col2 = b.col2, val1, val2) 来实现一个更新上的如果那么操作。
					>例子：update a inner join b using (key_a_b) set a.col1 = if(a.col2 = b.col2, val1,val2) 想象数据表中的数据是规律存储的。
			>只修改表的某列的默认值：alter table a alter column b set default 5; 其中alter column , modify column , change column都是不一样的。
			
举动-痛点6：索引的创建规则：解释和反问。
	>解法/处理思想：
		>索引基本：在存储引擎层实现，而不是服务器层实现。
		>索引用到：最左原则。like 'L%'也可以(因为本质是比较操作)。order by 中也可以用到(条件是：字段顺序同联合索引顺序，且排序方向一致；连表时要求字段都是第一个表的)------这样可以利用索引进行排序---而不是额外的再次排序；或者第一列被指定为一个常数。
			>不能用到：函数参数中、表达式中、不等关系
				>如果是> <, between and 这些不等关系，那么这列可以使用索引，但是后面的列就不能再使用索引了。in后面的列则依然可以。
			>前缀索引：可以where,不能order by 和Group by。创建字符串字段的前缀索引add index column(length)
			>and: 相关列可以做联合索引 add key(col1, col2)----当然是把选择性更强的放在前面。or相关语句则可以改为union的方式---因为直接or两个单列索引都不会被用到。explain + 返回时间 可以看出来。
			>in: 是范围查询--从explain type列的值range来看---当个数多8个时候即便做了唯一索引也会导致all扫描，也看作是查询联合，所以不宜太多的值。当然In中的每个可以进行索引。
			>能创建主键、唯一索引尽量创建：不能只是普通索引。
		>覆盖索引：查询的字段也在索引里---联合索引里--即where上的字段和查询的字段和order排序字段构成了一个联合索引，那么通过查这个索引就直接获取了结果，而不用回表---用主键id再去查；同时也用索引完成了排序。
			>explain中的extra字段解释：值为Using where---说明where上使用了索引，Using filesort-----mysql额外进行了排序--使用了文件排序效率低--最好不要出现；Using index ----使用了覆盖索引--查询效率最高--查询字段和比较字段和排序字段构成的联合索引被使用了。
		>索引类型：除了B+树索引，可以在建表时指定索引类型：比如create table aaa(....  key using hash(columnname)) 就使用了hash索引。。memory引擎就支持hash索引-------键是列值的hashcode, 值是行id；。NDB引擎也是。使用场景最好就是列值是字符串且比较长，这时候hash处理后可以减少存储空间----毕竟也不会进行范围查找。
					常用hash函数：crc_32  结果是整数值。索引不能用sha1()和hash()这样产生的是字符串的hash函数。---毕竟不需要尽可能消除冲突，但要求整数为结果。可以将md5()生成的字符的右半部转换为整数，效果也不错。
					              fnv64也可以。
				  >触发器可以用来直接更新新增的列的其他列的值：在begin end 之间直接set new.column2 = crc32(new.column1);即可。而且存储过程和触发器中设置变量值都要set 关键字；都要用delimiter 来做起止分割。
		>超大型的表：索引开销也大。替换技术：分区技术、块级别元数据技术
			>增删改查之后大量的表文件碎片：optimize table 来整理碎片空间。
		>不建议操作：主键更新、非顺序增加行，使用uuid作为主键---会非顺序插入和索引占用更大空间。auto increment的缺点是高并发下的插入----会有竞争的问题。
		>orderby 和 limit同时出现时：当心先抛弃再排序，即先limit后再orderby的情形。
		>压缩索引：
		>冗余索引：
		>查询每个索引的使用频率：
		>where过滤时间：在服务器层。而在存储引擎层，只是返回数据。
		>连表：用索引字段
		>索引常用策略：联合索引 + 覆盖索引查询方式。实现查询和排序都利用到索引。select ... from tableA inner join (覆盖索引的查询)as B Using(key)
			>三大类可优化的场景：扫描了太多行，额外的文件排序，使用了临时表。回表查询、 随机IO.
		>找到损坏的表并修复：check table ; repair table ;
		
举动-痛点7：查询优化，语句本身中的痛点\冗余的动作。。设计库表、设计索引、设计查询语句-------高性能mysql设计三大方面。
	>解法/处理思想：
		>查询的子任务：数量和每个的运行时间
		>慢查询表现：查询的行和列太多---取出全部列和全部行，有很多是不必要的又被用户抛弃。扫描的行数/返回的行数 比值太大。
		>explain type: 访问类型---全表扫描all、索引扫描、范围扫描、唯一索引查询、常数引用ref。 值：const, eq_ref, ref, range, index, all
		>explain rows: 预估存储引擎的扫描行数，结果会返回给服务器层。
		>explain Extra: 对存储引擎返回的结果用什么方式过滤，Using where表示服务器层用where条件来筛选存储引擎返回的结果。如果使用了覆盖索引就可以返回结果，那么Using index而不用回表查询了---也在服务器层完成。最好的，就是直接存储引擎层就用索引来过滤结果。
		>mysql查询性能消耗大头所在：不是常规认为的建立和断开网络连接、解析查询。而往往是联表查询而建立临时表、未使用索引和覆盖索引
			>mysql服务器：每秒10w查询，内部每秒扫描上百万行数据。
			>删除建议：分多次删除。即delete from ....limit 1000; 这样多次执行。
		>join: 会建立临时表？group by , order by , union 都会建立临时表。
		>in：如果()参数里是子查询，那么会被优化为exists( ...)形式，所以建议直接用exists()来代替in的写法；或者用inner join来代替。因为这样就可以利用到索引传递---两个表的索引都被使用；但no exists需要用left/inner join 来代替：子查询要慢些。常量呢？
		>查询过程：四大阶段：从用户发起查询到mysql服务器，到服务器返回用户数据
			>查询缓存: 大小写敏感的hash查找实现的。
			>解析、预处理：语法规则验证,schema存在验证，权限验证；
			>优化器生成执行计划：各个执行计划的成本估计，
				>静态优化：
				>动态优化：调整关联顺序、外连接转内连接、where运算规则等价简化、一个联合查询分解为多个执行计划、逻辑优化-存在/不存在立即返回、IN的值的排序优化、
				 >联合查询和where的结合的执行计划：是一个两层while循环迭代取数据的过程，外层通过where查找出的每个结果，都在内层循环里当作条件去查找出 外联内联
			>执行计划中调用存储引擎API: 传递给存储引擎的是指令树，一颗左侧深度优先的树---因为join是层层嵌套执行的。explain extended 之后执行show warnings之后可以看出重构的查询。
				>handler api只有几十个：提供基础的功能。执行 执行计划中 某些操作才会调用这些存储引擎的接口。
			---结果返回：是增量式的，产生即缓存和封包返回。从而加快响应。
			---mysql不能并行执行。
		>用户查询连接线程的状态：show full processlist 	。Sleep正在等待客户端连接，Query执行查询或者把结果发送给客户端，Locked在执行计划的执行中调用存储引擎API遇到的等待表锁，Analize and statistics 生成执行计划中，copying to tmp table 复制数据到临时表中，
			>预估成本：last_query_cost 
			>关联查询的成本优化角度考虑：因为先扫描一张表、再试图走索引来嵌套循环地搜索下一个连表的数据；所以会选择扫描成本低的作为扫描表。
			>排序：文件排序，再内存中是快速排序；数据量大就分成多个块，对每块快速排序然后回写，最后对排好序的块两两合并----合并算法比较简单的。
				>排序算法：冒泡排序、快速排序---一次交换、双指针排序---有一次指针传递、二叉树排序、类似二叉树原理的一次遍历--每次遍历时取出数据放在新的“排序数组”中--二分查找找到放数据的位置、分段二分排序再合并。
					>快速排序：left, right, tmp三个指针，tmp存储基准值，left, right分别从首尾开始，tmp存right的值，从left开始，比基准大的left的值覆盖到right, 再从right开始，比基准小的放到left， 再从left开始，，，如此直到left==right，这个位置的值设置为tmp，两边开始递归进行排序。这种方式不需要新空间也能n*logn的复杂度，而遍历-二分查找插入法则需要一个同样长度的新数组---尽管也是n*logn的复杂度--且时固定的最大的。
				>单次传输排序：新版本采用，查询的列和排序列都先查出来，然后按照排序字段排序，最后返回数据。
				>两次传输排序：旧版本采用，只查排序列，排序好后再去查选择的数据列。
		>同时对一个表更新和查询：mysql不允许，但是可以通过 update tableA inner join (temp table) 的方式实现----即临时表的方式。
		>优化器提示参数：若干如SQL_BUFFER_RESULT...。。有的最好不使用：比如for update 和 lock in share mode。。。USE index, ignore index, force index可以使用---但是对新版本的mysql反而不好。
		>优化特定类型的查询： 寻找代价最低的更好方案。
			>count(): 行数 、列的有值结果数--非NULL。。count(*)其实优化了，就是结果集的行数。NULL值不算。所以 select count(if col1=val2 or null)，count(...) from table 就可以统计出一列的多个值的分别个数，或者多列的多个值的个数。另一个函数sum(if(col2 = val2, 2, 0))也可以用来统计值的个数
				>补集：减少扫描的行数。比如 a > 10的个数可以转化为 all - a <= 10
			>union ： 小表在前，只在第二个表的关联字段加索引，order by 和 group by 只能全部是一个表的字段。union all 显然更好更快，没有去重的检查。
			>子查询： 用关联查询代替。因为子查询创建的临时表没有索引
			>group by 和distinct: 字段上用索引，主键索引、唯一索引。增加order by null 来不再排序。
			>limit： 延迟关联，即limit先放在一个使用了覆盖索引的子查询语句里，再外层内联而取其他字段。
						试图用一个字段来转化为一个 区间查询。或者 区间查询 + limit 20 这样的通用有一个指示字段的查询----下一页的方式通过查询21条而返回客户端20条的方式来看是否还有下一页--那么就不用查询总量了。 
			>自定义变量：set @a=1 的目的可以帮助在select 方面使用来辅助计算。又可以辅助计算on duplicate key 的冲突总量----利用 + 0 *xxx 既运算赋值又不影响结果的方式。
				统计来辅助决策。
			>where上的通用：在函数比较之前，先用可以用到索引的比较条件来过滤，这样可以大大缩小筛选范围。索引条件辅助筛选！！！
			
举动-痛点8： 高级特性的利用


			
x.举动-痛点： SQL优化
	>解法/处理思想：
		>避免大事务产生过多的undo: 如导出数据到新的表：先create table new_table like old_table ,然后..., 所以需要手动开始事务、小任务做完、提交事务。不能默认一条语句来全部功能完成 而等待自动提交。
		>分区表：创建分区表时带上：partition by range columns(col1)， 各个分区独立索引。插入数据，数据就会根据分区列而存到不同的分区中，查询时优化器则会选择过滤哪些分区----只要直接使用分区列来进行过滤。
		>合并表：将被淘汰，略。
		>视图：不能创建触发器。查询视图的实现算法：合并算法---将查询语句和视图创建中的查询语句合并--然后去底层表查询数据返回。临时表算法----先执行视图查询语句查出数据放到临时表中，后将查询语句转为等价的查询临时表的语句；通过explain type字段可以看出采用的临时表delivered---临时表算法视图不能被更新。。
				>create algorithm=temptable view as select * from table1 一般有group by ,union  就不能更新视图。
				>用途：不影响查询结果而更改视图的表结构；给表列赋权。因为没有索引-----所以也可以用来当作连表的第一个表。
		>存储过程：能在应用程序中就不放到服务器端。
		>触发器：可能导致死锁和锁等待----从而导致原来的sql执行失败。一个事务里，所以一起成功或者失败。
		>事件：即定时任务。create event abc on schedule every 1 week do begin xxx end;
		>取锁和释放锁：之前可以增加：declare continue handler for sqlexception begin end;
			>取锁：get_lock(),,,,, 释放锁release_lock()
		>游标：
		>绑定变量：
		
		
参考资料：
1.mysql手册