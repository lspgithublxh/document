---------读书战略：自顶向下，从应用层到底层细节。先熟悉的常用的，后底层的不常用的。精读好书---《深入理解系列》
--------es的处理思想都对应有 相应的“某种举动 及其导致 的问题”
>需求背景-痛点陈述：现实开发中遇到了什么痛点导致XXX的开发？  
>那么痛点的原因、产生的条件：分析是什么环境、什么动作 什么效果什么目的 等精准形容词的事实描述 导致了痛点的必然发生，难以避免？。条件-痛点。原因-结果。
>则可以消除痛点的最简单的精准事实陈述是什么：修改“条件-痛点”陈述的哪一部分就可以导致没有痛点产生。 要做的根本事情是什么：
>那么新陈述表明的解决动作是什么：
>新情况的新痛点是什么：新举动、新环境会产生的新痛点描述出来， 继续上述4条操作。
>学习要有战略和格局：过于零散、孤立、末支、叶子的知识点就没必要化太多时间，懂得放弃。聚焦在根节点、枢纽节点、产生分支的节点、主干知识点、枢纽知识点、关联到很多知识点的知识点上。
 >对于主干知识点：要有全新的认识视角和进行精细的描述，大量的提问和好奇和进行必要的实验以获取支撑观点/导出观点的数据。
 >规范是工程最独特的特征.
 >慢慢读：
>一种新技术的学习：
 >它面对的情况和问题、它的世界观、它的方案、它的方案验证/论证/能处理的解决的所有情况及能成功处理的理由/功能边界
  >所有的软件：都可以看作是向上封装一层接口，根据自己的世界观封装底层而向上/对外提供统一的(统一的更简单的更直观的更业务的更少底层信息的)接口，底层包含一系列的第三方的插件/构件/组件；内部则去做兼容和调用(对底层)(对上层则做逻辑分解和底层实现)。
>知识混乱就是因为没有组织：
	>组织就是关键字树：几个单词就是每层上的每个节点的内容；
	>组织也可以看作逻辑树：有逻辑关系，逻辑顺序，逻辑联系的关键字的层层集合。层层囊括更精细的范围，层层划分范围。
>推进理解的属性发展拓展、问题延展：重要方式；
>什么是架构：架构也是从抽象到具体的考虑和描述；树形延展开来，可以写满非常大的黑板和巨大的脑图！！sharding-jdbc,dubbo,spring都可以这样方式来展现它的架构！！它的抽象到具体的考虑---本身才是架构！！！而不是什么模块、模式之类！！
>抽象设计：则某一层就不管上一层的含义和下一层的含义，即更抽象的含义或者更具体的含义；而是实现本层的含义；完成本层的含义指定的功能；。如网络协议的架构设计；	
>面向设计来理解，面向架构设计来理解，面向架构问题一层一层来理解它：面向设计来理解，所以按照面向对象设计的方式，看其中的对象、行为属性、流程环节逻辑。	
>找不到知识/描述 所对应的问题 ， 那么看书将没有条理纲领，变得零散琐碎没有组织。	
>不是按概念方式组织，而是按架构、问题方式来组织 笔记，书本内容。架构顺序，问题层次顺序。	
>架构不是设计出来的，也不是演进出来的(甚至不是迭代出来的--尽可能避免迭代)：而是问出来的。	
>每个方法方案都从属于一颗树，所以找到一个方法巧妙方法仅仅是第一步--找到从属的层次树 有更大的价值；(无论是谁想到的方法/概念，都要这样更进一步)
>解决问题的办法就是提出问题：类似递归和动态规划；。。权衡就是线性规划；	
--在网络、搜索引擎、推荐系统 三方面的专家；作为系统方面的独特优势/拔高优势；(网络-查询-推荐)
	
----有且只有响应，通信端才知道连接是否成功；。浏览器自动扩展。
----维持连接，并发连接，都是软件的实现，物理上看都是一条出口；从响应就是维护连接的角度看，不存在需要维护什么连接，维护就是维护连接数据而已；只要发送响应，连接就活了；在网络端口出口，可以连续发送不同目的地的响应报文，这就是并行；所以完全可以用队列来接收请求数据包；而用队列缓存发送响应数据包；多核使用起来，来并行大批量的发送和接收；不存在要维护和持续占用“端口”网络出口这种概念---完全没必要，用完即走 就可；	
	>或者不存在连接这个概念：所有的事情就是接收数据包和发送数据包(接送/发送缓冲区)。(连接 是 软件臆造出来的概念，不要和物理对应；和物理对应就会束缚思想，就会很多事情理解不了不知道原因)
	>连接的状态转移图；
	>应用的固定端口：实际上是建立新TCP连接的请求的处理的端口，请求到达这个端口--后面建立一个独立的TCP连接---来负责和客户端通信-交互数据；
	
>举动-痛点：实现、好的实现；使用简便、扩展简便、通用、高效快速的实现；讲究工程方法；
	>解法/解决方案：http 报文/客户端服务端通信过程：信息块的搬迁承载转移。信息块存在web服务器，web客户端发送http请求，web服务端响应请求的数据；
		>因此：每个请求本质就是包含一个资源路径；URI。资源可以是：静态资源，动态资源--数据/动态数据/动态生成的数据/动态计算出来的数据/动态查询出的数据/动态捕获监控采集的数据；跟踪记录的数据；
		>每个HTTP对象数据：需要添加一个MIME类型：表示这个资源的具体类型；对象类型/子类型  如 ：image/jpeg    text/html  text/plain  电影video/quicktime   ppt类型application/vnd.ms-powerpoint   作为 Content-type 的值
		>统一资源定位符URL：协议+服务器+本地资源。统一资源标识符URI：就是URL...。URN--试验阶段--未使用；
		>HTTP事务：一个请求+一个响应；报文：一行一行的简单字符串组成；主体+起始行都是纯文本/不是二进制；而主体可以是二进制(图片视频音频软件程序)；
			>HTTP请求报文：起始行+首部字段+主体
				>起始行：结构化的。HTTP方法 资源路径 HTTP/1.0
				>首部字段：结构化的。以空行结束；空行后才是正文；
				>主体：发送给服务端的数据；
				>HTTP方法：5种；对资源的可能操作：GET/PUT/DELETE/POST/HEAD
			>HTTP响应报文：起始行+首部字段+主体
				>起始行：结构化的。HTTP/1.2 200 OK 
				>主体：发送给客户端的数据
				>状态码：请求结果的状态描述：成功/重定向/没找到
			---使用nc netcat 方便操纵UDP+TCP的流量。	
			---客户端服务端之外的web组件：
				>代理---中间转发；web安全、应用集成、性能优化的组成模块；。。代理：代表用户访问服务器；过滤、病毒检测等如；
				>缓存--CDN页面副本；经过代理的常见文档保存起来--请求直接从缓存里取出返回；
				>网关--连接其他应用程序；将http流量转换为其他的协议；如HTTP/FTP网关；
				>隧道--盲转发的特殊代理；在非HTTP网络上转发数据；通过HTTP连接承载加密的安全套接字层SSL流量，让SSL流量穿过只允许web流量通过的防火墙；--HTTP外壳；
				>Agent代理--发起自动HTTP请求的半智能web客户端；非浏览器---而是编写的程序；比如网络蜘蛛；
		>URL与资源：URL标准格式：9段；用户名-密码-参数-片段 不常用；		
			>如ftp: ftp://username:password@host:port/path/gun;type=d
			>http: http://host:port/path;sale=false/path2;graphics=true 多个路径段； 后面加查询 ?query1=abc&query2=sxx;
			>指定文档中某个小节/图片：http://host:port/path#drills   浏览器则展示片段部分到当前窗口；片段部分不会发送到服务器，只是会被浏览器使用---如当作滚动距离；
			>基础URL和相对URL：基础URL：<BASE> 或者当前页的URL:   一个个部分继承而来。不安全字符：转义字符 来表示；
		>HTTP报文：
			>起始行：\n\r换行CRLF； 三部分
				>请求报文：HTTP方法 路径URL  HTTP/版本 
					>方法：PUT--是让直接存储主体(建立主体-URL的映射)，POST--是让处理主体；TRACE--追踪报文-可能经过代理服务器(ping-pong返回头部里有Via字段)；OPTIONS--决定可以在服务器上执行哪些方法？(返回额外信息Allow字段里)。。扩展方法效果更好；
				>响应报文：HTTP/版本 状态码 信息原因 
					>状态码：100--信息提示  200--成功 300--重定向(主体包含重定向的新链接)   400--客户端错误  500--服务端错误。。
			>头部：首部 。每个值可以换行--需要加\t制表符 或者空格
				>Content-type: 说明主体的MIME类型 
				>Content-Length: 说明主体的字节数
				--通用首部：
				--请求首部：如Accept: */*  HOST---接收主机名和端口号  Referer--包含当前请求URI的文档的URL	Accept--告诉服务器接收的内容 媒体类型/字符集/编码/语言   ；IF-Modified-Since 要求服务器响应之前进行判断；
				--响应首部：客户端在与哪种类型的服务器交互；如Server:。。安全响应首部--如 Set-Cookie
				--实体首部：应用实体的描述：如 Content-type:text/html;charset=iso-latin-1
					>内容首部：Content-xxx
					>实体缓存首部：如何何时缓存：Expires/Last-Modified
			>主体： 
		>连接管理：	
			>HTTP事务的时延：
				>DNS解析系统将URI的主机名转换为IP地址花费时间较长；几十秒
				>TCP连接建立时延：1s
					>TCP连接建立时延：
					>TCP慢启动拥塞控制；重用连接来保持高速；
					>数据聚集的Nagle算法；避免产生大量少量数据的分组；累积数据后发送；即先发送全尺寸的，后非全尺寸的；等待小分组填充的过程就是时延；而ack本身就是小分组还会延迟发送；延迟更大；所以写入大数据块，而禁用Nagle算法；TCP_NODELAY
					>用于捎带确认的TCP延迟确认算法: 段的ack先缓存，定时内寻找附加在某个数据上返回；这种节省了包的都带来时延；
					>TIME_WAIT时延和端口耗尽；发送FIN端在收到对方ACK和FIN后，发送ACK后 就进入2MSL的TIME_WAIT等待，避免自己发送的这个ACK对方没收到而重发FIN---如果此时在同样端口上的新连接又建立起来了则会导致误以为关闭--而重置；所以要等待2MSL,2min；  影响性能---降低到500次/s
				>RTT请求响应网络时延：
			>HTTP连接的处理：	
				>Connection 头部：值代表的其他头部key,下一跳必须删除；close--则本次事务后关闭持久连接；Connection本身也要清除
				>并行连接：多个TCP连接受带宽影响；且连接消耗内存资源；尤其服务器端：不能每个用户都处理100个并行连接。所以，并行浏览器做限制---最多4个；---池化；
				>持久连接：重用TCP连接。但是每个请求还是串行执行的；只消除了连接建立和关闭的时延；
					>当页面请求完毕后：HTTP/1.1让连接保持打开状态，以便未来的点击之类的重用现存的连接；---重用的连接也避免新连接的慢启动阶段和拥塞适应阶段而更快；
					>HTTP/1.0+ keep alive连接：单连接内 串行请求-响应；客户端设置：Connection:Keep-alive;请求将连接保持在活跃状态； 服务器支持--则响应中也包含Connection:Keep-Alive  ；取值：max---最多的事务；timeout---保持时间。。客户端没有发送：则服务端会在请求之后关闭连接；
						>代理服务器：一个连接不能重用其他请求；不能主动关闭和服务器的连接；
							>不能转发的头部：Connection开头的；Proxy-Authenticate,proxy-Connection ;Transfer-Encoding 
					>HTTP/1.1 persistent 连接：默认激活；当响应报文里有Connection: close 首部 才会关闭连接，否则http/1.1连接仍然处于连接状态；---当然可以主动关闭连接；。。持久连接---一个客户端对一个服务端最多只能有2个；响应报文里一般有Content-type 
				>管道化连接：共享TCP连接+并行TCP请求。
					>HTTP/1/1 允许在持久连接上可选的使用请求管道；在响应到达前，可以将多条请求放入队列； 回送HTTP响应的顺序需要和请求的一样；---因为HTTP没有序列号标签；。但有风险；连接关闭--大量请求未处理的问题；---不知道成功与否---比如POST--所以GET可以管道，而POST一般不可以；幂等方法：GET/PUT/DELETE/HEAD/OPTIONS/TRACE
				>复用的连接：交替传送请求和响应报文。NIO类似。
				---关闭问题：
					>主动关闭输出信道 是安全的：但关闭输入信道则是不安全的；比如假设主动关闭了，而对方已经成功发送给自己10条请求，但是数据它还没有读取--它的缓冲区中，然后发送第11条，结果我这边返回RST重置，结果对方就会将缓冲区11条都清空，
		>web服务器：
			>接受客户端连接：主机名查找--服务端一般禁止；
			>解析HTTP请求：起始行：内部空格相隔；CRLF结尾；首部则CRLF+空行结尾；开始解析Content-length表明长度的主体数据；
			>调用内部资源：
			>构造响应报文：
			>发送给相应客户端：
			---单线程web服务器：少见；
			---多进程多线程web服务器：最大线程数限制；池化+排队；
			---复用I/O的服务器；多条连接，哪条连接上有状态变化---有事件：对那条连接进行少量的处理；且把数据提出来即返回该连接；而数据交给专门的线程来处理；
			--复用的多线程web服务器：多线程+复用I/O; 利用多核--每个核--监听部分打开的连接
			>文档根目录: httpd.conf 中配置 DocumentRoot /xxx/xxx  就是资源的前缀：前缀+URI 就是实际位置；
			>虚拟托管web站点：httpd.conf 中配置 <VirtualHost www.xxx.com> 内部配置 DocumentRoot 等。
			>查询目录返回内容：一般为此目录下的index.html之类：apache中配置目录URI时搜索的文件配置：DirectoryIndex ...。。。禁止生成目录索引文件：Options -Indexes 
			>动态内容支持：早期：配置 ScriptAlias /cgi-bin/ /xxx/find/path URI cgi-bin开头，则到后面的路径上寻找.cgi对应的脚本来执行得到内容；AddHandler cgi-script .cgi 
			>重定向：资源已经删除/服务器负载大/资源转移。。返回3xx状态码  + Location 重定向的URL。。
		>代理服务器：	部署、使用、记录、访问控制 
			>既是服务端也是客户端：
			>公共代理：多用户共享；高速缓存代理服务器，效用比更高；。网关：协议转换器；代理：同协议的转发；如web/e-mail网关；通过http读取email邮件；
			>功能：改善安全性、过滤、访问控制、提高性能、节省费用；。代理可以监视流量并对其进行修改--增值web服务--防火墙；
				>web缓存：维护常用的文档的本地副本；
				>反向代理：内容路由功能配合使用；负载均衡；导向特定的web服务器；
				>转码器：修改内容的主体格式；图片压缩、文件压缩、语言翻译；
				>匿名者：删除http报头中的身份特性：ip地址/from/referer/cookie/sessionid
			>位置：
				>出口代理：(基本不会主动被外部访问)比如一个公司的本地网络的出口点，来过滤；
				>访问代理：入口代理(基本不会主动对外请求数据)，ISP访问点上，缓存代理，提高用户下载速率；
				>反向代理：网络边缘，web服务器的代理；正向代理--是将请求转发出去--到Internet中去；反向代理--是将请求接收进来--转发到内网中去--某台服务器上；。。代理客户端--正向代理；代理服务器--反向代理；
				>网络交换代理：Internet中，对等交换点上，通过缓存来减轻拥塞；
				----代理层次结构：出口代理-->ISP访问代理-->网络交换代理--->反向代理
				---web请求导向代理：客户端实现：直接请求代理；服务端实现：重定向到代理； 中间流量拦截：路由到代理器 或者 充当服务端的代替物；
					>客户端代理配置：浏览器代理配置；WPAD--web代理自动发现协议--自动检测可以从哪个配置服务器下载一个自动配置文件；
					>客户端代理配置：PAC文件。.pac, MIME:application/x-ns-proxy-autoconfig  逻辑里根据URI返回代理域名端口
					>请求报文特征：向代理请求(客户端显示代理；但如反向代理则不必)，必须完整的URI：GET http://www.marya-antiques.com/index.html HTTP/1.0   \r\n User-Agent:SuperBrowser v1.3 因为代理服务器要转发到真正的web处理服务器，需要知道方案和名称额端口；
					----有且只有响应，通信端才知道连接是否成功；。浏览器自动扩展。
				---via 首部：值是一个 中间节点信息 列表；即中间节点自己加上去的；格式为: 协议 域名  如：1.1 www.xxx.com;  所以via字段可以用来诊断循环报文，记录转发过程，标识发送者的协议能力		
				---server 首部： 原始服务器的；
				>Trace 请求：TRACE /index.html HTTP/1.1 \r\n Host: www.xxx.com \r\n Accept：text/html   响应：Content-type: message/http \r\n Via: 经过的中间代理链 \r\n 。。。主体：完整的请求报头+Via+X-Magic-CDN-Thingy + Cookie+Client-ip
				---Max-Forwards: 最大转发次数；
			>代理认证：用户提交了正确的访问权限证书，才允许对内容请求；	
				>返回需要访问证书的响应：407 Proxy Authentication Requested 状态码；描述证书：Proxy-Authentication ： Basic realm="Secure Stuff" .
				>带上证书的访问： Get ... ... \r\n Proxy-Authentication: Basic YnJxesab...
				---OPtions 方法： 确定服务器的能力；返回报文 Allow 首部： GET,PUT,POST,HEAD,TRACE,OPTIONS。。。Options * HTTP/1.1  整个服务器的能力
		>缓存： 降低距离时延、降低对原始服务器的要求、缓解网络瓶颈问题、减少冗余的数据传输(相同的请求--尽管不同客户端)；			
			>缓存问题：新鲜度和准确度；
			>命中和未命中：新鲜度检测：---可以是代理主动进行的，也可以是用户触发的；新鲜度信息：Cache-Control ,Age, Expires ;但不调整Date
				>方法1：缓存中获取了，再去服务器验证新鲜度；再验证方法：HTTP首部：IF-Modified-Since 首部：如果服务端发现没有改变--则返回304 Not Modified ; 如果改变了---则直接返回主体内容 200 ok; 对象被删除---则返回 404 Not Found
				>方法2：代理定期去服务器请求将变更的数据加载到缓存；//比如每秒进行一次；
				>方法3：用户请求代理，缓存没有而去服务器请求而再缓存；
				---客户端判断数据是否来自缓存：Age/Date首部。即时间维度来确定；
			>缓存的拓扑结构：私有缓存---如浏览器内建。公共缓存：多个用户共享，减少网络流量		
				>多级缓存：后面的缓存 则空间更大、功能更强；越近的缓存则空间越小但速度更快；
				>网状缓存：存在缓存路由，内容路由器；。。缓存协议，兄弟缓存；HTCP,ICP
			>缓存的处理步骤：	
				>新鲜度判断：服务器会返回给代理：Cache-Control: max-age=过期日期 ； Expires: 绝对时间 。。过期了则向服务器再验证，有变动则要相应变动--变动了获取副本；没有变动则更新日期；
					>If-None-Match: 实体标签；  如果实体标签 被修改了，发送给服务器后，如果实体标签匹配则返回304， 不匹配则返回新文档；并返回新的标签；。。缓存多久：Cache-Control: 的值:no store>no-cache>must-revalidate>max-age;
				---服务器配置模块: apache：mod_headers  /mod_expires /mod_cern_meta	
		>集成点：网关、隧道和中继		
			>网关：扩展的非HTTP协议到达的新的资源的访问入口，而网关本身则对外提供HTTP接口；。不同协议的网关/安全网关/应用程序服务器API网关	
				>协议网关：如FTP/HTTP网关： 客户端发送 GET ftp://ftp.irs.gov/pub/oo-index.txt HTTP/1.0    这样浏览器会发送给协议网关而不是原始服务器；协议网关即：gw1.joes-hardware.com 的地址；而它打开ftp连接 转发给ftp.irs.gov的真正ftp服务器；
				>资源网关：网关和目标服务器在一个服务器上；根据请求 找到(实现注册) 应用程序，调用执行，将结果封装到http报文里返回；
			>隧道：用HTTP发送非HTTP数据；来穿越只允许web流量通过的防火墙；	
				>CONNECT 方法：客户端用这个方法 来请求 隧道网关；而隧道网关直接建立TCP连接 到 目标服务器；。如：CONNECT home.netscape.com:443 HTTP/1.0  而相应响应成功为：HTTP/1.0 200 Connection Established 没有主体；。。这样网关先建立到服务器的连接，和到客户端的HTTP连接，然后客户端发送SSL加密的流量，而网关收到数据包后直接转发给服务器；(不用解析头之类)
					>客户端连接到网关：可以加入认证：并指定隧道端口；CONNECT xxx.xxx.xxx:443 HTTP/1.1 \r\n Proxy-Authentication: Basic abcdefg...
			>中继：没有完全遵循HTTP规范的简单HTTP代理；直接转发。而对于 Connection: keep-alive这样的单跳 首部，也不处理，直接转发；所以可能会和服务器建立连接而不释放(服务器也不释放)--且会拒绝和客户端的同一个连接的第二个请求；导致阻塞；		
		>Web机器人：	
			>爬虫：数据结构 来判断爬取过的URL：可以利用bitmap/trie(先hash后trie)(压缩空间+树形搜索)，1GB=8*10^9bit=80亿 标记位；
				>文档别名：大小写，#页面位置定位，域名和ip，带端口，默认页面；统一转换为规范URL
				>环路检测2：对于文件路径，出现超链到上层节点，则会出现不同路径的同一个文件。。3：假页面的生成和处理；
				--为什么要有Host: 指定，因为 HTTP发送到服务器时，域名已经不见了，经过DNS只有了ip, 到达的数据包 就只有 Host: 首部 才知道 这个请求数据包 请求的哪个域名的资源；；毕竟同一个ip服务器上，可能提供多个站点/域名的资源服务；
				--在HTML页面中的首部：在<meta> 标签里，<meta http-equiv="key", content="val"> 这里的key-val就是一个首部；如 ； robots：noindex;  DESCRIPTION:文本摘要
				--robots.txt 机器人自愿遵守的规则文件；
			>搜索引擎：单词-->页面列表(相关性排名) 倒排索引表；	
		>HTTP NG： 传输-调用-应用 三层；组件模块化	
			>报文传输层：WebMUX 协议：报文分段，复用TCP连接；
				>WebMUX； 复用的TCP连接上并行的传输报文；
			>远程调用：远程方法调用的支持。二进制连接协议---通过有状态的连接--请求报文：操作、对象、可选数据值
			>web应用：允许多个应用共存于本层；
		>客户端识别和cookie机制：
			----对同一个端口的应用：可以打开多个TCP连接；实际上对一个端口的TCP连接建立请求，都会新建一个TCP连接----之后就是这个TCP连接和客户端进行通信---而不是再次请求原来那个端口---如80端口---仅仅是用来建立新的TCP连接的---这个TCP连接有独立的新的服务器端口(如33234)，而TCP响应报文就会带上这个新生成的目的端口--从而客户端下次就是将数据发送到这个端口上---对应的TCP数据缓冲区中；
			>用户识别机制：
				>HTTP首部包含：
					>From: 用户的email地址
					>user-agent: 用户的浏览器软件 
					>referer: 来源连接 。用户浏览行为的记录；
					>Authentication: 用户名和密码
					>Client-IP: 客户端ip地址 
					>X-Forwarded-For: 客户端ip地址  
					>Cookie: 服务器产生的ID标签
						>首次认证成功：服务器返回：Set-Cookie: key=value;key2=value; 客户端设置保存后；下次请求：带上：Cookie:id=xxx, domain="xx.com" path="" 路径匹配；。往往在重定向之后使用：302 Found \r\n Location: 新URL
				>客户端IP地址：
				>用户登陆：
				>胖URL：在URL中嵌入识别信息；
				>cookie: 功能强大的身份识别技术；
		>基本认证机制：
			>质询/响应认证框架：基本认证和摘要认证：
				>质询：客户端发送 首部：WWW-Authenticate:  需要认证则服务器返回401 Unauthorized响应, 首部 WWW-Authenticate: Basic realm=""  这个realm指令的值指定了一个域，是一个描述性的字符名；来帮助用户了解应该使用哪个用户名和密码(这个域要求的通行的用户名和密码)；
				>授权：客户端重新发出请求，带上认证算法、用户名密码：在首部：Authentication: 经过扰码的Base-64表示形式--base64(用户名:密码) 。服务器返回里头部：Authentication-info: 
				--代理服务器的质询和认证：首部不一样：Proxy-Authenticate , Proxy-Authentication, Proxy-Authentication-info  ；状态码 返回 407 也不一样；
				--缺点：无法避免重放攻击；没有提供针对代理和作为中间人的中间节点的防护；。。SSL+基本认证可以；
					>避免重放：加密前加入服务器返回的nonce；避免被解码：hash散列化(128位MD5摘要)/指纹。。处理的是密码；用户名保持；。。。缺点：用户名被篡改？
		>摘要认证：	Authentication: 里发送 客户端选择的算法、摘要、支撑数据；	
			>首次随机数：在WWW-Authenticate里，后续随机数，在Authentication-info: nextnonce=""里。下一个随机数，从而一个事务结束后不用重新质询了；
			>首次 WWW-Authenticate： 服务端返回：值：Digest realm="" qop="" nonce=""
			>首次 Authentication: 客户端发送：Digest username="" realm="" nonce="" uri="" qop="" nc=xxx cnonce="" response=""
			--摘要算法：H(data) = MD5(data) ; KD(secret,data)=H(concatenate(secret:data))
				>A1的计算：即安全数据部分的计算：用户名+密码+保护域+随机数 等 A1=用户名:realm:password,      MD5-sess中：A1=Md5(user:realm:password):nonce:cnonce , 其中cnonce就是客户端随机数
				>A2的计算：auth=request-method:uri-directive-value   qop指定不同时不同；。。。auth-int下：MD5(MD5(A1):nonce:nc:cnonce:qop:MD5(A2))
			--随机数算法：BASE64(timestamp H(timestamp : ETag:privatekey))	
			>对称认证：提供了qop指令则要求；
			--密码过期策略+复杂的密码；
		>安全HTTP: HTTPS
			>浏览器自动获取 所连接服务器的数字证书(是SSL握手的一部分)：颁发者、站点名称(域名/子域名)、证书有效期，公司公开密钥，证书签名算法，CA证书签名；(签名算法的公开密钥则在客户端的CA证书上有)
			>SSL握手：完整握手、简短握手、双向握手
				>交换的信息：客户端发送：随机数+会话ID+密码套件列表；服务端返回：随机数+会话ID+密码套件；再返回证书；再返回：密钥交换算法要求的N\a信息；  接着，客户端返回：密钥交换算法要求的N\b信息；。1-3-1-1 这样的信息交互模式；
			>有代理：需要建立一条HTTPS SSL隧道；还是HTTP CONNECT 请求方法到代理，代理到web服务器；	
		>实体和编码：	换行0x0A
			>实体首部：Content-Type, Content-Length, Content-Language , Content-Encoding , Content-Range(部分实体)， Content-MD5(内容校验和)，Last-Modified(服务器上的最后修改时间)、Cache-Control(该如何缓存该文档)，Expires(失效日期),Allow(允许的请求方法),ETag(实例的唯一验证码)
			>分块编码：传输编码。
			>Content-Type: 编码前/压缩前的类型；charset=iso-8859-4 说明的是把实体中的比特转换为文本文件中的字符的方法；boundary参数说明了分割主体中不同部分所用的字符串；
				>对于 Content-Type:multipart/form-data; boundary=AaB03x  这种， 其实体部分是分段的，每段以 --AaB03x 包围，内部是：Content-Disposition:form-data;name="xxx"\r\n内容 这样的嵌套模式的内容。响应也是这样分段；
			>内容编码：Content-Encoding: gzip , 接收的客户端从而用gzip解码器对实体进行解压缩；，此时Content-Length必然代表的是编码后的长度；Content-Type: image/gif 是原始内容的类型	
				>gzip之外的编码：compress--unix文件压缩程序压缩的；deflate--zlib的格式压缩的；identity--没有对实体进行编码；
				>客户端告诉服务器它能理解的编码：Accept-Encoding: compress,gzip
			>传输编码：不止对实体，而且对整个报文；Transfer-Encoding:  chunked    	请求：TE：trailers, chunked 可以接收的传输编码；。只有一种实现：分块编码；
				>无需事先知道主体长度：即允许实时生成--一边传输一边生成内容；因为每块由：长度值+CRLF+内容构成；结尾块：0+CRLF ,  最后可能有 Content-MD5:xxx ， 只要首部里有 Trailer: Content-MD5。。。Trailer被称为 拖挂 首部；
				---使用内容编码 压缩，传输编码来分块发送
				---有条件的请求：IF-xxx  开头的首部在请求端；。。匹配了服务器才返回文档；
				---中断和继续传输：Range: bytes=20224 Content-Range: bytes=20224...  Accept-range: bytes ..。甚至可以从不同的对等实体同时下载多媒体文件的不同部分；
				---差编码：A-IM:  ....差异生成器。
		>国际化：		
			>字母表：Content-Type: charset=   ,  
				>字符集：字符的某种二进制码；字符到二进制码的一种映射函数；  。。告诉客户端 用 什么字符集 来把 内容中的二进制码转为 字符；。。。
				---映射过程：二进制码-->数字-->字符-->图案
				--字符集在文档中可以设置首部：<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=iso-8859-1">
			>语言：Content-Language: 
			--客户端告知可以接收的：Accept-Language: en;q=0.5,fr;q=0    Accept-Charset:
		>内容协商和转码：	服务器返回Vary首部：告知代理需要使用哪些请求首部进行内容协商；即变化条件：Vary: User-Agent,Cookie 
			>转码：函数降级类似；。。入代理缓存根据User-Agent 而对服务器返回的内容做适配 到 客户端的转码；
		>web主机托管：
			>虚拟web主机托管：多ip 方案 和 Host方案；	Host:是目的web服务器的域名--而不是代理服务器；---缺少Host则返回400
			>服务器集群：
			>分布式代理缓存：客户端经过交换机直达代理缓存，返回数据。代理缓存会访问原始服务器；
		>发布系统：web内容发布技术：FrontPage----rpc请求和响应在主体里,DAV---扩展首部:LOCK/COPY/MOVE----它们的主体是xml
			>PROPFIND 方法：单次调用获取各个独立实体的所有属性；
			>PROPPATCH 方法： 设置或删除 多个属性 提供原子化机制；。。。死锁检测和处理：占有的对象和等待的对象---加入当前锁图就更新了锁图；占有而不永久等待，不占有；
		>重定向和负载均衡：
			>HTTP重定向：就是web重定向。302+Location 
			>DNS重定向：不同客户端访问不同附近的DNS服务器，返回不同的目的Ip地址--如可以是缓存服务器的地址；DNS服务器可以配置域名的ip list ,并使用某种策略调度ip--比如轮询;  nslookup www.xxx.com  返回iplist 一般取第一个ip-----但是单个客户端上的应用就不负载均衡了；最近的、均衡的、屏蔽故障的；
			>任播路由：几台服务器使用相同的ip地址---等路由器转发分组过来；。服务器通过路由器协议和路由器通信；。。
			>策略路由：
			>IP MAC 转发：交换机或者路由器处理分组：如目的MAC赋予分组；。一般交换机只是根据ip而决定从哪个端口发送出去，发出去之前将MAC替换为目的端口的MAC;。。而有的交换机还能根据ip+port而选择从哪个端口发送出去---也在发送之前替换MAC-------一般是转发给代理/缓存；
			>IP 地址转发：第四层交换机 根据端口而改分组的ip地址为镜像服务器或者代理的Ip。
			---将报文重定向到代理服务器：
				>WCCP协议：路由器将web流量重定向到 缓存服务器；
				>ICP协议：	PAC文件，通过 Content-Type:application/x-ns-proxy-autoconfig 返回，主体是一个函数；函数里包含代理地址；运行这个函数得到代理服务器的地址
					>获取PAC文件的尝试：先DHCP查询,后SLP(服务定位协议)查询(QNAME=xxx.xxxx.xx), > DNS知名主机名 >DNS SRV记录 >DNS TXT记录中提供的服务URL...。。得到CURL,在上述请求，来得到代理地址。
				>HTCP 协议：对象发现协议；查兄弟缓存是否有目标文档；
				>CARP 协议： 缓存阵列路由协议
				>WPAD 协议： web代理自动发现协议
		>日志记录和使用情况跟踪：			
			>缓存和日志：走缓存而没有走目标机器：
			>Meter首部的各种指令：do-report , will-report-and-limit 