---------读书战略：自顶向下，从应用层到底层细节。先熟悉的常用的，后底层的不常用的。精读好书---《深入理解系列》
--------es的处理思想都对应有 相应的“某种举动 及其导致 的问题”
>需求背景-痛点陈述：现实开发中遇到了什么痛点导致XXX的开发？  
>那么痛点的原因、产生的条件：分析是什么环境、什么动作 什么效果什么目的 等精准形容词的事实描述 导致了痛点的必然发生，难以避免？。条件-痛点。原因-结果。
>则可以消除痛点的最简单的精准事实陈述是什么：修改“条件-痛点”陈述的哪一部分就可以导致没有痛点产生。 要做的根本事情是什么：
>那么新陈述表明的解决动作是什么：
>新情况的新痛点是什么：新举动、新环境会产生的新痛点描述出来， 继续上述4条操作。
>学习要有战略和格局：过于零散、孤立、末支、叶子的知识点就没必要化太多时间，懂得放弃。聚焦在根节点、枢纽节点、产生分支的节点、主干知识点、枢纽知识点、关联到很多知识点的知识点上。
 >对于主干知识点：要有全新的认识视角和进行精细的描述，大量的提问和好奇和进行必要的实验以获取支撑观点/导出观点的数据。
 >规范是工程最独特的特征.
 >慢慢读：
>一种新技术的学习：
 >它面对的情况和问题、它的世界观、它的方案、它的方案验证/论证/能处理的解决的所有情况及能成功处理的理由/功能边界
  >所有的软件：都可以看作是向上封装一层接口，根据自己的世界观封装底层而向上/对外提供统一的(统一的更简单的更直观的更业务的更少底层信息的)接口，底层包含一系列的第三方的插件/构件/组件；内部则去做兼容和调用(对底层)(对上层则做逻辑分解和底层实现)。
>知识混乱就是因为没有组织：
	>组织就是关键字树：几个单词就是每层上的每个节点的内容；
	>组织也可以看作逻辑树：有逻辑关系，逻辑顺序，逻辑联系的关键字的层层集合。层层囊括更精细的范围，层层划分范围。
>推进理解的属性发展拓展、问题延展：重要方式；
>什么是架构：架构也是从抽象到具体的考虑和描述；树形延展开来，可以写满非常大的黑板和巨大的脑图！！sharding-jdbc,dubbo,spring都可以这样方式来展现它的架构！！它的抽象到具体的考虑---本身才是架构！！！而不是什么模块、模式之类！！
>抽象设计：则某一层就不管上一层的含义和下一层的含义，即更抽象的含义或者更具体的含义；而是实现本层的含义；完成本层的含义指定的功能；。如网络协议的架构设计；	
>面向设计来理解，面向架构设计来理解，面向架构问题一层一层来理解它：面向设计来理解，所以按照面向对象设计的方式，看其中的对象、行为属性、流程环节逻辑。	
>找不到知识/描述 所对应的问题 ， 那么看书将没有条理纲领，变得零散琐碎没有组织。	
>不是按概念方式组织，而是按架构、问题方式来组织 笔记，书本内容。架构顺序，问题层次顺序。	
>架构不是设计出来的，也不是演进出来的(甚至不是迭代出来的--尽可能避免迭代)：而是问出来的。	
>每个方法方案都从属于一颗树，所以找到一个方法巧妙方法仅仅是第一步--找到从属的层次树 有更大的价值；(无论是谁想到的方法/概念，都要这样更进一步)
>解决问题的办法就是提出问题：类似递归和动态规划；。。权衡就是线性规划；	优势劣势在一定场景下也是劣势优势；
>一个词，到一句话，两句话，一段话，一篇文章；这个就是抽象总结，层次总结；越简洁，站得越高
--在网络、搜索引擎、推荐系统 三方面的专家；作为系统方面的独特优势/拔高优势；(网络-查询-推荐)
	
----有且只有响应，通信端才知道连接是否成功；。浏览器自动扩展。
----维持连接，并发连接，都是软件的实现，物理上看都是一条出口；从响应就是维护连接的角度看，不存在需要维护什么连接，维护就是维护连接数据而已；只要发送响应，连接就活了；在网络端口出口，可以连续发送不同目的地的响应报文，这就是并行；所以完全可以用队列来接收请求数据包；而用队列缓存发送响应数据包；多核使用起来，来并行大批量的发送和接收；不存在要维护和持续占用“端口”网络出口这种概念---完全没必要，用完即走 就可；	
	>或者不存在连接这个概念：所有的事情就是接收数据包和发送数据包(接送/发送缓冲区)。(连接 是 软件臆造出来的概念，不要和物理对应；和物理对应就会束缚思想，就会很多事情理解不了不知道原因)
	>连接的状态转移图；
	>应用的固定端口：实际上是建立新TCP连接的请求的处理的端口，请求到达这个端口--后面建立一个独立的TCP连接---来负责和客户端通信-交互数据；
----UML：为什么类继承关系图---因为这就是具体到一般的概念对象抽象过程。自上而下是能力顺序，能力组合；	
----说话和介绍：语速不要快，快就是掩盖问题，掩盖过程步骤；直接导致别人认为思路不清晰，表达不清楚，东拉西扯；也不利于自己思路的成长和扩展和自己主动发现问题，且必然导致不简洁--废话很多；
	>介绍需要先纲目后具体：抽象到具体；而不是张口就是罗列枚举---内容没有结构--全是线性结构；
	>描述更精简：一个字一个词，一句话，两句话，一段话；
----大事和吏治：大事 就像西天取经；吏治就像管理四人；


--计划：nginx/tomcat-->计算机系统-->架构-->自己的系统架构方案:专题研究、大提问、大总结。大简化/模型图化；
>一个进程看作一个消息，代码计划/任务计划；；都是异步隔离；	
	>程序启动点/执行点：可以多个，看作是并行的；(一个机器上，多个程序文件里)；可以留下执行点/新增执行点；可以删除执行点/减少执行点；
	>函数式编程为什么好：因为每个精细环节清晰描述确定了下来；使得充分配置和指明动作；
	>如何看待对象的方法：所有的对象都是被动的；主动的只有cpu/并行点；
	>程序的执行要想象为人在执行；多线程则是交接执行权给其他人执行；
	>抽象编程与具体填充：假设编程和实现假设。面向对象中一个对象属性就假设已经填充好了，一个接口的实例就假设已经在容器中有了。代码编码层面和虚拟机执行层面，都规定/定义/设计为 将 接口和实例分开，系统启动时/甚至具体接口调用时才去容器里找接口的实例(启动时 一方面建立实例容器，另一方面 对接口寻找匹配的实例和链接到实例---进行连接和关联)。资源填充 和 接口调用(抽象调用)，资源--接口的映射对。领域抽象，资源抽象，功能抽象。
----未知和迷惑的地方：痛点	；
----关键和核心的地方：要点

--混乱的答案，宁可不说；只回答真正掌握的；。没有逻辑，因为没有进行抽象；没有找到所在的流程环节、模型中的位置
--系统、中间件的介绍，不是一来就是组成结构；这层次已经太细了太具体了太里面了，必须要从最简洁最抽象最上层开始；最表面最近开始；务实，不僵硬，不突然，要自然，不要忽视和没注意没意识和跳过很多步；而是从问题出发、从困难出发、从疑惑出发
	>从问题出发：先明确问题；先明确表达出问题、疑惑点、黑箱、痛点、矛盾点、难点，表述的范围可以很大(完全不知道是什么怎么办)后面逐渐具体问；无论多少问题，先明确下来；尤其要全部且完整的描述下来；
		>问题的提出：先明确背景，自然衍生、过渡、转折、演化，逻辑关系上，什么时候什么事情什么人，事情什么阶段遇到的什么问题、阻碍、阻挠、缺陷、瓶颈、不够简洁、不够简便、不够方便、不够优雅、离目标远、离理想情况远、离期望/极限效果远；不够抽象的地方；把它们充分描述完整叙述结构式组织起来。
			>问题抽象：归结为一类问题；去除具体和细节而明确问题模型；
		>问题产生原因：过程；条件；	
		>问题导致的恶果：阻碍、损失；
		>理想的方案特征/效果/必做必不做的动作&事情/应当改变的环节: 
			>这种特征/必做必不做的前提、必要条件、必然要求、必然说明、必然指示、必然可以确定的更多的事情/结论：
				>一系列结论、约束得到之后(结合条件/问题/情况本身)逐渐可以清晰看到/归结出该具体问题符合的/满足的通用/一般的/一类的问题模型/函数模型/服务模型/IO模型/请求响应模型的轮廓：若干个具体模型
					>方案的装饰/补充: 补充可靠性/稳定性/高性能(从而高可用/高并发)：因为暂时只是一个裸机、容易受到伤害、有功能但没有抵抗力(仅为打火机的火而不是熊熊大火)
							>方案的用法规则：在请求缓存前使用
		>能将具体方案进行分类的维度/情况/模型/环节/流程/抽象表述 的确定：然后使用 抽象-具体 的方法来得到新方案；					
		>普通的方案：已有的方案；方案的抽象，方案的取值选择评价；方案的表象缺陷、劣势；。。模型、数据结构和算法、协议约定分担 维度 上考虑；
	>任何事情/事物都有顺序/逻辑：且几乎都是几种常见逻辑中的一种: 时间先后、空间远近、因果环扣、程度递增
--大总结：含义包括：重新 深刻理解：
--通用的建模架构能力+Flink深度强化学习的推荐系统。。。。而不是做简单的业务逻辑开发；用深度强化学习来做应用/解决实际问题(用户的识别问题和抉择问题)；用抽象建模架构出逻辑完整的方案(工具方案/服务方案)；
--一体两翼的发展模型：底座：增强操作系统、网络、搜索、推荐能力； 两翼：普通项目：则架构建模；特殊项目：则深度强化学习；。。四大基础+两大实践(应用/使用)。。基础：是为了解决自己的问题；实践：为了解决别人的问题(用户的问题/大众)；
--一次彻底弄懂，而不是 反复低温加热。看架构书和源码书，不看使用书。
--对话中胜利：一个是提问，二个是不断的输出-高能输出。
--牢固的观念: 系统都是被使用的。
--任何一个系统、产品、服务、方案、东西、事情，它要解决的核心问题是什么？理想的形态效果影响应该是什么？市面上对应的哪些产品达到了或者没达到或者很难达到？没达到是为什么是否有我们的机会？是否还有我们可以满足的缺口。找市场缺口。
--从缝纫机原理看方案所属的分类和方案内的环节。抽象出分类和环节。
--把自己当做cpu,调/使用各个服务/接口/类/系统。
--全新学习掌握方法：先定问题体系，先提问，定逻辑路径，后开始找答案--推导和思考和查阅资料。
	>旧方法：还是盲目阅读，还是从头到尾的阅读一遍的阅读。
--所有系统和方案的理解/研究/制定的出发点：都是 出发顶点/问题顶点/概念顶点，找到了顶点才能出发，出发要从顶点出发，才顺畅，没有后顾之忧
--计算机解决问题的方法：采集，记录，计算，展示，通知，跟踪 数据/信息。

--商业经营才能：(全新的解决问题的方法：提出问题)
--什么问题 是可以用互联网来解决的？ 只要满足什么特征，该问题就可以用互联网方式来解决? 该问题的本质是什么问题(如是信息传递问题？)该问题抽象一般化后是什么问题(资管、记录、通知、计算、采集识别调动、代理/中介/数据中心/信息中心/信息模拟线下过程中心、信息传递)(信息展示/发布/搜索/推荐 平台；信息池；信息可以是映射描述的现实事物的信息(如商品/价值物/人)，也可以是纯虚拟信息(游戏/知识/新闻/视频))
	>能用信息发布展示/活动追踪-信息记录/通知/协作/推荐/搜索 解决的问题：信息可以是 编辑的信息/映射的信息/等价现实的信息/等价现实任何事任何物的信息。内涵BAT的老业务(电商/聊天/游戏/信息流/搜索)。
	>能用数据驱动决策抉择与调度分配/识别与推理/观测采集与调动机电-生物 而解决的问题：如alphazero/图像识别/语音识别/视频识别/云计算/智慧城市/自动驾驶。内涵BAT新业务(云计算/视频语音识别-下棋打游戏智慧体/智能音箱/自动驾驶)
--码农之家和脚本之家、异步社区。从 面向对象-->模式-->架构：由小到大。
--给其他非软件行业的工程师/人员开发软件。三高三可(高可用高并发高性能,可扩展性可维护性可重用性)。
--最佳：一边看书，一边独立思考；(比起纯看书和纯思考都好)。因为 看书 要有沉淀，积累，独立思考 结论，总结。而不是流经书，翻翻而已，左进右出。
--说话：社交场合，最重要的是：要有自己的认知、决策和行动；对形势的判断和分析和预测。而不是被别人牵着走，或者置身事外。
--什么是最重要的? 就是你想做出一个什么东西...  这是最有价值的事情,是最重要的目标(比起学位和金钱和看多少书都重要);
	>不讲在公司的项目: 只讲自己 业余时间 做出的东西; ..  和 理解的东西... 总结起来 就是 四个方面: 架构 + 源码 + 算法 + 产品/作品
--不必指责和愤怒: 只需 战胜 和提防.
--莫忘理性决策：详细的明确和计算，一点也不能含糊。看看这次搬家时机的决策失误和搬家房间选择的失误，造成了金钱和时间上的巨大浪费。又比如以前自大没有投资股市---导致损失很大！！	拒绝感情用事和感动别人。
	>不能武断：不能一厢情愿。不能只见树木不见森林。
--兴趣不仅决定能力，而且决定性格，比经历更加影响性格；总结和思考 是兴趣带来的根本也是兴趣导致的根本活动；而性格能很大程度上影响命运---作。韩信(仰仗自己聪明而希望别人只记得我的好不记得我的坏)、赵括(自己负责精彩，麻烦交给别人--希望别人帮自己解决；只知顶层逻辑不知道低层逻辑)、李广(总觉得别人对自己不好，发现不了自己的错，不按程序办事，爱自己来，当别人按程序来--总觉得别人是让自己受气，受不了别人的指责)	
--在大部分有钱人和机构都将资本+利润存入股市的时候：说明股市是会升值的，股市就是最大的公司。多余的所有钱+利润 只有在股市才能分享。
	>既要有信心，也要有担忧： 激情和忧虑 都有 ，才是 理性的人。而不是两者都没有的麻木不仁、冷血和装。
	>做人不要尖酸刻薄，说话要说别人的好，坏处知道 但是不要说出来。有的人不喜欢被戴高帽，或者认为是反讽，这只是 好 没有说到点上而已。
	>面对别人指出的问题: 改就完了,且深刻反思和各种改进, 大量的收获和扩展.更强!!!错误的反思总结得到的东西让人更强!!!
	>已经是青年人了：要敢于争取
	>控制欲望、总结反思验证、勤于积累和使用：控制无收益的欲望-事情白白浪费时间；总结反思-站在第三方检查和痛批评价自己的想法和行为-从细节到方向目标-做得不行的要改变；勤于积累和使用-阅读和实践都要彻底掌握弄通；
		>读书不破、万卷何益：不会有长板；
		>不痛苦痛批、不是反思：
	>择人：最忌讳的是好吃懒做的人。喜欢比较的人--一上来就卡脖子；眼睛没必要跟鼻子比。
	>不要轻易拒绝做 看不起的事情、还早的事情、不重视的事情、觉得自己不需要的事情-觉得世俗/自大的事情(世俗也要同流合污)：买车摇号、社保缴纳、公积金缴纳、找女朋友、找好的房子、考在职硕、炒股-投资。多少件事情--明明顺手就可以做，却没有做，一直拖，导致损失惨重！！
		>每一件瞧不起、不重视、还早的事情：相反，都要早点做！！
		>机会错过 难再有：往往影响是决定性的。没把握机会 就是 决策性失误！
		>其他事情：私活-阿里云-本地开发-换电脑。
	>想到就要做，错过不再有：这是最重要的名言！！只有这样才能发挥才智 并且 赢得 胜利！！！	最重要的就是时机、机会，把握机会把握时机。
		>时机、战机 转瞬即逝：稍纵即逝。错过就是一辈子，错过就是奉上身家性命。犹豫不决和瞧不上和不需要而暂时不做延后做 都是错失良机、贻误军机。
			>说小了是 酸，说理性点 就是 后悔遗憾 承受损失。
	>商业机会：大部分来自于持续观察大家的生活---什么社会事件政策会怎样的影响人们的生活/会让人们的生活发生哪些改变； 人们生活中遇到了什么瓶颈/矛盾/困难/问题/需求/不足/遗憾/不开心的事情。		
--理论观点/方法缺乏层次系统的组织，还是在等别人分配赚钱任务。概念、观点 还是片段、不连续的。
	>基本认知方式：提炼、总结、简化、抽象、封装 。
	>问题为 元素 进行组织：这次不以概念为元素，来更方便于实际使用、进行设计训练---工作也当作是设计训练。
	>填充所有的逻辑漏洞：
	>分层问题森林\分层问题 群: 一个n层的问题,其顶元素 只是 另一个n层问题的一个元素. 因此 k个 分层问题  构成 了 一个最顶层分层问题 , 整体 是一个 问题森林.
	>每一种策略/设计/具体化： 都必须明确它到底是为了解决什么问题。
	>范畴不明确：就会 陷入 “还有什么” 的困惑和迷途。范畴的向下具体划分和向上抽象统一更大范围。
	>讲一个东西的内容时：可以看出是否结构化思考，是否很明确范畴，范畴化思考，不断的抽象上升又具体下降--树上遍历。因为问题，产生目标，想到思路，立刻执行。
	>输入不必多：关键是转化 为 总结、实践  有 多少。	
	>可视化：为最佳的理解方法。
	>深入一个事物：就是问它的什么的什么的什么的的的的的的的的的的的的的的。
--领域、问题、逻辑。(路径/方案/思路)(条件/目标/路径)	范畴。顶级思路/顶层思路。顶层领域，顶层问题。范畴与逻辑。范畴关系(同一范畴内、不同范畴内)、比较关系、规则关系、联动关系。
	>不能只以概念入手，也要从问题、思路入手。
	>谈话永远不能泛泛而谈：回答而已，别总想着怎么回答会好-显得聪明有创意有见解之类。必须要有目标，要预见和引导 话题走势走向，进而从当前条件 寻找 路径/思路。
	>开发时：反思总结 而 扭转观念，不要一来就想着实现代码，而应该想着本层逻辑、本层事务、具体交给下层实现-下层再进行拆解-完成它要做的那部分工作-塔式调用/直到具体的专门的一个个的实现//这个也是逆封装过程，类似塑造过程。
		>链式调用：默认实现Filter 放在 最后，用户提供的放在前面；从而用户提供了实现如果想提前返回则可以直接先返回不走默认。
		>插件的发现/用户回调类的注入：往往都是自动配置类bean  注入了外部的 beanFactory，而自动配置bean里就有本框架的核心类，而获取了bf,则各种规范的实现bean就都可以获取了，从而用在框架各个位置。
	>一切技术都是简便方法：更快速的方法、更省的方法、更安全的方法。更可靠、更通用的方法。
	>调用 就是 询问：询问就是调用。
--顶级关注点：任何事物 寻找到它 最有价值的一面  对我有用有好处，如果有 则 认识到通和使用到精。没有看到组织结构，必然混乱和觉得复杂、含糊不清、仍然不懂、没有消化--分解/拆解出有营养可以被利用来构造系统的基本元素出来。
	>于社会：形势和机会：最理性的分析 -->最准确的预测 --> 最周全的方案 --> 最简便的验证。很多人不相信完美的十全十美的方案的确存在，也就不愿思考和制作和逼近，而是找了一个草率的方案，执行后失败而亏损。
		>人际关系：在不能够失败的事情上取得胜利 才叫胆子大胆略胆识,其他不能产生直接或间接作用用处的事情 失败了也无所谓--就当作给对方一个面子--做个厚道人-而不是尖酸刻薄没人接近没朋友-朋友就是大量小事上免费的互相帮助。办事：对方道德好-好心人，道德一般讲利益-合情合理，道德差坑蒙拐骗一把-就损失了。
	>于痛点：目标和思路：最理想的样子 -->最真实的现状 --> 最顶层的思路 --> 最简便的做法。
	>于业务：领域和关系：帮助用户解决的问题是什么(用户只需要有什么条件、只需要做什么)(概括) --> 最理想的方案的最顶级的思路是什么 --> 要展示什么信息 、后端计算要什么信息 --> 领域的属性结构、领域在某活动中关联的领域(如人和商品在购买活动中关联了起来)--活动的间接结果/结果描述：就是将领域和领域绑定在一起--划归到一个活动领域中而成为一个活动领域的两个属性--毕竟一个活动本身也有领域/流程/规则--单独的领域是独立无关的,只有在活动中才和无关的领域关联起来;反过来发现两个无关领域关联起来了则一定在某个活动中(如人与商品-在购物活动中；商品和地点-在物流活动中)；领域是基本不变的有限的，真正大量的不断产生的同样需要记录的是活动数据--一是活动参与者多二是活动步骤多三是活动多，此外，展示独立的领域信息 其实价值有限且固定难以增长，而不断新增的活动让领域参与者有新的参与感、活动服务了参与者、给参与者带来了新的服务价值、解决了新的问题 满足了新的需要--这些都是在活动中完成的；所以创造活动并记录活动 数据 才产生巨大价值。纯线上活动、活动的线上部分、线下活动的线上模拟活动 ，寻找、熟悉和创造 新的 活动，是对一门业务能力的三个阶段。
						 --->明确 所有的领域(属性结构)、活动和活动领域(其属性为若干个独立领域+活动本身信息) --> 各个活动领域 将各个独立领域 直接或者间接 关联了起来，则可以建立起一张关联起所有独立领域的大表；也可以判断是否存在和 存在则找出 两个独立领域的关联路径；帮助数据分析和数据挖掘。---> 使用 活动领域 记录和重新梳理 活动的过程。记录了一个活动过程，就是记录了一个服务过程(展示-交易-消费-评论)  。例子：一个购物：独立领域的关联过程： 人和商品(下单) --> 人和商家(支付) --> 商品和地点 (物流) --> 人和地点(固定信息) --> 商品和人(物流终点) --> 商品和评论(消费者对服务打分)
		>澄清 业务流程是什么-->每一步需要展示什么信息、要上传什么信息
			>信息分成哪几部分: 本质上可以归结为 哪几个独立的 领域(有明显的自己的边界)，这些领域的属性结构树是怎样的。
		>有 存储、筛选、推荐和展示海量数据 功能的 系统：供看、消费、互动。
			>展示的目的：>展示的东西：展示有价值的信息、宣传(广告)、引导用户购买、引导用户提供信息(生产/上传)、引导用户交互信息。
	>于系统：：拆解和组建。本身的规律和统一的路径。范畴式创新(补集/包集/子集)
		>认识：
			>系统一定不是一个单调的整体，而一定是组装起来的。单调的整体 只是一个部件，甚至不能用来构造复杂稳定的系统，没有这个扩展性、接口。
			>系统的运转：组装起来之后，启动系统，开始触发系统，向多米诺骨牌一样 传递下去。
			>系统的逻辑结构：假设...则有。如果...并且...,那么对...情况,则有...。假设有几个关键的暴露关联关系并好度量的事实、实验、条件、不变性，则可以得出xx间接的关联关系。具体关系直接向上抽象，将具体量消除,推导更一般的关系；。或者将关系和关系封装在一起，得出更间接更远距离的关联关系，得出对一个事物的完备的关系集合。或者规律本身特征的概括，来得出其他未知规律也一定满足的特征-抽象特征(如不变性)
			>系统的元素：系统的元素可以用来构成其他系统。因为它职责单一，可以替换别人也能被别人替换，可以共享(越单一越能被共享,越复合越不能被共享)(共享就是拿来使用,避免重复劳动)，可以互换，各个系统的若干个位置上都需要，从而用这些元素构成的若干个这类系统，一个系统报废了拆分出的组件元素 还可以放在其他系统中，从而元素利用 最节省 最经济、利用率高-浪费少。单一职责 是 有限的 ，构成一个 有限的集合。承载单一职责的元素 种类 就是 有限的，构成有限的类别的集合。从而每类元素可以批量生产，缓存起来，按需提取。
				>元素的类别：职责类别：特殊的元素--骨架型元素(支撑连接其他元素)。业务型元素(完成自己的输入输出模型)。
				>元素的接口：元素 的 可以和其他元素连接咬合起来 而传递/接收 刺激/物质/信号 从而发挥自己的作用 的部分。
				>元素的连接：一个元素的接口和另一个元素的接口咬合在了一起，形成 信号/刺激/物质 可以从一个元素传递到另一个元素的状态、复合形态、复合物形态。新的复合物有新的接口。不同于两个元素的输出输出模型 的 新的输入输出模型 产生了，这是连接起来 最大的意义和作用和目的，还具有新的状态转移图---也有使用用途。
				>元素的组建：在一个框架型/架子型/骨架型元素上(丰富的接口)(本身甚至就简单的仅仅是一个接口集合) 连接 接入 若干 功能型元素 和 骨架型元素。
					>组建的目标-条件-路径：最顶层的目标--产生一种更间接更长路径关联起输入输出的高度更高长度更长远度更远的输入输出模型的子系统/子模块(以进一步组装出更强的系统/让本系统更强)
				>元素的封装：用边界将 若干个临近的元素(无论是否连接起来) 包装起来，隔离其他 集群元素，而有自己的独有的基础资源、基本元素资源池。形成独立的环境、独立的上下文、独立的数据中心(信息中心)，统一的对外接口、复合的多模式的输入输出模型。
			>系统的状态转换：可以从外部施加给系统的动作，系统接收该动作后向内传递 而改变内部形态 最终传递反馈到外部(表面) 输出 响应，施加的每个动作每种动作都会引起系统状态的往不同路径上的迁移转化。这个状态迁移图 往往 固定的，即从某状态到另一状态可复现/永远不变的，从而沿着这些路径找到最短路径达到我们希望的具有某特征的状态---往往也是我们的目标 和有用处的事情。
			>系统的拆解分解：(自然界的系统没有飞地--即没有可以控制感知的物理隔离的另一部分; 生的属于后代属于另一个系统;甚至不能产生和发送控制用途/通讯用途的电磁信号;声音等是否算)
				>系统要解决的问题本身的拆解：问题的树形结构。问题模型。
				>系统的目标的拆解：功能的拆解，职责的拆解。从整体 最顶层 的 一句话概括  到 最底层的 若干个 元素的单一职责的表述/表示。(最高目标就是最高层的目标,而非平等的目标中最重要的目标;区分两种概念表述)
					>顶层目标的确定过程-就是需求明确的过程:
						>最简理想模型功能的明确过程：最简单目标、简单模型功能、理想模型功能、最理想条件下的模型功能、各种因素都不考虑进来的模型(正相关影响因素/负相关影响因素/微扰因素)、理想实验模型、实验功能、脆弱功能、简化功能、本质功能、核心功能的明确过程、澄清过程、细化过程、精准描述的过程。还只是一个实验理想模型。
							>理想条件的特征：其他阶段不考虑-只考虑核心阶段、其他影响变量不考虑-只考虑主要影响变量、具体细节情况不考虑-只考虑最抽象上层的情况。其他功能不考虑-只考虑单一功能。
						>其他一个个平级约束条件逐个考虑进来后 模型逐次扩展后的新而又新的模型的明确过程：新目标、新的主体架构、演化后的主体架构。扩展对基本功能的表述，将其中的具体的东西向上抽象化一般化。最苛刻条件下的模型功能。
							>约束条件的特征：限制条件、故障、条件变量值变为极值特殊值、险恶的环境、多变复杂的环境。必然会自然会发生的遇到的新需求，第一版现在就会遇到的其他需求。把这些需求明确下来--为了需求的完整和深刻 先只讨论需求有什么是什么 此环节不考虑实现。
							>考虑的目的/必要性：让系统健康成长、稳定成长、能适应险恶的环境、自愈自修复。生命力更顽强。
						>目标模型的向上抽象过程：功能增强过程。封装进其他目标模型，和其他目标模型封装到一个新的目标模型。
							>增强这个目标模型：依赖这个模型、监控这个模型、统计分析监控量并得出结论发出控制信号调节/指挥/引导/服务/治理/保护/优化/自动化/智能化 这个目标模型/系统。
							>考虑的目的/必要性：考虑到各方面各线可能增加的需求和功能-进行预留和预备、让系统扩展性更好、性能更好、功能更多还不乱、更稳定可靠、可扩展也可卸载替换功能模块、更好的可控性-更细更广可控。
						>目标模型的向下细化过程：向下一层层具体化展开明确确定。
				>系统的解决思路的拆解：方案思路的拆解。思路模型。
					>思路中的有限类型元素集合：
					>思路中的当前可以使用的条件的集合(组织成结构)：
				>系统的组件的拆解：组件模型。分解出下一层的构件，下一层的构件再到下一层的构件。一层层分解下去(如肉分解出蛋白质-蛋白质到氨基酸,来到可以被吸收的层次)(如汽车拆解出底盘-底盘拆解出发动机系统)，拆解到元素层级，最广泛被使用/重复利用的 元素级别。
		>使用：	利用和扩展。训练(它)和增强(它)。整合(到一个方案中)与改造(更适配一个方案)。
			>该系统如何应用在方案中：哪些类 哪些问题 的 方案  会使用 到 这种系统。就像用人 一样 用系统。
			>这些方案如何应用在业务中：这些方案又可以用在哪些业务中。
				>方案的评估和论证：
			>这些业务如何解决人们遇到过和将遇到的系统型的个人又难以独立解决的希望有组织-公司提供专业的服务来解决服务的问题/痛点： 
				>动作的条件、目的和规范：如伸缩 这个动作。
	>于创业：人们当前遇到了什么问题 --> 人们会遇到什么问题 --> 人们想要解决而无法解决想别人提供可以解决的哪怕是有偿的也要解决的问题是什么 --> 先 概括出用户想要而缺乏且看到则感到惊喜的服务是什么
>使人不惑：
	>结构：将系统呈现为结构形式来表达，可以帮助分清主次，找到本质入手，立刻看到关键、看到本质的轮廓、要义的切入点、概念。
		>一个变量 可能 也是 一个结构：
	>大量的困惑和不理解：都是 理解推进过程中 没有建立中间概念 ，即 没有找到可以 对某 事物的 理解作用起到增强作用的 中间概念、桥梁概念，通过桥梁概念来找到前后的联系，上文和下文的联系，导致结果突兀难以理解不明所以 。所以 理解的推进过程 中 中间概念的 找到 至关重要。	
		>困惑的根本原因：联系是断开的。上文和下文的联系 是断开的。或者说是 强硬 联系起来的。联系的一点也不自然。
		>没有归结到根本：没有将上层抽象的概念和 底层 基本基础的 牢固的概念 建立 联系，建立 坚强 牢固的 联系。上下之间缺少 中间概念 也会悬空 而 难以理解 抽象概念。
		>强硬理解：就是 不知道 条件到目标的路径，而强行让自己认为条件到目标就是必然的/直接的/一步的/显然的/不关心中间过程的。完全就是记。只知结论。
		>明确定义构成整件事情的所有 没有 清晰准确定义的 基本概念：都要 明确 提出 和定义 一遍。并构成 概念树。
			>要基于实验模型 进行思考：上面的概念页来源这个实验模型；没有实验模型 那么 就没有任何图像，只剩下逻辑了。
		>任何的总结都必须总结到最顶层：形成最简洁扼要的一句话的总结。由它可以层层推出到最底层的 整个 树形细节过程。	
		>使人困惑和书上东西看不懂的原因：一个动作、操作、名词、式子的定义/含义 理解错了，或者根本不理解。第二，才是 跳跃，中间过程 和 联系 省略了/显然了。 如 min max L的含义。
		>没有做铺垫没有说概念是从什么实例实际具体中抽取抽象而来的：没有关联结构图，就会很抽象。比如 条件随机场。
			>没有梯子的介绍/书：除非作者能腾云驾雾飞上去。
	>以前总是失败的原因：
		>大量的基本概念的含义都理解错了：错误 或者不够本质，拆解到不可拆分的 毫无封装的东西。
>目标：对一种系统 进行 领域建模，系统架构。总结出新的 一类架构，新的一类问题/共同问题。		
	>写研究报告、策划方案、完整讲清楚-八面受敌：
	>验证方法的进步和改进：
	>论文阅读：先浏览一遍，局部看懂，局部能看懂的看懂，主线清楚。然后才开始细看，把中间过程补充上。所以至少两遍。
>公式推导的问题/痛点、想法、目标、起点、条件和路线：每次公式推导必须明确，从而清晰思路。
	>问题的提出：推荐算法中 通过 相似用户、相似物品计算 用户对 物品的 喜好值 并不是彻底的一般的方法，更像是一种临时的方法。所以想寻找一种通用的统一的一般方法。
	>想法的得出：评分矩阵里的每个评分 为什么是这个 值，思考这种必然性、确定性，不那么显然的显然性，任何一个确定的一定的取值则要么是公理要么就可以继续分解用更基础的概念集合更本质的元素集合 来解释来计算来表达出计算过程来表达相互作用得出该结果的过程，任何一个值 要么 是 公理值 要么就是 计算结果。
		>把评分值当作计算结果 反推计算过程：假设是一个简单的线性组合得到的计算结果，而线性组合可以分解为两个向量的乘积，而这个评分值显然是由用户的特性和物品的特性决定的，而特性相乘，必然一个是数量-一个是含量，显然用户要求的是数量，而物品有的是含量；所以两个特性向量，用户的是用户的特性数量/偏好数量/需求数量，物品的是物品的特性含量。
	>转换后的目标：计算最优的用户特性数量矩阵和物品的特性含量矩阵。最优的标准：明确为 方差最小。在这个约束/要求下 计算PQ矩阵。
	>起点条件和顶级想法层层细化：在这个约束/要求下 计算PQ矩阵的数学方法：梯度下降法/最小二乘法。用差量的方式 甚至可以用 迭代法：Puf(t+1)=Puf(t) + α * зLossui/зPuf(t)	, 而 ^rui = ∑Puk*Qki, Loss = ∑(rui - ^rui)^2, 为防止overfitting,添加正则项控制过拟合：Loss = ∑(rui - ^rui)^2 + λ(∑Puf^2 + ∑Qfi^2) = f(P,Q)
	>方案的证明和优化：
		>对于 ^rui = ∑Puk*Qki ： 此表达式计算^rui 显然只考虑了 Pu和Qi相互作用的部分，即用户和物品共同决定的部分--通过需要数量*具有含量 来 共同确定的部分，实际情况中 可能还有 只跟 用户、只跟物品有关的因素 bu, bi, 甚至跟用户和物品都没关系的因素μ ，所以 修正后的 ^rui = ∑Puf*Qfi + μ + bu + bi ; bu往往可以用用户的性格打分习惯严格、温和来决定；bi往往和物品质量有关；
		>对Puk: 是用户对各个特性的需求量，而用户实际 对这个特性 的 需求量 可能 会 因为 用户 购买了 越来越多的物品后 而 有所改变--比如历史买了富含维生素C这个特性的西红柿 而 下次对 黄瓜这个同样富含维生素C这个特性的物品 需求量 就更低了，所以需求量 需要和用户的购买历史物品 关联起来，即 Puf 替换为  Puf + ∑Yjf/sqrt(N(u)), ∑Yjf就是已购买的物品对此特性的需求量的影响力之和。SVD++
		>再次优化：则是 考虑时间因素了。rui的各个因子都是时变的了。
	>符号的拆解和封装：符号也可以拆解开 用 更基本的 符号来表示，直到 +- 等。其他符号都是简化某个使用基本符号构造的复杂运算过程 而 定义的；就像 计算机里封装出一个个函数一样 封装出一个个符号。
		>积分符号 也是 一种简化符号，是对 某个区间 分割 出的 无数个 连续的无限小量 求和 这个过程 的简化 表示。Σx*f(x)dx = ∫x*f(x)dx 
		>乘法符号 是一种简化符号：是对 k个 相同值m的 求和 这个 计算过程 的 简化 表示，等值表示。C = m+m+..+m = k*m。。。数量和单位数量值--方便总量值的计算。(计算总量 和 可以摆出多少种组合 都是最原始的需求，野人时代就有)
			>乘法第二种含义：同时性/两个集合的元素能够组合出的所有结果构成的集合-方便组合数的计算。比如两个独立事件同时发生的概率。一个事件发生的概率 等于 这个事件代表的情况数 占 全部情况数 的比例，(一个事件 是若干个情况的集合)(一件事情 全部可能出现的情况)(一个实验 全部可能出现的结果)(一件事情 出现了某种情况(即所有可能情况中的某种) 是 一个 概率事件)。
				>当两件独立的事情联合构成/视作 一件新的事情时：则这个新的事情 全部可能出现的情况数 就是 两个子事情的情况数之积(组合出的结果)。
				>同时性：代表了组合空间的增大。
			>乘法的第三种含义：映射。如 [0,c]*[0,b], 如果 每个当作轴上的点区间，则两个集合相乘 就是映射到 相交的一片平面区域，这也可以看作两个集合元素完全组合的结果。	
		>触发符号的来源：计算比例、占比。计算倍数则是另一种 源头。概率 是 表达 情况的占比。		
	>推导这件事情也需要一步步推进：每一步都走的很小，很连贯，来保持思路的连贯。
		>合理的充分的代数表示：非常重要的一步，表示事情、过程 应该完全代数化，没有具体变量的痕迹。
		>先明确概念再明确概念之间的关系：
	>数学：就是在基本概念和定义(元素、目标、条件、路径) 下 向上 封装、抽象 、推导推论 而 建立起来的 关联系统结构。如线性代数、概率论。
		>抽象：就是省略具体特征。
	>物理：也是基本定义和概念、不变性等 上 进行抽象、封装、推导推论 而建立的 关联系统结构。
>举动-痛点：要解决的问题、目标、条件/起点/底层/原子、思路。最顶点的思路，最上层的确定性/认识。难以形式化描述的任务 如何 用 软件来解决。	人类靠直觉解决的问题 如何通过计算机来解决。
	>解法/解决方案：根据层次化的概念体系来理解世界。某个概念通过 与某些相对简单的概念之间的关系来定义。从而让计算机构建较简单的概念来学习复杂的概念。绘制出一张 这些概念如何建立在彼此之上的图，来得到层次很多的 深图。这种方法就叫 深度学习。
		>特点： 规则简单：策略困难。规则可以 完全形式化的非常简单的 规则列表来描述。抽象和形式化的任务 对计算机 来说 是容易的。
		>特点2：非形式化的内容 表示出来。
		>机器学习：从原始数据中 提取 模式 的能力。从数据中获取知识(估计的参数)，然后用来决策(用估计的参数计算决策条件值得出判定结果/选择选项)。 
			>数据-->特征集-->机器学习算法-->得出判定选择选项
			>数据-->机器学习算法发掘出特征集-->机器学习算法-->得出判定选择选项: 称为 表示学习。
				>表示学习算法的例子：自编码器。它由 编码器函数 + 解码器函数 组成。
					>编码器：输入数据-->该数据的不同的表示/新的表示。
				>变差因素：不可观测 但 影响 可观测的量。且它们同时影响着 可观测的量。
				>目标：从原始数据 中 提取 高层次、抽象的特征。如各种角度拍摄的汽车图片-->汽车。如带口音的说话-->内容。		
		>深度学习：让计算机 通过较简单的概念 来 构建 复杂的概念。因为 计算机是不能直接理解 感官输入的数据的。将事情表示为 嵌套的层次概念体系。
			>从原始数据开始，一层层向上提取 本层 能够直接 提取的 更抽象一点的/一般一点的/一类一点的 特征/基本构件 的集合。 如  原始图片的像素集合-->通过相邻像素的亮度 而 抽象出边缘实例 若干---> 通过边缘 而 组合/抽象出 角/轮廓 实例 若干。--> 通过轮廓和角的组合/抽象 出 物体的部件/部分 实例 若干。---> 通过 部件/部分 而 组合/抽象 出 完整的对象 实例 若干。
				>表示方法：深度概率模型
					>前馈深度网络：
					>多层感知机：
			>整流线性单元：
			>反向传播：
			>长短期记忆网络：LSTM: 
		>线性代数：
			>标量：坐标轴上的一点
			>向量：空间上的一点。多条轴 的联合值域/组合出的值域/构成的值域 就 张成了一个空间。 
			>矩阵：1.看作初始坐标系下的n个列向量构成的新的坐标系。(这是 对向量的坐标系变换角度 看)
			>张量：1.在各种坐标系下值/坐标值 都相同的量(坐标系也考虑进来？)。
				>黎曼流形：曲面上的各种对象在不同 坐标系下的 表示  之间的 联系。
				>一个具体取值的向量：显然要考虑 这个向量在哪个 坐标系下，如在直角坐标系下，球坐标系下，还是一个 自定义的坐标系下。
					>坐标系的表示：x = [x1,x2,...xn]^T  上标就表示坐标轴索引。
					>坐标值的表示：就是[...]表示。 空间中同一个点，在选择不同坐标系 来 表示它时，坐标值 是 不同的。
				>本质定义：x是直角坐标系下的点, f(x)表示 这个点处的一个物理量；在坐标变换后，x变换到了球坐标系下的x', 对应的物理量为f'(x')； 如果 f(x)=f'(x') 则f(x)是0阶张量，	f(x)=f'(x')是变换法则。
					>坐标变换：x-->x' : 可以写作： x = g(x')   dxi = Σзxi/зx'j * dx'j  矩阵形式：dx = S dx' 这里 S就是一个偏导数矩阵，第i行j列就是S(i,j)= зxi/зx'j;  S就是 x用x'来表示 即x(x')这个函数 的 雅可比矩阵。x和x'之间的变换是非线性的，但是dx,dx‘之间的变换则是线性的。物理量dx具有线性的变换关系，所以定义为 1阶张量。 同理 ，dx/dt = S * dx'/dt 则 dx/dt也是一阶张量。
						>爱因斯坦求和约定：dxi = S(i,j)*dx'j  某个字母同时出现在上标和下标，表示要对它求和，这里就是对j。或者说要把哪个多余的标 消除--就对它求和。
						--读音：西格玛：∑Σσ ， 拍：Π， theta: θ  delta:δΔ， lamuda：λ gama:γΓ 倒三角：▽▼  rou：ρ,  uu'sx： 所有数学符号。uu'jh：几何符号； 
						>梯度变换：▽f = [зf/зx1,зf/зx2,..зf/зxn]^T,  而 ▽'f' = [зf'/зx'1...]^T  因为已经假定 f=f', 所以 зf'/зx'j = зf/зx'j = Σзf/зxi * зxi/зx'j = Σзxi/зx'j* зf/зxi 对i求和---因为这样才能把i消除。  纵向拉开后，形成方程组 而用矩阵表示：▽f' = S^T*▽'f
							>进一步：假设令 ▽ = [з/зx1,...]^T = [з1,з2...]^T ,  ▽' = [з/зx'1,...]^T = [з'1,з'2...]^T 则 上式可以简化为  ▽' = S^T*▽,  因为 f'=f 所以消除了。或者简写为 分量 形式 ： з’j = S(i,j)зj  从而说明 ▽ 和 зj 的变换也是线性的，是 一阶张量。‘在S侧则这种张量的变换规则 是 协变的，'不在S侧则这种张量的变换规则 是 逆变的。矩阵运算的变换：将S移动到另一侧：S^(-1)(j,i)*з'j = зi从而逆变形式 变协变形式。
							>S: 是一个i*j的偏导数矩阵，融合了张量的变换规则，就是张量的变换规则：(S(i,j)) = зxi/зx'j  即 上标一定在分子上，下边在分母上。
								>协变的：协变的变换规则，这个变换规则 在 新坐标系侧，用在新坐标系上。协变的 求和 对 上标求和。
								>逆变的：逆变的变换规则，这个变换规则 在 原坐标系侧，施加在原坐标系上(进行逆变,变为逆)。逆变的求和 对 下标 求和, 但是微分的逆变 是对上标求和----所以一般看 这个一阶张量的指标写在上面还是下面--写在上面则对下标求和-写在下面则对上标求和。显然，逆变的变换规则 矩阵 可以转换为协变的变换规则矩阵，同理反过来也可以。
							>▽：(对坐标的)偏微分算子向量：分量即为 зj = з/xj。这个算子的变换是线性的，所以是张量，因为是一维的，所以是一阶张量。即梯度 是一阶张量。
				>度规：长度和角度的度量。			
					>直角坐标系下相邻两点的距离：用勾股定理得出：ds^2 = Σ(dxi)^2 = dx^T*I(n,n)*dx = ΣΣδij * dxi * dxj =δij * dxi * dxj  这里用了爱因斯坦求和约定；为什么要用i,j因为避免两个向量的约束关系直接在i,j上体现出来，而应该无关的，所以应该提出这个关系而在δij这个矩阵里表达出来。
					>任意坐标系下相邻两点的距离：借鉴直角坐标系中的表示，定义为：ds^2 = gij * dxi* dxj 矩阵gij 就刻画了 该坐标系中 某两个坐标分量积 对 长度平方的影响权重 ，矩阵中某个元素表达了 某两个坐标轴分量积 对 度规结果 的 影响程度。 在另一坐标系下 来表示同一个 长度 则： ds'^2 = g'(p,q)* dx'p * dx'q , 都表示的同一个东西的长度，所以取值应该跟坐标系无关，所以长度应该相等，即 ds^2 = ds'^2, 所以 gij dxi dxj = g'pq dx'p dx'q = gij * (S(i,p)*dx'p)*(S(j,q)*dx'q) = gij*S(i,p*S(j,q)*dx'p*dx'q  这个说明了 g'pq=gij*S(i,p)*S(j,q) 说明 gij 是二阶张量。变换规则是线性的。显然右边 是隐含了对i,j求和的。写擦矩阵形式：G' = S^T*G*S。。。
						>原：ds^2 = gij * dxi* dxj = dx^T * G * dx = (Sdx')^T * (S^(-1)^T G'*S^(-1)) * (Sdx') = G'dx'^Tdx' = ds'^2 证明了 长度 在两个坐标系下是等值的。
							>注意：1.分量相乘是可以交换的(求和符号也可以在交换后才起作用/且按交换后的指标顺序来对指标求和)，所以gij * dxi* dxj = gij*(Spi*dx'p)(Sqj*dx'q) = Spi*gij*Sqj*dx'p*dx'q 。2.同一个元素在原矩阵中的上下标和在转置矩阵中的上下标是相反的，或者说 原矩阵中的一个元素可以用转置矩阵中的一个元素来表示：如Spi 就是S^T(ip) . 3.几个不同矩阵的各自的元素相乘，在进一步表示矩阵相乘的时候，需要加求和符号，此时应当对矩阵元素的表示和相乘顺序作调整以能 正确表示 矩阵先后相乘计算的求和过程。或者说 (调整后的)元素相乘的 求和 过程能够反应/等效 出的矩阵相乘过程。对所有指标都要求和： Spi*gij*Sqj*dx'p*dx'q = Spi*gij*S^T(j,q)*dx'p*dx'q = dx'^T* S*G*S^T * dx' = dx'^T*G'*dx' , 即 得出 G' = S*G*S^T 这就是长度 的 度规张量G 的逆变的变换规则。从形式上看，这个度规张量 符合一般的张量形式。长度的度量是度规，这个度规是2阶张量。
								>长度的度规张量 的变换的 带指标形式：G' = S*G*S^T 的带指标 形式： G'(p,q) = S(p,i)G(i,j)*S^T(j,q) 注意这个是逆变形式-是对下标求和 。。长度的 度规 是2阶张量，而长度本身 是 0阶张量(即标量)
								>张量变换：一阶张量的变换，用线性变换表示；二阶张量的变换，用矩阵合同变换 来表示。更高阶张量的变换 表示 如下--协变形式(注意是对上标求和)。
						>G: G=(gij) 称为 metric 张量 或者 度规。直角坐标系下 这个 度规G 是 单位矩阵I = [1 0 0; 0 1 0; 0 0 1] ，球坐标系下 这个度规 G' = S^T*G * S = S^T*S = [1 0 0; 0 r^2 0; 0 0 r^2*sin^Φ] 分别代表了 在径向、纬度、经度上的影响。
							>度规 gij: 表示 基向量的变化量 引起的 向量的 变化，两个变化的比例 的平方。比值的 平方。如直角坐标系中，三个基向量上的这个比值都是1，圆柱坐标系中 三个基向量上的这个比值 则是 1 r 1。圆柱坐标系中，认为dr,rdθ,dz才是基向量，即基向量的长度不一定是1：而是sqrt(gij)
						>T: 如果T是一个张量，即原坐标系下的张量，T=T(i...k)(p...q),  则这个形式 说明它满足 线性变换法则：1.如果坐标系变换表示为：dx = Sdx', S是坐标系上点的变换度规， 2. 则和新坐标系下的张量T'(u...v)(m...n) 的变换关系(即协变形式的变换关系)为：T(i...k)(p...q)= (S^(-1)(m,p)...S^(-1)(n,q)) * T'(u...v)(m...n)*(S(i,u)...S(k...v)) 新张量左边为协变而对上标求和，右边为逆变而对下标求和。显然要比微分/梯度/长度的度规 这些张量 的变换要复杂，但它 又必然是 微分的变换规则矩阵和逆变换规则矩阵的若干次组合。比如长度这个标量的度规G/张量G 就是一个点度规和一个逆点度规 的组合。
							>注意：m...n,u...v都是求和指标。为什么要定义这么多指标？因为发现了通项的存在，然后 为了描述准确通项 是 什么 表达式的 通项/通项如何延展为完整的表达式，所以要定义/加上指标来指示说明(就像代码里的指标/标记一样)。但大多数情况下 带有大量指标的通项 本身并没有给出可以计算的信息，这个通项 是 自底向上 从 单一指标的量/可观测的量/可接触的量 层层 向上 封装 出来的(因为每个不同的指标 之间没有依赖关系，所以它们凑到一个表达式中 就是 组合的关系,形成的量 就有多个指标)
							>上标：新坐标系 的 分量索引。如球坐标系。第二个坐标系的轴号/基向量号/微分向量号/偏微分分量号。或者 一个坐标系下的第二套指标。上标逆变。可以单个指标，组合指标，一个量有很多指标，说明它是构成一个巨大巨多层次求和的表达式中的单个元素的一般形式；
							>下标：原坐标系 的 分量索引。如直角坐标系。第一个坐标系的轴号/基向量号/微分向量号/偏微分分量号。或者 一个坐标系下的第一套指标。下标协变。一个带指标的量 是 一个求和表达式的 单个元素形式/单项统一形式。这个单项可以是一个 四则运算表达式，也可以是微分偏微分表达式/求导/求偏导表达式。为什么需要求和？为什么会出现求和形式？：线性组合 出现、向量点乘出现、点用坐标系表达时出现、描述梯度时出现、描述点的运动速度时出现、描述坐标系变换时出现(两个在空间位置确定的坐标系,求空间上一点在两个坐标系中的各轴分量取值)。
								>下标有两个分量：表示两套分量指标。同一坐标系下/同一基矢量系的两套指标。
							>单指标的量：向量元素。两个指标不同的 单指标量相乘，结果显然应该被定义为一个双指标量--且指标就分别是这两个量的指标。
							>双指标的量：矩阵元素。
							>创新之处：将多个带不同指标的量的相乘  表达 为 一个 带所有这些指标的量。即向上 概括了以下。封装了一下，简化了一下。
					>体积元的度规：点x到x+dx之间确定的小面积或者体积或者超体积 A ，在直角坐标系下 A = dx1 dx2 dx3 ...dxn , 在其他坐标系下，根据坐标系变换规则 dx = Sdx' , 则 dx1 dx2 dx3...dxn = (ΣS1j*dxj')(ΣS2j*dxj')... = 和 S的行列式有关 = |S| dx'1 dx'2 dx'3...dx'n，另一种解释方法 ，假设系数是λ,则 dx1/dx'1 * dx2/dx'2 * ... = λ, 则发现每个元素是S的对角线元素： = S11*S22*S33*S44... = 假设S是对角矩阵--比如球坐标系中就是，很显然乘积 就是 S的行列式 |S|, 因为 G'=S^T*S, 因此 sqrt(|G'|)=|S|	, 因此 A' = sqrt(|G'|)*dx'1...=A 
					>协变导数：在计算 度规 随 坐标位置的变化 的变化程度，如 加速度的协变导数。
						>一阶张量的求导：设有一阶张量的变换关系：W'μ = S^(-1)(μ,v)*Wv  ,  则继续求导 ，即左乘 з‘λ ，从而 з‘λ*W'μ = з‘λ*(S^(-1)(μ,v)*Wv) = S(i,λ)*зi * [S^(-1)(μ,v)*Wv] = S(i,λ)*S^(-1)(μ,v)зiWv + S(i,λ)*зi)*S^(-1)(μ,v)Wv  这里因为 中括号里两个单项相乘，按照微分计算规则，需要对两个单项分别进行微分，因此展开成了两项。这样，看到 直接进行这样求导 形成的不是张量，因此 寻找另一种求导方式，使得 结果 是 符合张量定义的(形式有意义)；定义这种 求导为 Dλ， 它对 某个张量求导 的结果 满足形式：Dλ * Wμ = зλWμ + Γ(μ)(λv)*Wv 这种求导 称为 协变导数。之所以是这个名称，因为这种求导的协变形式是 D'λ*Wμ = S(i,λ)*S(-1)(μ,v)*Di*Wv  满足二阶张量的 变换关系。Γ(μ)(λv) 称为 Christoffel symbol
							>上式的说明：是基于这样的逻辑过程：假设 存在一种求导Dλ (一阶张量), 它能既能满足 张量变换关系：D'λ = S(i,j)*Dλ, 还能满足 具体作用于 另一个一阶张量 即对它进行求导时具有 D'λ W'μ = S(i,λ)*S^(-1)(μ,v)*DλWv
							>一个张量乘以另一个张量 而 形成的量：可能不是一个张量。
							>两个量相加 后乘以另一个量 而 形成的量：可能是一个张量。
							--要用坐标分量来表示的量：如速度，加速度，力，则坐标分量上的值 随着 坐标系的不同而不同。但不用坐标分量表示的量如质量、温度则跟坐标系无关。
						>Christoffel 符号：Γ(l)(i,j) = g^l * зgi/зxi  或者： зgi/зxi = gi * Γ(l)(i,j) 基矢量gi对 xi轴的偏导数 在gi上的分量 就是 Christoffel 符号。Christoffel 符号 是一个 三阶量。
							>推导过程：
								>直角坐标系：下的一个位置矢量x
								>空间曲线坐标系：空间上一点x在 这个曲线坐标系下的分量(x^1,x^2,x^3)
								>位矢：x 为一个矢量。位矢的增量/微小变化 dx = Σ зx/зxi * dxi = зx/зxi * dxi 注意,x的i在上标。
								>位矢的增量比率：gi = зx/зxi  是一个向量，沿着xi分量轴方向。称为 协变基向量。g的i在下标。则 dx = Σ gi*dxi =gi*dxi 
									>gi:曲线在x^i轴方向的弯曲程度。是向量，方向同x^i.
									>g^i: 曲线在x^i轴方向弯曲程度的倒数。是向量，方向同x^i.
									>gij: 曲线在x^i轴方向的弯曲程度向量与x^j轴方向的弯曲程度向量之点积。点积有协同的意思，所以同向最大，垂直为0.
									>gj：可以被g^i线性组合表示。gj = Σ αjr*g^r = gjr*g^r  是行的线性组合。
									>g^i: 可以被gj线性组合表示：g^i = g^(ij)*gj 也是行的线性组合。
								>距离的 表示： (ds)^2 = dx * dx =  gi dxi * gj  dxj (可以这样写因为 和的乘法 展开也是 和的每一项分别相乘对方的每一项, 所以这里也引进了新的指标来表示最终结果 的 单个结果项的一般表达式) = gi * gj dxi dxj = gij  dxi dxj  这里 gi * gj就是两个向量的点积，显然这个点积 有 i*j个,每个结果表示在一个矩阵里的一个元素，则这个矩阵定义为/称为gij。这样整个表达式的 含义 变为 对 整个矩阵 的每个元素进行求和(同时每个元素乘以dxi dxj)。又因为 gi * gj  当 i != j 时，根据垂直曲线坐标系的定义 中 的 垂直要求，则 结果=0，即 i!=j 则 gi*gj = 0 因此这个矩阵gij 是 一个对角阵。
									>如果gi 用欧式空间的直角坐标系ej 来表示： 则 gi = Σ eik* ek = eik*ek  即是直角正交基的线性组合。eik是一个矩阵的元素。用来表示 gij这个矩阵的行列式 ： |gij| = det(gij) = det(gi*gj) = det (eik*ek * ejl*el) = det(eik*ejk) 可见新矩阵的pq位置元素 是 eij矩阵的p行和q行元素的线性组合。计算它的行列式就比较麻烦。它的行列式 = (det(eij))^2 = [g1 *(g2 x g3)]^2  即为gi为棱的平行六面体的体积的平方。定义混合积 g1 *(g2 x g3) = [g1,g2,g3] 这是一种 科研 手法，就是假设引进一个 成立的 等式，尽管未证明。
									>定义逆变基向量 g^k = gi x gj / [gi,gj,gk] : 直接可以得出 g^i 和 gi 是平行的。而 g^i 和 gk 其中i!=k 则是垂直的/正交的，那么 可以得出 g^i * gj = δ(i)(j) 即 对角矩阵。δ^i,j 称为 Kronecker 符号。所以 [g^1,g^2,g^3] = (g^1 x g^2) * g^3 = 1/ [g1,g2,g3]
									>定义二阶逆变度规张量 g^(ij) = g^i * g^j  目标：计算混合积，最后会发现=sqrt(det(gij))
								>最终推导过程：
									>对gij求x^k的偏导数：зgij/зx^k = зgi/зx^k * gj + зgj/зx^k * gi , 依次轮换指标得到另外2个方程，然后 利用  зgi/зx^k = зx/(зx^i*зx^k) = зgk/зx^i 即上下标 交换后不变，可以 用 后两个方程 相加 减去 第一个方程，因为 有3对相同项，并去了2对 而合并了一对，得出 1/2 * (зgik/зx^j + зgkj/зx^i - зgij/зx^k) = gk * зgj/зx^i  然后令 зgj/зx^i = Γ(l)(i,j) * gl , 相乘得出  зgj/зx^i * gk = Γ(l)(i,j)*gkl ,  然后联系两个关系，第二个关系左侧就是 第一个关系的右侧的指标轮换形式，所以  Γ(l)(i,j) = 1/2 * (зgik/зx^j + зgkj/зx^i - зgij/зx^k) * g^(kl)
						>协变基矢量：з/зx^λ ， 满足  з/зx^λ’ = зx^λ/зx^λ' * з/зx^λ  
						>协变基矢量对坐标的导数：з/зx^μ (з/зx^λ)   用上式 四项展开后发现它不是张量。з/зx^μ‘ (з/зx^λ’) = зx^μ/зx^μ' * зx^λ/зx^λ'  з/зx^μ (з/зx^λ) + (з^2x^α/зx^λ'зx^μ')(з/зx^α) 
							>Christoffel 符号 的假定 后推导 协变导数：想 将 上式右边第二项 分解为2项，然后一项移动到左边，一项还在右边 ，然后右边两项合并为一项，然后整体是一个张量变换式，从而得出两项之和是一个张量。很自然的，为了合并，则分解出的两项中的一项必然有 зx^μ/зx^μ' * зx^λ/зx^λ' 系数，假设 (з^2x^α/зx^λ'зx^μ')(з/зx^α)  = K(α')(μ',λ') + зx^μ/зx^μ' * зx^λ/зx^λ' * K(α)(μ,λ)  则带入上式后 发现出现了张量变换式，且 з/зx^μ (з/зx^λ) - K(α)(μ,λ)  就是一个二阶协变的张量，称为 协变导数。略微变换后发现，K(α)(μ,λ) = Γ(α)(μ,λ)*з/зx^α   所以 协变导数 = з/зx^μ (з/зx^λ) - Γ(α)(μ,λ)*з/зx^α  
							>协变导数对速度： ( з/зx^μ (з/зx^λ) - Γ(α)(μ,λ)*з/зx^α  ) V =  з^2V/(зx^μ*з/зx^λ) - Γ(α)(μ,λ)*зV/зx^α  令 = 0  з^2V/(зx^μ*з/зx^λ) - Γ(α)(μ,λ)*зV/зx^α=0
							>协变导数对曲线：( з/зx^μ (з/зx^λ) - Γ(α)(μ,λ)*з/зx^α  ) s^λ = з/зx^μ (v^λ) - Γ(α)(μ,λ)*зs^λ/зx^α = dv^λ/ds * ds / зx^λ - Γ(α)(μ,λ)*зs^λ/зx^α  两边乘以зx^λ /ds后，  d^2x^λ/ds^2 - Γ(α)(μ,λ) dx^k/ds dx^λ /ds = 0 认为就是测地线方程。
						>空间的基底：每个空间都有一组基底。
						>f(x)和x(f)的等价性：因为 f和 x共同决定了一个结果：这个结果用 f(x) 来表达 还是用 x(f)来表达：结果都是确定的 且 一致的。x来自矢量空间，f来自函数空间。这两个元素 形成一个映射。矢量空间中的所有x 和 函数空间中的一个f 进行组合确定；或者函数空间中的所有f 和 矢量空间中的一个x 相组合 而确定形成 一个新的元素/新的空间中的一个元素；所有双向的组合映射，形成一个新的 矢量空间 乘以 线性空间 的 新空间。函数空间为V*,矢量空间为V,称V*是 V的对偶空间。
							>有限维矢量空间V是有基底的：标准基底 = e1,e2,e3,...;  函数空间V*也有基底：e^1,e^2,e^3...
							>利用函数空间和矢量空间的组合 来定义张量： L: V^* V^* V^* V^* ... V^* V^* V V V V ...V --> R   用计算机程序 函数定义 来表述 就是： 一个函数，入参有 r 个 参数 是 函数类型，s个参数 是 向量类型， 返回值 是 一个整数。整个函数 被称为 张量。(r,s)型张量。 其空间记作 T(r)(s)(V)
								>上式读作：L 将 V^* ...V 空间中的元素 映射 到  实数空间中的一个元素。
									>因此： x(f) 读作 ： x 将 函数空间中的f  映射 到 实数空间中的一个元素。 显然，当x是矢量空间中的一点，是满足要求的---有这种映射能力的，所以x是张量，因为 是将函数空间中的f 进行映射到R,所以 x是(1,0)张量；或者说 矢量空间 是 (1,0)张量空间T(1)(0)(V)。
										>多个函数空间：每个函数空间中的元素可以是不一样的--如函数空间中的某些元素甚至不能作用在向量上--所以这个函数空间一定是能作用在该量上的所有函数构成的空间。
									>因此： f(x) 读作： f 将 矢量空间中的x 映射 到 实数空间中的一个元素。 因为 是对 是对矢量空间进行映射，所以f 是 (0,1)张量。 f是函数空间中的一点，所以 函数空间 是 (0,1)型张量空间。即：L:V->R
										>注意：f是线性映射，不是任意函数。或者叫 任意某个 线性函数/线性泛函。
									>因此：对一个矩阵A, (采用分量分析的方式), 它是m*n阶的，对于任意一个m阶的向量v, 则 v *A = u, u是n阶的。所以一个矩阵可以实现全部m阶向量 到 n阶向量的映射： A: V->V 。。另外，对于任意一个m阶向量v和任意n阶向量u,矩阵可以实现它们到 实数R的映射：(Av)^T*u = 实数，把元素(Av)^T 当作 一个整体，它只能被认为是一个线性变换/函数(只有原始量才能被认为是矢量)，u是一个矢量，中间是点积运算，所以实现了 V^* V ->R 映射。
										>一般的：对于一个量K，都要 和 函数空间/矢量空间中的任意元素运算 一下，来看 它实现了 怎样的映射：(还是觉得矩阵实现了V V ->R的映射：A(u,v)=实数；A:V V->R；；；但是，如果认为 u是一个线性映射，而v是一个向量 则也是合理的， Au 则是将一个线性线性映射转换为另一个线性映射：V^*->V^*;所以 Au *矢量v = 实数，是 V^* v ->R的映射)
								>(r,s)张量的基底元素的个数：如果是V是n维的，则一个V空间有n个基底元素，因此(r,s)张量有 n^(r+s)个基底元素。即每个空间中的基底和其他空间中的基底构成新的基底是组合的关系。
									>张量可看作：多线性映射。即V^* V^* V^* V^*... ->V V V V...
			>转置：用矩阵的元素来描述：(Aij)^T = Aji   用张量分析的标记来做 (AB)^T = (AikBkj)^T = (Aik)^T*B(kj)^T = Bjk*Akj =B^T*A^T
			>Hadamard乘积：A ⊙ B  计算过程 为 元素 对应乘积。
			>Ax分解等值为多个向量的和/线性组合的形式：Ax = Σxj*A;j 这样， 这明显是一个线性组合的形式， 把{A;j}看作是一个基底集合，则xj就是对每个基底的放缩比例，而由放缩后的向量进行组合相加后 如果得到b,则 这个放缩就是解。一个矩阵的列向量 确定一组基底，确定 了一个 生成子空间。所以 确定Ax=b是否有解 就是 确定 b是否在 A的生成子空间中。A的生成子空间 也叫 A的 列空间 或者 A的值域。如果对任意的b都有解，则A的列空间必须可以构成整个R^m， 则A的列必须有至少m个线性无关的列。			
				>列向量 线性相关的矩阵：奇异的。				
			>范数：衡量一个向量的大小的 函数 。 L^P范数 即 向量 元素的p次方的和的开p次方。根本定义，范数 是满足这样条件的这样的函数：1.函数值=0，则向量x=0; 2.满足三角不等式：f(x+y)<=f(x) + f(y); 3.对任意α, f(αx) = α*f(x) . 
				>L^2范数的等价形式：x^T*x  也是  x的模长。
				>L^∞：最大范数。 ||x||∞ = max|xi| 
				>L^1: ||x||1 = Σ|xi| 因为 当无穷次方时，其中最大的元素 对应的值已经远远超过了其他值，其他值就可以忽略了，再开方 就是 这个最大元素；如果有多个最大元素比如k个，那么开无穷次方是 就会无限接近于1.
				>Frobenius范数：||A||F = sqrt(ΣAij^2)	
			>对角矩阵：仅主对角线上有非0元素的 矩阵。i!=j,Dij=0  。。如果对角元素构成一个向量v, 则这个对角矩阵 表示为：diag(v) 优点：逆矩阵方便计算。存在逆矩阵：对角线没有0元素，逆矩阵就是 对角线元素的导数。	
			>对称矩阵：参数顺序无关的双参数函数生成元素时，元素构成对称矩阵。
				>单位向量：模长=1； 
				>两个向量正交：x^T*y = 0 
					>标准正交：R^n中，n个向量互相正交，且范数是1。
						>正交矩阵：行向量和列向量 都 标准正交。Ai;*Aj; = δij = A*A^T = I , A;i*A;j = δij = A^T*A = I ， 所以 A^T = A^(-1)   优点：逆矩阵方便计算。 
			>特征分解：矩阵分解方法。用来发现 不明显的函数性质。矩阵分解为 一组特征向量和 特征值。			
				>如果v满足：Av = λv	， 则v称为矩阵A的特征向量，λ称为 v的特征值，因为sv对应的特征值也是λ，但是v和sv线性相关，所以 只考虑 单位特征向量。
					>假设A有n个线性无关的特征向量：{v1,v2...}, 对应的特征值{λ1, λ2...} 利用特征向量的基本性质：则 AV=A*[v1,v2...] = [Av1,Av2...]=[λ1v1, λ2v2...]= V diag(λ) 其中λ是n个特征值依次构成的向量。所以A=V diag(λ) * V^(-1) 从而 这就是 矩阵A的特征分解。此时V一定三角阵 甚至对角阵。则|V|=1
						>如果A是 实对称矩阵：则 A = QΛQ^T 其中 Q 是特征向量构成的矩阵，且 是 正交矩阵。和上式融洽的。
							>用于优化二次方程：f(x) = x^TAx  其中限制x的模长=1， 将 实对称矩阵的分解带入，则 当x 是A的特征向量时，x^TAx  = λx^Tx = λ 函数f的最大值：最大的特征值；函数f的最小值：最小的特征值。证明方法：将A分解为 QΛQ^T ,那么  x^T*QΛQ^T*x = Σλi*xi^2 ， 其中满足约束 Σxi^2=1 构造拉格朗日函数 则可以 得出 L=λi, 然后argmax L = max{λi} 得出最大值，同理得出最小值min{λi}。。。第二种证明方法：即函数的某条等值线 是一个超椭圆，而约束关系是一个超求面，容易得出极值在轴上，轴上的值就是xi=1,而其他xj=0,所以得出极值=λi 中的max/min
					>矩阵A是奇异的：则A有0特征值。	
					>矩阵A的特征值都是正数：正定的。 优点：x^T*A*x >=0 恒成立，且当且仅当x=0时 =0.
					>A的特征值非负：半正定的。
			>奇异值分解：SVD。将矩阵分解为 奇异向量和奇异值。应用更广泛。
				>实数矩阵：都有一个奇异值分解，但不一定有特征值分解--例如非方阵矩阵就没有。
				>为何可以进行奇异值分解：因为发现假定 矩阵A可以分解为 UDV^T, 其中 U是m*m正交方阵，V是n*n正交方阵，D是m*n对角阵，发现可以反过来得出矩阵A。		
					>奇异值：对角阵D对角线上的元素。
					>左奇异向量：U的列向量。是AA^T的特征向量。显然AA^T是对称矩阵。
					>右奇异向量：V的列向量。是A^T*A的特征向量。显然A^T*A是对称矩阵。
						>新问题：A^T*A的特征值和 AA^T的特征值的关系。奇异值和 这两个特征值的关系。
			>Moore-Penrose 伪逆：非方阵A: 有  Ax=y，求解x。			
				>对角矩阵的伪逆：为对 该对角矩阵 进行 对角元素 取 倒数 后 再 转置 得到的。		
				>A的伪逆：A^+ = VD^(+)U^T 		
					>用途：A的列数多于行数时，A^(+)y 是 Ax=y的所有解中欧几里得范数||x||2最小的一个。当A的行数多于列数时，可能无解。此时 A^(+)y 是 使得 Ax和y的欧几里得距离最小的x: ||Ax-y||2
			>迹运算：Tr(A)=ΣAi,i
				>用途1：矩阵的Frobenius范数(每个元素的平方的和)的表示：||A||F = sqrt(Tr(AA^T)) 
				>用途2：Tr(AB) 其中，A是m*n的，B是n*m的，则 Tr(AB) = ΣΣ Aij*Bji 先对j再对i, 而很明显这个满足 交换规律：ΣΣ Aij*Bji  = ΣΣ Bji*Aij 先对i再对j。而 ΣΣ Bji*Aij = Tr(BA) 所以： Tr(AB) = Tr(BA)
			>行列式：det(A)。det(A) = Πλi	
				>用途：行列式=0 则 有维度完全收缩了。行列式=1 则 转换保持空间体积不变。
			>主成分分析：将 R^n空间中的点x和 R^l空间中的点c进行互相映射。显然，定义D为n*l矩阵，则 Dc=x 其中 n>l, 则 D就是 解码矩阵。
				>限制条件和目标：条件：D的列向量都有单位范数；目标：计算编码器的最优编码---不是l最小可以达到多少,而是 原始向量x 和 重构向量g(c*) 的距离最小--欧几里得距离最小：即argmin ||x - g(c*)||2 其中 g(c)=Dc。显然 计算D的伪逆 而再计算 D^(+)x 是使得 Dc和x距离最小的c: 
					>增加约束条件：D中所有列向量都是正交的。则 D^T*D=I
					>对目标函数argmin ||x - g(c*)||2： 展开计算：则 argmin ||x - g(c*)||2 = argmin (x - Dc)^2 = argmin (x^Tx - 2x^T*Dc + c^TD^T*Dc) = argmin(-2x^T*Dc + c^T*c) 再使用向量微积分：
						>向量微积分：
						>用向量微积分计算上式：▽(c)(-2x^T*Dc + c^T*c) = 0  得出 -2D^Tx + 2c = 0 得出 c=D^T*x  这个 和 用 伪逆来计算稍微有差异。 从而得出了 f(c)=D^T*x, 而 g(c) = DD^T*x
					>挑选编码矩阵D: 这个矩阵应该使得 还原之后的误差最小：即 argmin sqrt(((x^i)j - (DD^T*x^i)j)^2) 待定参数为D。 即使得n个误差向量构成的误差矩阵 的Frobenius范数 最小时的D。D满足的约束就是DD^T=I
						>目标函数矩阵化： 则定义出X: xij构成的矩阵，X;i是一个样本点； 当D的维度是1时，可以 等价为：argmin ||X - Xdd^T||^2,F , subuject to d^T*d=1 ;进一步转换为迹运算，argmin Tr((X - Xdd^T)^T*(X - Xdd^T)) 展开并利用迹运算的矩阵顺序前移规律，可得 argmin -2Tr(X^T*Xdd^T) + Tr(dd^TX^TX*dd^T) 再利用 约束条件 得：argmin -Tr(X^T*Xdd^T) = argmax Tr(X^T*Xdd^T) = argmax(d^T*X^T*Xd) 这个形式就是 二次型的形式，所以 它的极大值就是 X^T*X矩阵的最大特征值，d取值就是最大特征值对应的特征向量。得到的d就是第一个主成分。其他的l-1个主成分 就是 特征值排序后更小的l-1个特征值对应的特征向量，这l个特征向量就构成了D。

		>概率和信息论：比例和组合 都是 最基础的概念。比例值 和 组合集。
			>概率论：提供量化不确定性的方法，提供导出新的不确定性声明的公理。提出不确定的声明 并在此情况下 进行推理：
			>信息论：量化 概率分布中的 不确定性 的 总量。
			>一种对 不确定性 进行 表示和推理的方法： 
				>概率：频率、信任度。频率派概率，后者涉及确定性水平--贝叶斯概率。
				>逻辑：逻辑是这样的一种思维活动： 给定若干个 真或者假 的 命题 下，使用一套形式化的规则 来 判断 另外 一些 命题是否 是真或者假。
				>概率论： 是这样的计算活动：给定若干个 命题的 似然后，使用 一套形式化的规则 来 计算 其他命题 为 真 的似然。
			>概率分布：天然的向量。
			>概率密度函数：不要求p(x)<=1 ，只要求定义域内的积分为1
			>条件概率：在A发生的条件下，B发生的概率p。即A发生的条件下，B不发生的概率为(1-p)	。
			>边缘概率：是在离散联合概率分布的场景下 计算 X=x 发生的概率。结果写在边缘上。	
			>概率的链式法则：用一个棵树 来表示 条件的发生先后关系 ：最先发生则为根节点，概率为P(A); 然后发生的B则是在根节点下延申出左节点，B在A发生的条件下发生的概率P(B|A)就写在左分支上,则A和B同时发生概率 就是先走A再走B分支 这件事 的概率=P(A,B)=P(A)*P(B|A)。同理可以从B后可以延展出更多的分支下去。这样：从A1走到最底层的An 这件事 发生的概率 = A1...An同时发生的概率 = P(A1,...An) = P(A1) * ΠP(Ai|A1,A2,...Ai-1) i 从2到n
			>独立性和条件独立性：x⊥y 表示x和y相互独立，x⊥y|z 表示x和y在给定z时条件独立。	
			>期望：函数关于某个分布的期望：Ex[f(x)] = Σf(x)P(x)		。E[.] 则是对所有随机变量的求平均。
			>方差：按照x的分布来对x采样时，取值的差异程度 有 多大的 度量。Var(f(x)) = E[(f(x) - Ex[f(x)])^2]  方差的平方根 称为 标准差。
			>协方差：两个变量 线性相关性 的 强度 。Cov(f(x),g(x)) = E[(f(x) - E[f(x)])(g(y) - E[g(y)])] 如果 f(x) 和g(x) 有线性关系，即 f(x) = ag(x) 则 带入可知 协方差 Cov(f(x), g(x)) = a*Var(g(x)) 显然方差一般不为0，所以协方差不为0；
				>函数当作向量：则x是索引，f(x) 是向量的这个索引维度的分量取值；函数向量化  则 利用向量的概念--线性相关/线性无关。
				>独立性：既无线性关系，也无非线性关系。 非线性相关：f(x) = l(g(x))
				>协方差矩阵：x ∈R^n 是随机向量，则 x的协方差矩阵：Cov(x)i,j = Cov(xi,xj)  则对角线 元 是 方差。
			>相关系数：
			>常用概率分布：
				>Bernoulli 分布：二值分布： P(x=1) = Φ,  P(x=0)=1-Φ,  P(X=x) = Φ^x(1-Φ)^(1-x) , 则 E(x) = Φ, Var(x) = Φ(1-Φ)
				>Multinouli 分布： 具有k种取值状态的变量的概率分布：
			>正态分布：N(x;μ,σ) = 1/sqrt(2πσ^2) exp(1/(2σ^2 * (x-μ)^2))  可以令 1/σ^2 = β 来 重新 表达这个式子。	
			>中心极限定理：很多 独立的 随机变量 的  和 的 分布 ：近似服从 正态分布。  
			>同一方差下 在实数上 不确定性最大的 分布： 是 正态分布。 函数的不确定性：信息熵 -P(x)*log(P(x)) 其中 Var(P(x))=σ^2， 则 argmax(-P(x)*log(P(x)))  对 P待定，即 P(X=x)=? 满足 ∫P(X=x)dx=1 且 P(X)>=0 
				>多维正态分布：其中x,μ都是向量，Σ是一个正定对称矩阵(x^T*Σ*x >=0 恒成立;对称意味着Σ^T=Σ^(-1))--也是分布的协方差矩阵:N(x;μ;Σ) = 1/sqrt((2π)^n*det(Σ)) * exp(-1/2*(x-μ)^T*Σ^(-1)*(x-μ))
					>精度矩阵： 
					>协方差矩阵固定为 对角阵： 
					>各向同性高斯分布：它的协方差矩阵 是 一个 标量 * 单位矩阵。
			>指数分布：
			>Laplace分布：1/2γ * exp(-|x-μ|/γ)
			>Dirac分布：概率集中在一点：p(x) = δ(x-μ)  是广义函数。
				>广义函数：根据 积分 性质 定义 的 数学对象。
				>经验分布：是 训练数据 的似然 最大的 概率密度函数。
			>混合模型：
				>高斯混合模型：任何平滑的概率密度函数 都可以 用 具有 足够多组件的高斯混合模型 以任意精度 来逼近。
				>先验概率：P(c=i) 观测到x之前 传递 给模型 关于 c 的信念。
				>后验概率：P(c|x) 观测到x之后 计算的。
			>有用的函数：
				>logistic sigmoid 函数： σ(x) = 1/(1 + exp(-x))  用来产生 Φ
				>softplus 函数： ζ(x) = log(1+exp(x)) 用来产生 正态分布的 β 和 σ参数。
				---二者联系：ζ(x) = ∫σ(y)dy 从 负无穷 到 x 进行积分。 所以 dζ(x)/dx = σ(x)   对数关系：log σ(x) = - ζ(-x) 
			>贝叶斯规则：需求：已知P(x|y), P(x) 时计算 P(y|x) 。 利用 联合概率关系 可得： P(x|y) = P(y|x)*P(x)/P(y) = P(y|x)*P(x)/ΣP(y|x)*P(x)
			>测度论：measure theory	
			>信息论：研究 信号 包含 多少 信息 的 度量。	对 消息 设计 最优编码 和 计算 消息 的 期望长度；
				>基本假定/认为：一个不太可能发生的事件 发生了 则 能 提供 的 信息 多于  一个 非常可能发生的 事件 发生了 而 提供的信息。
					>确保能发生的事件：则没有信息量。
					>较不可能发生的事件具有更高的信息量；
					>独立的事件有增量的信息：
				>事件的自信息：X=x 的自信息 = -logP(x)
				>香农熵：每一点处的自信息的和的平均值：H(x) = -E[logP(x)] = H[P]  熵大 则 按P生成的符号进行  编码 所需的 比特数 在平均意义上的下界。
				>KL散度：衡量X的两个分布的差异：分布之间的某种距离。
					>定义：概率密度 比值 的对数的 期望： Dkl(P||Q) = E[logP(x)/Q(x)]
				>交叉熵：H(P,Q) = H(P) + Dkl(P||Q)
		>数值计算：通过迭代过程 来 更新 解的 估计值 的 算法。 如 找 函数 的 极大值 ， 线性方程组的求解。
			>上溢和下溢：
			>softmax函数：指数值的比例：softmax(x) = exp(xi)/Σexp(xi)
			>病态条件：如 A^(-1)的  max |λi/λj| 如果很大，则 矩阵求逆很敏感。
			>基于梯度的优化方法：
				>目标函数：损失函数/误差函数。
					>最小化 目标函数： x* = argmin f(x)
				>梯度：▽x f(x) = [зf/зxi]
				>方向导数：u向量方向 的导数： зf(X+αU)/зα = зg(X1+αU1,X2+αU2,X3+αU3)/зα = Σзg/з(Xi+αUi)*Ui = 当α=0时 = Σзg/з(Xi)*Ui  = U^T * ▽x g() = U^T *  ▽x f() 其中 U^T * U = 1 和 ||▽x f()||2 = 1  所以  min U^T *  ▽x f() = min ||U^T||*||▽x f()||2*cosθ = min cosθ, 说明 当 梯度方向和 方向U相反时候 方向导数取得最小值，梯度方向和U相同的时 方向导数取得最大值；所以在X处取得一个函数值，则 在 X + (εU) = X - ε * (▽x f) 取得 临近最小的函数值， 其中 ε称为 学习率。这种在负梯度方向移动 来 寻找 函数的 极小值 的 方法 被称为 梯度下降法。
					>差积：a = (ai,aj,ak) = Σai*ei, b = (bi,bj,bk) = Σbi*ei, 则a x b = (Σai*ei)x(Σbi*ei) = aiei x bjej =ai*bj ei x ej = 因为 ei x ej = ek = - ej x ei, 且 ei x ei = 0, 所以ai*bj ei x ej = (aibj - ajbi)ek = |[i j k ;ai aj ak;bi bj bk;]| 即 是 这个三阶行列式。
					>混合积：[a,b,c] = (a x b)*c = (aibj - ajbi)ck 其中 i!=j!=k 。ijk指标取三组1,2,3;2,3,1;3,1,2; 对应的第二项2,1,3;3,2,1;1,3,2;很明显 aibjck - ajbick = ak(bicj - cjbi) = (b x c)*a = bk(aicj - cjai) = (cxa)*b  三组都是按照 1,2,3顺序轮换而来的。
					>矢量微积分：
						>定义：X(t) = (x(t), y(t), z(t)) , 则  X'(t) = (x'(t), y'(t), z'(t)) ; X(t)可以表示 空间里一点的运动轨迹，即任意时刻的位置是可以确定的，则轨迹的长度 L(t) = Σsqrt(Δx(t)^2 + Δy(t)^2 + Δz(t)^2) = Σsqrt(x'(t)^2*dt + y'(t)^2*dt + z'(t)^2*dt) = ∫sqrt(x'(t)^2 + y(t)^2 + z(t)^2)dt = ∫||X'(t)||dt
							>第一类曲线积分：已知曲线的每一点的空间位置X(t), 曲线每一点上的质量密度/线密度 f(X(t)), 则曲线的 总质量,曲线起点a,终点b，中间无数个时刻的点ti , 则 中间 t(i-1)到ti 对应的两个点X(ti-1),X(ti)之间的这段弧长dsi 用拉格朗日中值定理得：dsi = |t(ti-1) - ti|*||X'(t)|| = ||X'(t)||dt , 而这段弧长的平均线密度 = f(X(t*)) 即中间某个点的线密度，所以 这段弧长的总质量 =  ∫f(X(t))*||X'(t)||dt 
							>第二类曲线积分：已知质点的每一点的空间位置X(t), 质点在每一点上受到的力F(X(t)), 即 这是一个矢量，则 从起始点a到 终点b, F对质点做的总功W 为 计算目标。对中间 t(i-1)到ti 对应的两个点X(ti-1),X(ti)之间的这段弧向量dS = X(ti) - X(ti-1)=ΔX(t)/Δt*dt = X'(t)dt ,这段距离上的功 =F(X(t))*X'(t)dt   所以 总功 W = ∫F(X(t))*X'(t)dt   如果 t处的曲线切向量 T(t) = X'(t)/||X(t')|| 则 W = ∫F(X(t))*T(t)*||X'(t)||dt  和 上式比较，发现只有 f(X(t)) = F(X(t))*T(t) 的区别。
					>爬山算法：对应于离散空间的 梯度下降算法。
				>Jacobian 矩阵： 由 f: R^m ->R^n ， 则 f的 jacobian 矩阵 J ∈ R^(n*m)元素 Jij = зf(X)i/зxj 即 X ∈R^m, 即 输出向量的每个输出分量 对 每个输入分量的偏导数。 
					>二阶导数： 由 f: R^m ->R , 则 f的二阶导数 f'' = з/зxj * (зf/зxi) = з^2f/(зxi*зxj) 可以表明 梯度 下降 的 改善情况/力度。有这个元素 构成的矩阵 称为 Hessian 矩阵。显然是 对称矩阵。且 是 实对称矩阵，因此可以分解为 正交矩阵 作为 特征向量 和 特征值对角阵 的构成。 
						>方向导数的导数：即u向量方向的二阶导数：则 对 U^T * ▽x g() =Σзg/з(Xi)*Ui 的每一项 都需要继续 对 α求 偏导：所以 三项变为 9项， u方向的 二阶导数 = Ui * з^2g/(з(Xi)з(Xj)) * Uj = Ui * Hij * Uj = U^T * H * U  很明显 这个 是 二次型 的 表达式形式，当u是一个H的特征向量时，则 结果 就是 H的这个特征向量对应的 特征值。当U是 其他方向向量时，假设可以分解为 这些特征向量的 线性组合，实际也必然可以分解为，U = Σαi*vi ,其中 0<=αi<=1因此 这个方向上的二阶导数 就是  Σαi*λi  。显然 该方向与某个特征向量的夹角越大，则权重越大，很明显，当最大特征值的权重为1时，这个二阶导数取得最大值；而当最小特征值的权重为1时，这个二阶导数取得最小值；即 最大特征值对应的特征向量的方向 就是 二阶导数最大的方向，最小特征值对应的特征向量的方向就是二阶导数最小的方向。
					>二阶泰勒展开： f(X) ≈ f(X(0)) + (X - X(0))*^T* g  + 1/2*(X - X(0))*^T * H * (X - X(0))  
						>考虑采用新的点对函数值的影响：f(X(0)-εg) ≈ f(X(0)) - εg^T*g + 1/2*ε^2 * g^T*H*g  从而看出 增加的部分：斜率的补偿和曲率的补偿、改善、矫正。 改善的部分 的 最小值 argmin (- εg^T*g + 1/2*ε^2 * g^T*H*g) 对学习率 ε 待定，则 使得最小的ε* =  g^T*g / g^T*H*g  = 1 / g^T*H*g 这就是 最优 步长。当梯度g方向和H的最大特征值方向相同时：则此时最优步长 = 1/λmax
					>牛顿法： 
						>向量函数对向量求导数：	df(X)/dX 其实就是上面讨论过的。因为对于一个 由向量X决定的标量函数f(X)，它的极值 跟X有关，则X处的附近的向量为 X + αU, 因此 求附近向量的函数值 / 附近程度 就是 函数 关于这个向量的导数：df(X)/dX = зf(X+αU)/зα = U^T * ▽x f()
						
						
						
						





		
https://www.zhihu.com/question/20695804 张量 解释。					
https://www.docin.com/p-1150499820.html Christoffel 的推导 学报。
https://zhuanlan.zhihu.com/p/116461924 协变导数的推导 