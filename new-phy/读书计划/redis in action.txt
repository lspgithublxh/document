--------redis的处理思想都对应有 相应的“某种举动 及其导致 的问题”
>需求背景-痛点陈述：现实开发中遇到了什么痛点导致XXX的开发？  
>那么痛点的原因、产生的条件：分析是什么环境、什么动作 什么效果什么目的 等精准形容词的事实描述 导致了痛点的必然发生，难以避免？。条件-痛点。原因-结果。
>则可以消除痛点的最简单的精准事实陈述是什么：修改“条件-痛点”陈述的哪一部分就可以导致没有痛点产生。 要做的根本事情是什么：
>那么新陈述表明的解决动作是什么：
>新情况的新痛点是什么：新举动、新环境会产生的新痛点描述出来， 继续上述4条操作。

1.举动-痛点：高性能的写入系统(1000次/s)在关系型数据库中难以做到，直接的key-list存储也尚无。//可用在广告定向引擎上。	twtter分析引擎上。
	>解法/处理思想：性能-内存数据库，复制特性-扩展读性能，客户端分片-扩展写性能，独一无二的数据模型-各种数据类型.。
		>关键特性：复制、持久化、客户端分片。扩展为一个	数百GB数据，每秒处理上百万次请求的系统。
		>扩展功能：发布订阅，存储过程/脚本。
		>常见应用：搜索引擎。主存储，二级存储。
		>与memcache: 同：存储键值映射、性能高。异：redis以两种方式写入硬盘，键值对数据结构更多，单进程子进程----memcache多线程；命令仅仅增删改查等。memcache可以append字符串---当作list使用，删除使用黑名单。
		>5种数据类型：字符串、列表、集合、散列表、有序集合。有专属的命令，批量操作和不完全的事务支持。MongoDB硬盘存储。
			>对于聚合数据，redis里可以是整数或者浮点数，但是memcache就只能是整数。
			>String: 值可以是字符串，有字符串操作。值可以是整数/浮点数，可以进行自增自减操作。
				>命令：get key, del key , set key , incr key 整数自增。setex key time-long； decr key, incrby key amount , decrby key amount, incrbyfloat key amount 双精浮点数增加
					append key value, 等字符串常见操作。getbit key offset 当作二进制位串进行二进制位的设置和获取,bitcount  , bitop类似二进制位串操作。
			>List: 每个节点是字符串，可以两端压入弹出元素，可以查找删除元素，可以读取单个或者多个元素。
				>命令：lpush key obj, lpop key , rpush key obj, rpop key, lindex key i, lrange key  i j  ;ltrim key i j 修剪key为指定长度会改变数据。
						blpop key timeout 阻塞式弹出，brpop key timeout 阻塞式弹出 ；rpoplpush key1 key2 右边弹出左边压入 ； brpoplpush key1 key2 timeout 阻塞式右边弹出左边压入
			>Set: 随机取元素，集合运算-并集交集差集，添加获取移除单个元素。
				>命令：sadd key obj, srem key obj, sismember key obj, smembers key , sinter ,sunion, sdiff 集合运算。
						scard key 集合元素个数 srandmember key  count 随机返回n个元素 。 spop key 随机移除一个元素 。smove key1 key2 item 存在则转移。
						sdiff key1 key2 差集， sdiffstore dest-key key1 key2 差集存储到新的集合
			>Hash: 值就是 键值对无序集合，添加获取删除单个键值对。
				>命令：hset key sub-key val, 	hgetall key , hdel key sub-key , hincrby key sub-key val , hmset key ...批量设置,hmget key sub-key sub-key2 批量获取 
					  hlen key 获取键包含的键值对的数量 hkeys key , hvals key 获取所有的键或者所有的值。 hincrby key sub-key 子健自增
			>Zset: 值是 字符串-分值 之间的有序映射，元素顺序按照分值排序。按分值范围可以获取到元素。
				>命令：zadd key score member, zrange key i j withscores 查看索引范围内的所有成员--并且按照分值排序，zrangebyscore key scorestart scoreend withscores 按分值范围返回所有成员并且按照分值排序。zrem key member移除成员。zincrby key sub-key val 自增
						zrevrange key start end 反序取出分值最大的成员
						zinterstore dest-key key-count key1 key2 aggregate sum/min/max  求出zset中存在于set中的member并且按照原顺序输出到一个新的zset
						zremrangebyrank key start end 批量移除某个排序范围外的数据。
						zcard key 统计有序集合的元素个数。
						zcount key min max 返回分值在min-max之间的所有元素个数
						zrank key member 返回member的排名
						zrevrank key member 返回member的排名--按照分值从大到小
						zscore key member 返回member的分值
						zrange key i j withscores 返回排名在i j 之间的成员,同时还带上分值
						zrevrange key ij withscores 同上，只是排序按照分值从大到小
						zunionstore... 10000个元素需要7-8ms
						
		>其他命令：
			>设置过期时间：expire key time-long 设置多少秒后过期。只能在键的级别，不能到集合的子键级别。
						   expireat keyname timestamp 设置过期时间到某个时间戳为止。
						   persist keyname 移除键的过期时间
						   ttl keyname 查看还有多久过期。
						   pttl pexpire pexpireat 都表示时在毫秒时间戳的层次处理。
			>删除key: delete key 
			>watch:
			>multi: 开始事务
			>exec: 提交事务。
			>discard: 
			>发布和订阅：其实redis做的并不够专业，所以一般很少使用,不当作消息用---但可以wconf类似当作配置用。消息积压问题，可能会影响到正常的其他业务，导致崩溃或者被os杀死。第二是数据传输的可靠性，可能导致订阅方在短线的时候消息丢失。
				>subscribe channel1 订阅
				>psubscribe pattern 订阅给定匹配模式的所有频道//是一种好的分类方式。
				>unsubscribe channel2 取消订阅
				>punsubscribe pattern 取笑订阅给定匹配模式的所有频道。
				>publish channel message 发布消息
				----双方都必须在线，客户端不在线那么就会丢失服务端推送的消息。
			>sort: 对列表排序，对集合排序。
			
		>持久化方式：用小而紧凑的格式将内存中的数据写入磁盘----方式1：在指定时间段内有指定数量的写操作执行/ 或者使用两条命令中的一条来转储到磁盘。方式2：将修改数据库的命令都顺序追加写到一个文件里。
		>主从复制的目的：读性能和故障转移。：先全量复制，后实时发送写命令。
		>内存目的：避免update时候随机读磁盘然后又随机写。insert虽然无此问题--一般直接append.
		>网站请求中数据一致性和数据加密的保证做法：数据加密---客户端加密或者客户端请求时后端返回了加密结果---来保证没有伪造数据传过来。明文的一致性：返回客户端明文+对这个明文加密后的token，那么客户端再次将这个明文返回来的时候也必然不能对这个明文修改---因为token和明文是一致的，一个修改都要修改。 
			>使用expire还是写脚本定期删除：取决于处理要删除的数据的精细程度和删除数据的重要程度。
			>使用redis实现购物车：当然用来存储用户会话cookie信息是最好的。
			>多层级的map: 可以在键名上通过lvl1:lvl2:lvl3:...方式来实现。
		
		>数据的一致性变化：事务问题：一般是协同修改、多处联动修改、守恒式修改才会导致数据不一致性的变化。即数据库变为了一个各处数据不一致的状态。
			>中间过程的不一致：运算简单相同。
			>完全的产生脏数据：
			>开始使用：multi ...  一系列命令 exec 。redis会将命令加入到一个队列里，然后顺序执行---从而没有多处修改导致的数据一致的问题。也可以用来批量执行命令---减少网络传输时间。
			
2.举动-痛点2：数据安全和应对系统故障的办法
	>解法/处理思想：数据持久化到硬盘，复制特性--数据副本复制到附加的机器上(提升系统的性能和可靠性)，事务特性和流水线特性
		>数据持久化方法：
			>快照：某个时刻的所有数据都写入磁盘。
				>配置选项如：多久执行一次快照、 是否对快照文件压缩、。。。
				>启动方法：客户端使用bgsave命令触发主动开始创建快照；redis就会调用fork创建一个子进程，子进程是父进程的一个副本，开始共享一个内存区域，直到有一方执行了写入操作。
							客户端用save命令触发bgsave执行比如： save 60 10000 在最近一次快照后开始算起，满足60s内执行了一万次写入条件时就会导致触发bgsave命令执行。
							客户端shutdown关闭服务器时，term命令时，都会触发执行一个save命令。
							另一台redis发送sync同步命令时，执行bgsave命令。
				>性能： 每增加1GB内存，光是创建子进程就会导致系统增加大约会增加10-20ms停顿时间---不能执行任何客户端命令。而生成快照期间还会停顿。
			>AOF: 类似WAL。顺序写、追加写文件，将写命令写入只追加文件
				>配置选项如：多久同步到磁盘，AOF是否要压缩。appendfsync=always/everysec/no 中间那个相当于批量的写入命令。
				>启动方法：写入的内容先放到缓冲区，然后操作系统才决定将缓冲区数据写入磁盘，可以flush()方法触发os执行刷入操作，或者发送sync请求操作系统同步到磁盘。
				>谨慎重写配置：重写AOF到了删除旧AOF文件时可能导致操作系统hang挂起数秒。bgrewriteof 目的是减少文件大小(实现方法时去重？)
		>复制：需求来源--redis单线程---所以即使一个命令执行10ms, 每秒也只能执行100个命令。
			>主服务器：配置了dir和dbfilename等选项
			>从服务器：配置slaveof host port 那么就会连接配置的这个主服务器。也可以动态发送slaveof host port 来让该从服务器从新的主服务器开始复制，。slaveof no one停止复制。
			>从连接主的过程：从清空本地数据，发送sync/psync命令--->主开始执行bgsave命令，新的写入命令开始写入缓冲区，生成快照文件后发送给从服务器--->发送完毕后，再将缓冲区的所有命令发送给从服务器，接下来每收到一个写入命令都发送给从服务器。
				>这就要求：主服务器只使用50%内存，留下空间给bgsave生成快照和创建写命令写入的缓冲区。
			>不支持主主复制：无法区分命令来源。
			>多从连一主：如果在快照刚生成时另一个同步请求进来，则会受到相同的快照和缓冲区命令，如果刚刚发送完缓冲区命令有新同步请求，则会重新生成快照。
			>主从链：合理。从服务器还有从服务器。但从在同步主的时候在解析快照时，从会让从断开连接，从新开始同步。
			>检查主发送到了从：发送数据之后补充发送一个唯一的虚构值。
				>info命令中返回的 master_link_status=up字段可以判断从服务器是否完成同步，事先发送冗余值然后等待判断冗余值是否已经可被访问到。aof_pending_bio_fsync==0判断数据更新已经同步到了磁盘。
			>从复制和AOF中恢复数据：
				>redis-check-aof:  顺序检查aof文件中是否有损坏的命令。有会删除之后的所有命令。
				>redis-check-dump: 快照的检验--就用sha1或者sha256就可以。
		>故障转移：自动故障转移---sentinel 
			>A主B从：A挂了，那么在B上save生成快照，后scp发送给C服务器，后ssh登录C服务器，启动redis-server start , 然后退出到B服务器，执行slaveof chost cport
					另一种办法是升级B为主。
		>redis事务：
			>watch命令对键监控：如果一个事务在exec之前有另一个事务变动了监视的键，那么前一个事务exec执行时会抛出一个错误。并没有加锁，只是有变动会在exec执行错误而返回报错而选择重试，因此是乐观锁。
			>unwatch: 在watch之后，multi之前取消监控。
			>discard: 在multi之后，exec之前可以取消入队的所有命令。---相当于一种取消。
			>展示商品逻辑：卖家将自己仓库里的商品转移到市场上。市场--一个zset, 卖家的仓库---一个集合或者zset/hset 。转移动作是要分解为转出和增加两个动作的，所以要放到一个事务里。
			>购买商品逻辑：一手交钱，一手交货。钱从买家转移到卖家，货从卖家转移到买家。钱的转移是两个动作，货的转移也是两个动作，这四个动作都要在一个事务里完成。
							同时需要监视或者检查市场实时是否还有这个商品，买家实时是否还有足够的钱。监视到变化则重新购买，如果重试次数太多或者超时了，则退出--放弃此次购买。
		>非事务型流水线：往往通过批处理命令实现。毕竟multi/exec也会有代价消耗性能。第二种，就是使用pipeline流水线，队列，而不包裹multi/exec来批量发送命令---性能会比一个命令一个命令的传递快4-5倍。
		>局域网通信速度：高速网络一次来回0.015ms, 所以限制了1s内最多执行1000次调用。
		>redis性能优化：方法1-上述的非事务型流水线。
			>redis各种命令都能跑多快：redis-benchmark -c 1 -q  基本每秒30000+次。实际考虑到回复解析处理，则只有一半。
			
			
>举动-痛点3：redis作为系统的支持可以做什么
	>解法/处理思想：
		>用来记录日志：1.将日志记录到文件里，一段时间后创建新的文件---不断的轮换。2.专门的日志服务syslog, linux上是在514 tcp/udp端口监听日志消息，并且路由到磁盘上的各个日志文件，并负责日志文件的轮换和删除。
			>redis的做法：就是将日志分别存到不同的list里。还会对每个小时内产生的消息及其频次的zset进行归档---rename为另一个键.last
		>用来自动补全：给定前缀字符，搜索所有以这个前缀开头的所有子键
			>数据结构zset: 必然需要得出一个范围，前缀开始的位置，前缀结束的位置；而这两个位置的得出显然只能通过定位字符串得出，假设存在开头和末尾，那么直接搜得出两个位置，如果不存在则可以插入两个位置标记字符串，自动重排序，那么查这两个字符串的位置就是它们包围的匹配的字符串的起止了，然后删除这两个标记字符串就可以。。比如前缀为abx, 则起字符串：abw{  止字符串：abx{
		>分布式锁： 取代setex和 watch命令。因为watch不具有可扩展性(multi/exec是流水线操作，可用)。性能会随着调用方增加而快速的降低性能。
			>加锁：setnx(key, uuid) 
			>加过期时间：expire key timeout 
			>释放锁：watch key 之下进行delete key 。。watch操作同时配合执行multi/exec操作。而pipeline/execute流水线事务可以独立执行。
		>事务和锁的底层：都是阻塞机制。
			>用分布式锁的场景特征：转移数据；读取并更新数据。//同步分布式的n个进程//含有两个操作。操作前获取锁，操作后释放锁。并没有实现事务的原子性等性质，只是让每组操作依次执行。
		>分布式锁的应用：计数器信号量、延迟队列、多个接收者的消息传递系统
		>文件分发：持续的分发文件：nfs, samba。
					内容逐渐变化的文件：rsync(部分的传送和续传)。多个文件副本分发到多台机器上：bittorrent协议。
					redis: 的string可以用来存储一个日志行/若干日志行。来方便处理。
		>内容搜索引擎：
			>倒排索引/反向索引：语法分析(不用)、分词、移除停用词/非用词。。实际操作就是直接split，获取到句子的单词集合，然后移除里面的停用词。
			>搜索：单个单词：直接匹配。
				>多个单词搜索：如果不同，可以sinterstore得出交集；如果同义，叫同义词，可以sunionstore；如果包含而不包含：则sdiffstore
			>对搜索结果排序：
				>前缀排序方法2：除了在zset中插入两个元素来自动补全的搜索外，还可以将对象字符串转换为数字---比如使用128进制的ascll编码得出的数字，那么搜索匹配的时候就可以直接用整数来range了--------其实这种方法很常见。
		>广告定向：
			>广告后台是一个搜索系统：提供按位置、内容等输入信息返回广告。
				>广告索引：
			>广告计价：按浏览次数的CPC广告---广告价格*千次点击通过率*1000.。实际上通过率= 点击次数/浏览次数，所以实际上是保存这些信息到记账系统里。
			>附加值：广告各个单词在页面中的匹配次数，得出的给广告的eCPM价格加上多少增量---一个附加值：相当于是一种定向之后的效果反馈/匹配程度反馈。
		>职位推荐引擎：数据结构和可行动作。更重要的，是找到最好的最需要的最优的的定义。比如这里，就是“用户技能最匹配的职位中(匹配有个匹配分值)前n个待遇公司最好的职位/得分最高的职位”.----职位匹配得分最高的top20职位按职位得分高低排序。或者多级排序--高层类别少大类区分底层类别多小类区分。中间是技能得分和待遇得分。
			>找到概念/功能/工具的最优的的定义之后，再想它的数据结构和可行动作之实现。
			>买卖双方：交易双方：是一个互相推荐/互相选择的过程。有选择有互选的场景就有推荐。
		>社交系统：微博/朋友圈：用户发消息，跟随者可看，可看跟随的人的消息。
			>用户表、消息表；(散列)；用户-消息表(列表/有序集合); 用户-跟随者表,用户-关注表(有序集合)
			>设计功能：新增用户删除用户，发布消息删除消息；关注用户取消关注；
			>流API：并不是普通API一样调用一次就返回一次。websocket 和 spdy技术不成熟。使用分块传输编码，则http服务器可以生成并发送增量式数据----分块是一种http中的一种传输编码：transfer-encoding: chuked。
		>---数学、物理、工程项目、技术：都是逻辑思维和想象力的概念思考活动。逻辑群的新增和删除。快就是慢。慢就是快。问题目标过程描述清楚，方案才能清楚。
				
				
举动-痛点4：降低redis的内存占用，扩展redis的读负载和写负载、使用Lua语言进行脚本编程。
	>解法/处理思想：
		>存储结构：列表、哈希、有序集合是逻辑结构。底层结构：在存储量小或者长度小的时候，采用了压缩列表的紧凑存储方式。
			>正常情况：列表---双链表存储，散列---散列表，有序集合--散列表+跳跃表
				>双向链表：中间是一个指向字符串结构的指针，字符串结构：三部分：字符串长度+剩余空间+字符串本身(空字符结尾\0)
				
			>压缩列表：序列化的存储方式。先编码后存储，读取后先解码。节点量限制不能太多的原因：内存复制消耗内存和cpu
				>列表的压缩列表：一字节的上一个节点长度、一字节的本节点字符长度、本节点字符串。三部分构成。即额外的开销只有2字节。
				 >使用条件：查配置list-max-ziplist-value 的值，默认64, 三种结构都是，即超过64字节的字符串就会采用其他存储结构。节点数量一般是512个为临界点。	
				>集合的压缩列表：整数集合intset
				 >使用条件：节点元素512为最多个数。更多之后会被转换为hashtable哈希表。。
		>分片：	pre-shard预先分片256个。根据不同的分片id返回不同的连接。get_sharded_connection。。分片存储，主从从树形结构。只读从服务器
			>对散列分片：hset shard key value 数据存储到不同redis实例上。
				>计算键的整数值：字符串采用CRC32计算，而不用md5,sha1之类。得出的数%分片总数 得出分片id
		>打包存储：即值采用字符串拼接存储。使用setrange, getrange, getbit, setbit等命令实现。bitcount ,bittop。。
		>Lua脚本：取代流水事务线和锁、信号量
			>python调用方式：将脚本生成sha1校验和---script load命令，再用这个校验和 + 参数 来调用这个脚本：evalsha命令  eval命令对脚本。
			>要求：脚本访问的所有键必须要在同一台服务器上。
			>redis原子性的原因：一次只能执行一个命令，或一个脚本。
			>限制脚本运行时间：lun-time-limit 杀死脚本：script kill 
			>脚本好处：为什么要使用脚本。减少通信时间和watch/multi/exec事务冲突。
			>锁的实现：普通就是setnx成功后exipre失效时间设置。lua中使用setex 命令。释放锁：get键之后del键。。时间性能更好。
			>信号量的实现：普通就是往zset里添加一个键，值为当前时间，；每次先移除过期的键，添加成功并且排名在信号量个数以内则成功。
							Lua脚本方式：先移除过期的键，再看zset的个数是否超过Limit, 如果没有则添加键。zadd如果键存在会实现更新的效果。
			>自动补全：Lua脚本方式完全就是正常处理的转移到服务端执行，减少了通信次数。确定起止元素, 添加起止元素,获取起止index, 移除起止元素，range起止index所有元素。
						但是Lua脚本不需要在 获取起止index之前watch 这个zset键。
			>买卖交易：正常：加锁、资金转移、商品转移、释放锁。Lua脚本，则整个过程在服务端执行，只需要传递双方、商品id等参数就可。
			>键太多：则要分片存储了，不受限于单台机器的内存。
			>windows上不适合的原因：没有fork调用，导致redis持久化的时候就只能阻塞所有的客户端。即不能后台保存。虽然尝试用线程替代子进程，但是微软仅仅提供源码。