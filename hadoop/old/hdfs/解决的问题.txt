1.磁盘块：512B （一次读写若干个磁盘块来运作磁盘的）
  块的大小影响磁头寻址。太小，则不好寻址，因为更小的步长。
  一次寻址的时间如果有10ms,那么这个时间内可以从磁盘传输1MB的数据了。
  不要把大多数时间用来寻址，比如如果文件块只有1MB。那么50%时间都用来寻址了！！。如果文件块有100MB，那么只有1%时间用来寻址。 
  但文件块太大则丧失了并发处理的机会，不能利用好其他节点完成之后的空闲时机。

2.HDFS块：64MB
  读出一个文件块，大约0.64s。寻址0.01s。

3.常见的配置：
  3.1 fs.default.name=hdfs://localhost/  默认的文件系统,默认端口8020
  3.2 dfs.replication=1 文件块的冗余量：为3则复制三份备份到三个数据节点。

4.常见的分布式文件操作：hadoop fs -help
  4.1 读取文件
     URL类打开一个文件流
     hadoop URLCat hdfs://localhost/user/tom/quangle.txt
     FileSystem类也可以打开一个文件流，用FSDataOutputStream可以详细控制这个流。
     FileStatus可以列出文件目录。

  4.2 创建目录
  4.3 移动文件
  4.4 删除文件
  4.5 列出索引目录
  4.6 上传文件、下载文件
     hadoop fs -copyFromLocal input/docs/quangle.txt hdfs://localhost/user/tom/quangle.txt
     hadoop fs -copyToLocal quangle.txt quangle.copy.txt
5.常见配置文件：
 5.1 core-site.xml

6.Hadoop有JAVA编写，文件系统间的相互作用由Java API进行的。
  其他语言通过运行Thrift 服务的java服务器来间接访问到hdfs。或者jni方式调用java客户端。
 其次，hdfs提供了通过http访问的web服务器，通过节点上的web服务器，可以访问到节点上的资源。
  
7.javaAPI

8.网络拓扑（节点之间的网络距离）：
  数据中心d/机架r/节点n/进程
  备份往往自己节点上放一份，其他机架上的若干个节点上各放一个备份。
 

9.文件归档
  文件夹可以归档为har文件，可以作为mapreduce的输入。

10.数据节点收到数据之后：
   会校验数据的正确性，校验和
   会定期检测数据块的完整性，是否有物理损坏。

11.文件压缩和解压
   也可以对mapreduce的输出结果进行压缩。有专门的命令和工具类。

12.序列化
   目的是实现rpc调用时传输数据需要的字符串化数据和恢复数据。
   Writable接口
   很多类都是只能从流里读取数据，不能直接从文件中读取数据，比如Writable的实现类读取数据的方法。流是一种特殊的数据结构，是一个中间的概念，是数据的中间状态。（就像大多数人不能吃生肉，肉必须转换为另一种状态---熟的状态，而输的状态的肉可以被人使用并）转化为另一种状态--比如co2和h2o等
  而流能够从文件中读取数据，也能写入文件。
  ----流的本质是什么？是字节数组的包装类。字节数组的工具类。
   ---int, long ,string等各种类型的数据都有对应的hadoop序列化工具类。集合也有。
 12.2序列化文件：
    SequenceFile类，以键值对的形式加入到它内部。写入和读取序列化文件。
    MapFile类也是序列化文件的工具类，不同的工具类使得序列化文件中的内容是不一样的。



 

13.不同节点的进程之间的通信：
   使用RPC方式:
  
  
