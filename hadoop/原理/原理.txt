1.各个节点之间的通信协议、端口（ip当然考虑）：
   NameNode\JobTracker
   DataNode\TaskTracker

2.NameNode负责做什么？功能是什么？做哪些事？按场景（活动）一一描述：


3.DataNode负责做什么？负责哪些事？做什么事？按场景（活动）一一描述：


4.解决常见的几个分布式问题的方法：
  4.1 硬件故障（节点起不来了，挂了）：如何知道，各个节点上的各个“大文件”部分文件块具体怎么备份和复制冗余。以后又怎么做？
     ---我的观点：a.多个节点互相冗余、每个工作节点有备份节点（只是未工作、未启动）
		  b.DataNode节点主动发送心跳给NameNode,或者NameNode周期高频地ping各个节点。没心跳、ping不通则认为挂了。
  		  c.NameNode检测知道DataNode挂了之后，在自己的“大文件”管理器里搜索，得知该DataNode的存储的全部文件块以及这些文件块的备份文件块在另外的哪些节点上，NameNode再逐个文件块地通知有备份的活着的DataNode启用该文件块，自己不使用则传给活跃的机器使用。
     ---hadoop:

  4.2 一个大的文件，怎么拆分，拆分后的各部分在具体节点上又怎么被接管、被保存的？（如何保证存储的正确、成功）
     ---I:a.Hadoop有定义自己大小、格式的文件块
	  b.NameNode负责对用户上传的文件有序加工生成一个一个标准的文件块，并发送给节点DataNode,节点返回它对收到的文件块存储成功的这个文件块在它内部的“文件路径”的hash值。NameNode保存文件块id和这个返回的路径hash值，放在“大文件”（可以是一个路径值）下（“大文件”对应的集合中）。
	  c.DataNode对接收到的文件块进行存储和备份。存储格式应该和一般文件一样（windows下或者linux下）。。
	  d.NameNode还对每个文件块进行备份式存储在不同的节点上（当然告知节点，传过来的这个文件块是备份块，要当做备份看待。先不激活，以后“我”通知你时才激活）。		
     ---H: 

  4.3 一次查询、计算，如何分解到各个节点的、哪些节点的？又是怎么把不同步的结果有序合并起来的？（如何保证查询的正确、成功）
      ---I: a.下载一个大文件，其实没必要。也不是最好的事情，虽然比一般的快，但是是单一文件。最好是从中查找、匹配、统计什么数据，才是善长的。
	    b.读取一个大文件，NameNode可以找到该大文件对应的集合--里面存了文件块id和路径hash和节点ip根据这个NameNode请求各个节点返回相应的文件块并根据文件块id顺序合并为大文件。
	    c. 对计算任务，DataNode的事情不是找到那个文件块再输出到NameNode就完事了。而是要先对这个文件块计算，map-reduce中，map阶段是在DataNode节点完成的，NameNode节点进行combine和reduce两大操作！
	    d. 客户端读取文件时，从NameNode只获取了各个块的数据节点地址，而实际上读取数据是直接从各个数据节点进行的，数据节点能够做到，同时各个节点也就并行操作。加快了传输速度！！
      ---H:
  4.4 写文件：
      ---I: a是客户端本身的JVM中生成了hdfs文件块，后直接发送到数据节点上，而同时发送这个文件块的路径和存储节点信息到NameNode名称节点的。



5.常见的各种技术的极限：
  5.1磁盘寻址的速度很慢，即移动磁头的速度和传输数据的速度差距太大，有个极限。
  5.2 关系型数据库不能线性收缩、数据大小受限。mapreduce只能一次写，只能批处理不能交互访问，数据结构为非结构化的没有结构的一堆数据：如文本和图像，不像oracle之类是按照键值对明确的来存储的，是结构化数据，同时又是线性数据（单一键值对，没有数组、对象）。
  

6.mapreduce设计目的：
  运行需要数分钟或者数小时的作业。

7.mapreduce过程：
  1)jobtracker构造任务，将信息发送给一个一个的tasktracker
  2）tasktracker从共享文件系统中获取到任务jar文件，输入文件从分布式缓存复制到这里。
  3)tasktracker解压jar，创建一个新的TaskRunner实例，实例启动新的子JVM来运行一个任务，这个子JVM进程通过umbilical接口和父进程tasktracker通信。
  

8.软件技术书大量的内容：都是对程序的描述，看这种书没有意义，没有任何意思，且没有价值，直接看源码，或者思考想象其算法、协议、规则才更有价值！！


