1.配置文件：
 默认属性配置文件：core-default.xml
  特定重新配置文件：core-site.xml
  具体格式：
  <configuration>
     <property>
      <name></>
       <value></>
	</>
    </>
  访问配置文件的类：Configuration  方法：addResource("///.xml");


2.安装：
   参考资料：http://blog.csdn.net/stark_summer/article/details/42424279   tar -xzvf hadoop-2.8.0.tar.gz
		http://www.cnblogs.com/tec-vegetables/p/3778358.html  可以看wordcount程序
		http://blog.csdn.net/u012859691/article/details/44178971 可以看jps
		http://www.linuxdiyf.com/linux/27981.html
		http://blog.csdn.net/mark_lq/article/details/53384358可以看浏览器
                http://hadoop.apache.org/docs/r2.8.0/hadoop-project-dist/hadoop-common/ClusterSetup.html可以看详细的参数配置、命令含义、资源网站地址。

   ssh安装资料：http://www.cnblogs.com/yangyquin/p/5021070.html

3.ssh无密码登录：
   3.1>lixiaohai创建目录.ssh   不能sudo
 //  >授权sudo usermod -g root lixiaohai
 //  >关键是要授权.ssh 777的权限。才可以执行下面的语句在lixiaohai用户下。
   3.2>ssh-keygen -t rsa
   3.3>cp id_rsa.pub authorized_keys 
   >sudo apt-get install openssh-client （一般用户都没有安装openssh-client，所以要专门安装一下。）
   3.4>ssh localhost //之后输入yes,回答后。不需要密码就进去了。就welcome了。 
   3.5>scp authorized_keys lixiaohai@192.168.180.132:/home/lixiaohai/远程复制文件过去。
   3.6>转到132上，cat authorized_keys >> .ssh/authorized_keys   
   3.7>转到133上，ssh lixiaohai@192.168.180.132 远程登录：。直接进入。
   >exit 退出。
   
4.集群需要配置的文件：
4.0 hostname主机名 和hosts主机名与ip的映射（master,slave）（需要重启）
    而且要非常严格
4.1 ssh无密码登录环境的建立（master可以无密码访问到slave即可）
4.2 主要配置文件的配置：(master)
~/hadoop/etc/hadoop/hadoop-env.sh  //配置java_home     和export HADOOP_OPTS="-Djava.library.path=${HADOOP_HOME}/lib/native"
~/hadoop/etc/hadoop/yarn-env.sh  //配置java_home
~/hadoop/etc/hadoop/slaves   //添加slaves节点
~/hadoop/etc/hadoop/core-site.xml  //配置namenode访问路径：fs.default.name
~/hadoop/etc/hadoop/hdfs-site.xml //配置每个slave节点的日志本地路径、数据本地路径、备份数。（子节点中不能有这些信息，要删除）（主节点：hdfs-site.xml.template重命名为hdfs-site.xml也可以）
				  //或者说配置namenode的通信文件夹和datanode的通信文件夹
~/hadoop/etc/hadoop/mapred-site.xml//配置job tracker访问路径：mapred.job.tracker  
~/hadoop/etc/hadoop/yarn-site.xml
4.3 slaves文件的配置(master)
4.4创建数据节点 /hadoop/tmp /dfs/data /dfs/name

-----master将配置文件发送到各个slave。再移动文件位置，使得etc/hosts文件和hadoop文件的路径一样。
-----添加HADOOP_HOME路径到profile和PATH里

---主节点：关闭、格式化、启动（会触发启动所有从节点的hadoop）（./stop-all.sh和sudo ./stop-all.sh不是权限区别，问题大不一样，）
   ./stop-all.sh
   ./hdfs namenode -format
   ./start-all.sh
   jps查看进程信息。

---主节点：上传测试文件、运行wordcount程序测试、查看运行结果

  
export HADOOP_HOME=/home/lixiaohai/opt/hadoop-2.8.0
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_YARN_HOME=$HADOOP_HOME
export YARN_HOME=$HADOOP_HOME
export JAVA_LIBRARY_PATH=$HADOOP_HOME/lib/native
export YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop
export HADOOP_PREFIX=$HADOOP_HOME
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop 
export HADOOP_ROOT_LOGGER=DEBUG,console
export CLASSPATH=.:$JAVA_HOME/lib:$HADOOP_HOME/lib:$CLASSPATH
export PATH=$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH

注意：hadoop-env.sh中的java_home一定要和/etc/profile里面的java_home一样。
      另外，/etc/hosts里面有127.0.1.1 ubuntu这个配置，要改变，因为会被hadoop mapreduce利用。
     在者，每次重启后，要关闭防火墙
   sudo mv jdk1.8.0_131/ /usr/local/这种最后一级不是本用户建立的，移动会移动里面的内容，文件夹不会保留，。（从用户文件夹到根用户文件夹。而不跨越用户则会暴露包）
   sudo mv jdk1.8.0_131/ /usr/local/java/   这种就会保留文件夹。因为java文件夹是本用户建立的，sudo mkdir也是自己建立。但是也不一定，/opt下就可以还是保留了文件夹。
5.查看集群和上传任务：


6.文件操作：参考资料：http://blog.csdn.net/qq_32166627/article/details/53302903
   ./hadoop fs -mkdir /user 根目录下创建目录
   ./hadoop fs -ls /  查看根目录下的内容
   ./bin/hadoop fs -put ~/opt/taskl/words.txt /user/  上传文件
   ./bin/hadoop fs -get /output/part-r-00000 /home/lixiaohai/opt/taskl/  下载文件

7.mapreduce操作：
  ./hadoop dfsadmin -safemode leave 安全模式每次启动都要执行。可以不执行。
  ./hadoop jar ~/opt/hadoop-2.8.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.0.jar wordcount /user/ /output
 ./bin/hadoop jar ../jar/javahadoop-1.0-SNAPSHOT.jar com.hadoop.test.WordsCount /user/ /output2
  》查看结果：./bin/hadoop fs -cat /output/part-r-00000
  》查看各个节点上的各个任务运行日志：lixiaohai@S1PA222:~/opt/hadoop-2.8.0/logs/userlogs/application_1495883797210_0003/container_1495883797210_0003_01_000001
     其中stdout是System.out.print()打印的结果。各个节点上都可以看得到，而且每个节点的container 的id是不会重复的，虽然一个节点可能有多个。


8.问题：
  8.1要保证namenode下:  dfs/name/current/VERSION 和datanode下： dfs/data/current/VERSION 中的clusterID一样。
  8.2尤其/etc/hosts里面127.0.1.1   localhost.localdomain   localhost这一行配置。
  8.3 dfs.namenode.name.dir 是最新的，dfs.name.dir不是。
  8.4 namenode 启动三个线程，datanode启动2个线程。则已经表示启动了yarn。可以进行mapreduce任务的执行。
  8.5 DataNode NodeManager有手动启动的命令

9.动态新增节点：http://blog.csdn.net/mark_lq/article/details/53393081
  》基本安装、ssh无密码登录配置
  》hosts hostsname jdk安装 hadoop安装和建立文件夹和scp 传配置文件
  》更改自身配置文件和其他机器上的配置文件。其他机器hosts。。
  ----其实，如果文件夹结构都一致（三个数据文件夹和一个主程序hadoop-2.8.0路径），那么只配置每个机器上的hosts。master再配置slaves即可。因为配置文件没有关于节点的配置信息，否则10000个节点怎么加？是不可能的。
  ----也说明了每个节点不会直接就知道和其他节点打交道，甚至不直接和其他节点打交道，只和master打交道，仅仅知道其他节点的ip而已。
  ----也说明节点可以自己启动自己，然后master知道了。
      ./sbin/hadoop-daemon.sh start datanode
     ./sbin/yarn-daemon.sh start nodemanager

10.java api 参考资料：http://hadoop.apache.org/docs/r2.8.0/hadoop-project-dist/hadoop-common/filesystem/index.html

11.查看master的状态信息：http://hadoop.apache.org/docs/r2.8.0/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapredAppMasterRest.html
    有详细的http rest请求-响应格式。
    》专门运行mapreduce:http://hadoop.apache.org/docs/r2.8.0/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapredCommands.html

12.编写自己的mapreduce程序，打包为jar,并发送到hadoop集群运行。
   参考资料：http://blog.csdn.net/zhangt85/article/details/42077281
   详细的：http://hadoop.apache.org/docs/r2.6.0/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html
   12.1命令与jar包的关系
      》执行hadoop jar命令，本质上是会执行jar包中的指定类中的main方法的，而hadoop jar命令中的参数就会传入main函数的args参数组中，而这些参数可以用来设置像FileInputFormat的输入路径和FileOutputFormat的输出路径的属性。
      》因为根本无法从jar包MANIFEST.MF这种文件中获知主类是哪个，所以只有在hadoop jar命令中明确写出这个主类的名称，且这个主类名称不会被当做参数传递到该主类的main方法的args中。
      》在main中执行的事情主要是设置Job对象的各个参数，然后会发送提交这个Job对象，集群就开始执行这个job了。
   

        