1.spring补充：
	>ioc: 自动绑定@Autowired的生效的过程：
		>所在类先实例化，在填充属性这一步：会先获取这个类的全部 自动绑定域 + 自动绑定方法，然后对每个自动绑定对象，调用它的@inject()来获取对象来进行绑定。
			>绑定方式：如 获取对象，反射设置Field里；如 获取对象，反射调用 Method方法；
				>获取对象：使用 CommonAnnotationBeanPostProcessor 对象， 会发现它 使用了 jndi机制来获取的：this.jndiFactory.getBean(element.mappedName, element.lookupType)
					>采用@Resource注解更是如此：在其@buildResourceMetadata()方法里，逐个属性获取时，确实使用了@Resource.class。 第二种是：@javax.xml.ws.WebServiceRef， 第三种注解是：@javax.ejb.EJB
						>这种ResourceElement 方式就是先jndifactory(SimpleJndiBeanFactory),再 beanfactory 
							>查找：java:comp/env/xxx
				>获取对象2： 还是使用 beanFactory.getBean(beanName)
		>@Autowired按照类型；@Resource按照变量名称;		
		
2.Mybatis的生效过程：
	>猜测：@MapperScan注解--->注解的参数指明的包路径，下去找所有的.mapper文件--->.mapper文件表明的关联的Mapper interface接口--->创建interface的动态代理-->动态代理注册到spring容器
	
3.dubbo的生效过程：
	>客户端猜测： @EnableDubbo注解+@ImportResource("classpath:dubbo-consumer.xml") -->会从classpath的所有jar里寻找 而从某个包下找到dubbo-consumer.xml而加载和解析--->解析后知道：所有的服务端需要的配置；第二，解析所有的"服务id --- 服务接口"，建立这个服务接口的动态代理，将动态代理注册到spring容器；则@Resource指明接口类型的变量，就注入了这个动态代理了；
	>服务端猜测： @EnableDubbo注解+@ImportResource("classpath:dubbo-provider.xml") -->会从classpath 如当前jar的resources路径下找到dubbo-provider.xml而加载和解析--->解析后做的事情：从本项目中找到 各个接口的实现类，然后实例化，注册到spring容器，并且建立：接口--实现类实例  的 映射map ---> dubbo服务端 本身有的模块 就是 接收rpc请求，找到请求接口---从而映射到实例，然后方法名找到这个实例类的方法反射集合--找到方法Mehtod匹配的，反射调用来执行；结果返回了；
	
4.shardingsphere的使用和架构：
	>模块：
		>sharding-jdbc: oltp应用使用
		>sharding-proxy: olap应用使用. 可以控制台 mysql 命令直接连接；
	>场景：
		>数据分片：
			>分库&分表：
				>数据分片-垂直分片：不同业务的表放在不同数据库，相同业务的表在相同的数据库；如订单表和用户表；压力分散；
				>数据分片-水平分片：某个字段/些字段的值的规律特征 进行分散 ，将行数据分散到不同的数据库/表中存储；如按照主键的奇偶分散到不同表/库；突破单机数据量的瓶颈；
					>新挑战：SQL的调整；跨库事务；
						>问题1：对join两张表后的范围查询：两张表都进行了分表，那么一般就要，笛卡尔积，A表的所有分表都要和B表的所有分表分别join来查结果；
							>方案1：配置绑定表关系，如按照相同的key来分表；则A_0表和B_0表其实都存key集合相同的数据；那么只需要一对一关联即可；
							>补充方案1：字典表--方便关联查询；
					>分表分库主键hash策略：奇偶、尾数(对10的指数取模)、SQL Hint强制分片、
						>数据源分片策略：定位到目标数据源；数据库；
						>表分片策略：定位到目标表；
					>分片的过程： 字段值-->hash函数处理结果--> = --> 某个值 --> 值-表映射，范围-表映射 
						>确定分表查询sql集合：
						>确定分表查询sql所对应的库：可以避免全库操作，全分库都操作；
					>Groovy语法：行表达式
						>解析为 展开出全部的字符集合：${['online', 'offline']}_table${1..3} 这个就会返回 2*3个名称；即为真实数据表、分表的名称；
							>又如：ds${id % 10}
					>不同数据节点的全局唯一主键：
						>生成方案：
							>如果约束初始值和步长：则缺乏完整性和可扩展性；
							>方案1：应用端Util + mysql中一张配置表： 
								>Util: 用自己ip查配置表 获取 分配的id; 如果 ip不存在，则插入一条记录，id值自增即可/唯一保证即可; 返回这个id值；再本地使用雪花算法生成唯一id: 时间戳13位_id10位_本机自增id6位；；但是2^64总共为>10^19的数据量；其实足够了！
									>时间戳表示的漏洞：时间戳本身是毫秒数，这个是客观值；但是这个整数值用二进制来表示：实际上只需要log(10^13) = 13*log10>42 bit即可，连一个long型整数都不到；所以long可以表示时间戳--且绰绰有余，因此可以增加机器id部分和序列部分；即使用41bit来表示时间，那么这个空间下可以表示的毫秒数为：2^41/一年的毫秒数 结果大约69年，足够！则剩下23位用来表示id+自增足够：如10位id,则1024个进程，序号自增12位，则4048位；。这两个也可以调整，节点如果更多，序号更少，反正1ms总共有409w左右的唯一数生成；那么1s内可以40亿唯一数生成；
									>雪花算法：
								>配置表：ip--序号id 的映射表；
					>分片流程：实现
						>SQL解析：词法分析--归类为关键字/表达式/字面量/操作符，语法分析---得出SQL的各个部分；
							>SQL解析引擎：PreparedStatement + ANTLR；以前Druid
						>执行器优化：正确性改写 和 优化改写
							>正确性改写：逻辑表名改为实际分库表名
								>补列：如avg函数的查询，分散后的统计则需要分别计算总量和总个数；order by的列不在select后，也需要；insert没有写自增主键，则需要改写加自增列；
								>分页问题：记录上次页之后各个表的偏移量？下次，从这些偏移量开始读取10条 来合并，后更新各个偏移量；
									>按照ID分页：如where id > 10 and id < 20而不是用 limit 
						>SQL路由：路由路径生成；
							>路由引擎：根据解析上下文匹配数据库和表，生成路由路径；(路由，就是要确定在哪些实际表上执行)
								>弹性伸缩：自动由数据库中间层分片；
								>分片键的值来源：既可以是sql中的，也可以直接指定； 	
								>携带分片键的路由：
									>标准路由：
									>笛卡尔路由：
								>不携带分片键的路由：
									>全库路由：set autocommit=0;这种语句，全部实际库都要执行；
									>全实例路由：create user customer@127.0.0.1 identified by '123';则所有的实例上都会执行；
						>SQL改写：改写为真实数据库可以正确执行的语句；//逻辑表改为实际表
						>SQL执行：多线程执行器异步执行；
							>执行引擎模式：
								>内存限制模式：流式归并；即并行向数据库请求，将结果集先到先合并，且维持连接，可以移动游标获取更多的数据；保证可以被更多的应用使用；
								>连接限制模式：每个库一个数据库连接；
								--设置最大数据库连接数：可能导致死锁；如最大2个，并发时，A获取了1个，B获取了1个， 又都需要2个连接而等待获取，则死锁等待；
						>结果归并：流式归并 	
							>流式归并：从数据库逐条返回，
								>流式分组归并：每个有序结果集合，都给一个指针，则将集合按照指向的元素排序，最前的那个集合的元素，就是本轮取出的元素，同时会读取出全部的指针指向的元素，如果相同则合并相关字段；合并完成作为输出；该指针指向下一个元素，重新插入排序--看在哪个位置(优先队列方式|最小堆方式)；完成后则继续取下一个最小元素来统计合并；
							>内存归并：先获取到内存中，再统一分组排序聚合；
							>装饰者归并：
					>使用规范：
						>子查询慎重：
						>insert select:需要同一张表 或者绑定表
						>replace select : 需要同一张表，或者绑定表
						>union不支持：
						>*和函数慎用：
			>读写分离：SQL语义分析, 将请求路由到主库或者从库；每个分片都可以有：主-从；
				>当前支持：一主多从
				>SQL透传：
				>特殊路由场景：
					>同一线程内：同一数据库，先写后读，则读会在主库上，来保证一致性；
					>基于Hint的强制主库路由：
			>分片策略定制化：
			>无中心化分布式主键：
		>分布式事务：
			>标准化事务接口：
			>XA强一致事务：
				>XAShardingTransactionManager 为全局事务创建、回滚、提交的命令发出者：发给XA事务管理器
				>XA事务管理器：通过SPI机制加载具体的实现类实例；接收XASTM的全局事务创建，接收客户端注册的XAResource；收到开始命令，则向XAResource发送XAResource.start命令；收到提交命令，则向XAResource发送XAResource.end命令；接着发送prepare命令，看是否准备好，如果都返回OK,则发送commit最终提交；有不OK的，发送rollback指令；；异常XAResource通过恢复日志恢复；
			>柔性事务：
				>SEATA 柔性事务：三大部分：TM\TC\RM
					>TM：应用端调用，发送给TC全局事务创建、回滚或者提交的命令；
					>TC: 创建全局事务，给定XID, 对应用端的RM的分事务的注册请求，管理；并且在收到TM的回滚/提交命令时，回调通知所有的RM回滚/提交分支事务；
					>RM: 负责向其对应的数据库开启事务/提交事务/回滚事务；即分事务的各自处理；也发送particepate命令给TC来处理；
		>数据库治理：
			>分布式治理：配置一致、状态一致、可观测性、高可用性；
				>治理：
					>全局事件通知机制：
					>独占性操作的分布式协调锁机制(不同节点之间统一协调、策略与规则的同步)：zk/etcd实现配置同步、状态变更的通知；
					>目标：
						>配置中心：
							>数据源的配置：路径：config/schema/schemeName/datasource 内容格式：yaml
							>规则配置：数据分片，读写分离，影子库压测、多副本；
						>注册中心:
							>对各个实例节点的注册和心跳监测：状态监控；
						>元数据中心:
							数据源的表、列、索引：元数据配置；
						---第三方组件依赖：通过SPI引入调用。不同的配置中心实现：如zk/etcd/apollo
				>可观测性：
					>tracing和APM的支持：
						>调用链展示：可视化(SQL解析情况也可以看)
							>使用OpenTracing API 发送性能追踪数据：则支持OpenTracing协议的产品如skywalking,zipkin,jeager
							>自动探针：
						>应用拓扑分析：
					>实现Metric指标监控和Prometheus,grafana的支持：实现实时监控；
						>监控指标：数据库运行状态、连接数据、事务数、吞吐量；
						>定义的一套SPI标准：
				>集群管理：
					>管理集群状态：集群拓扑图：
						>集群内节点状态和节点之间的网络通信情况：基于以下心跳信息，生成集群拓扑图；直观展示节点状态和数据库节点与应用的连接状态；实时展示，实时变更；
					>状态监测与更新：心跳机制
						>心跳监测：保存到注册中心；
			>弹性伸缩：单数据库数据迁移 ， 现有分片集群扩容缩容；
				>挑战1：弹性伸缩过程中数据不可用
				>挑战2：保证数据的可用性和正确性；
				>过程：数据的旧分片规则--->数据的新分片规则
					>存量数据迁移：开始迁移时的所有数据
					>增量数据同步：存量开始到完成时的所有数据。。此时要求：数据不可用(不可写)？然后迁移完成后，数据验证后才可用？或者记录位置，而继续“存量迁移”-->直到数据量足够小(才不走存量迁移逻辑)---而才真正数据不可用---使得这个时间最短！
						>具体对MySQL：订阅并解析 binlog
			>可视化链路追踪：
			>数据加密：
			>影子库压测：
			>多副本：
	>数据库背景：
		>单一数据库实例的数据的阈值：1TB内
	>实践操作：
		>分库分表：配置多个数据源 + 每张表的分库分表策略 + 表绑定关系
5.spring-boot的启动过程：
	>
6.spring 补充：
	>aop:
		>解决循环依赖问题：即 最复杂场景下的处理方案：
			>创建实例A-->注册到earlySingleObjects,singleObjectsFactory(对象工厂ObjectFactory)---> 属性解析-->如果B不在singleObjects/earlySingleObjects中存在，则创建实例B-->也注册到两个map;-->属性解析，如果依赖A-->先从earlyProxyReference里查看A是否已经AOP过了，如果标记没有，则调用singleObjectsFactory里的A的ObjectFactory这个lamda表达式生成动态代理，后将这个动态代理设置到earlySingleObjects,和设置到earlyProxyReference里-->返回这个A的动态代理的引用，注入到B中；B继续它的属性注入；
			
7.分布式事务：
	>化简：存到一张表里；多个字段，同时存储，则有ACID了；
8.编写风格：先文字描述，功能描述；后开始写代码；---所以代码自然分层次实现描述；	(接口描述类+具体值的实现类)
9.sharding-jdbc/sentinel/cat(skywalking)/arthas/spring-boot/spring-cloud为重点；
>问题记录：发现的待解决问题：
	>docker日志没有归档？
	>数据迁移停服务？
	>数据库慢sql分析、数据库容量监控报警？---提示扩容；----那么就自动的不需要分库分表了，但是这个必须只能按照自增的log类型来保存，保存范围，无删除，满1kw，自动开始新建表，下次写到新库新表里；
		>脚本的使用：linux\python脚本？会更简单？
	>key-list的使用：某些数据是否可以存到可用的kv数据库里？Tidb,
		>持久性存储：rocksdb
	>概览图：每个机器节点/rds/ecs节点，每个k8s节点，每个容器，可视化监控，各项指标；设置监控报警；相当于一个统一简单的监控平台；。。服务之间的拓扑图；
	>突然内存/cpu增长：各个线程的分析；cpu/mem占用分析,jvm统计；定位到代码级别！！！：：问题-->代码；
	>业务的梳理：各个接口和模块的整理、归类和统一；服务拆分的第一步；	
	>groovy脚本的使用：
>工作进度：
	>2020-9-8将发：base-api/base-util/base-bridge/base-mq/executor/web-mq/web-user/web-passport 
	   base-api/base-bridge/base-mq/base-util/executor/manager/web-mq/web-passport 8 个项目
	   
>kb历史：
	>日志查看： kb logs ihuaben-tomcat-user-74cdf44785-pv7ts | grep "saveUserScore"
>redis 操作查看：
	>列表： LLEN UserScoreQueue
			type UserScoreQueue
			LRANGE UserScoreQueue 0 10
	