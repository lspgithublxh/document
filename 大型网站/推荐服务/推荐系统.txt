
>推荐算法1：
	>已知：每个问题的各个知识点涉及度(0,1);---成为题目的特征向量。
			每个学生对问题有需要程度;----需要程度和题目的特征向量有关，也和用户对各个知识点的欠缺度 有关；并且认为越欠缺越涉及则需要度越大；从而可以有 “需要度=题目的特征向量*用户的知识点欠缺度向量”(或者叫“题目对该用户的 '知识加权提供量'：'平均提供量': '对用户的综合价值'”)。//需求就是价值
			
			
			
	>问题：学生的欠缺度未知。
		>解决方法：通过学习得出。计算得出。不断的接近调参得出。学习函数、误差函数、效果函数：定义为  1/2m *Σ(学生j对i问题的计算需求度  - 实际需求度)^2  .....目的是得出用户当前对各个知识的欠缺度(首先是假定 用户对各个已回答问题的真实需求度是准的，那么当前知识欠缺度和问题的知识提供量的向量积就要逼近问题的真实需求度：：逼近算法就是梯度下降法---梯度方向就是变化最快的方向-就是极值的方向或者说顶点的方向：：那么就可以得出用户的当前知识欠缺度)，并且在每次推荐和使用之后更新推荐，并且用户信息也要不断更新。
					那么在已知用户当前的知识欠缺度的情况下，给定一批问题，且问题的知识提供量/相当于蔬菜的各种营养成分已知，那么就可以计算出这些问题对用户的“计算需求度”了，做个高低排序，就是推荐的问题；；答题的反馈是：问题的需求度更新--比如答对了则更新需求度更低--而答错了则更新需求度更高，调节得更高//另一种调节手段是仍然调节知识欠缺度：根据问题的知识含有量而加权地调节各个知识的欠缺度。同理，如果是推荐一个人食物，那么就可以推荐用户今天吃什么(新产品)(同理，每天可以产生一个推荐菜单并且精确到食物和量)(同样，用户的各方面的营养欠缺度也需要知道，环境-身体状况-吃的历史等信息也需要)。(电影推荐，娱乐推荐，学习推荐，...)
						(此系统并非是根据用户点击量和用户评分和用户地址和用户信息进行的推荐)
						
		
	>问题2：普通推荐系统：协同推荐系统
		>
		
	>问题3：推荐系统基本模型：需求者-提供者-推荐者
		>被推荐对象的用户(需求者)：用户当前的各个营养要素占有程度/掌握度。Xj
		>推荐给用户的对象(提供者)：每个对象本身能提供的各个营养要素的量值。Qi
		----选择对象的依据：用户对一个对象的需求程度---值的计算式：R(Xj,Qi) ，按需求度高低。Rmn=Xmk * Qkn  ,m就是用户的个数，k是要素的个数，n是对象的个数。是一个矩阵。解出Xmk和Qkn， 解方程的方法：第一种就是n个方程n个变量，然后进行求出唯一解：：这是变量的方程约束值--方程约束导致取固定值得到确定值。第二种：函数极值方法--n个变量构成了一个函数，求这个函数取得极值时的n个变量各自的取值；这是变量的函数极值----函数极值约束导致变量得到固定值确定值。两种方式的目的都可以确定自变量的值。函数方式最经典的函数就是误差函数：f = Σ(计算值 - 真实值)^2, 这种方式需要知道真实值m*n个，计算值可以是两个矩阵相乘得出的m*n个，而两个矩阵中可以分别有若干个未知的即变量kl个，那么误差函数f就是关于这kl个未知变量的函数，从而可以确定它们的值；且真实值的个数mn不必多于kl，一个值理论上也是可以的---只是函数变得简单了约束少了--但都可以得出kl个偏微分方程--从而计算出kl个变量的取值。而一旦计算出了两个矩阵，那么真实矩阵里的未知真实值的计算值/估计值共有m*n - mn个就可以计算出来了::据此排名即可。第三种计算两个矩阵的方法就是深度学习。第四种多个未知变量的计算方法：已知n个样本已经发生了，并且每个样本发生的概率是theta的函数f(theta,xi), 那么这组样本同时发生的概率：g = f(theta,x1)*f(theta,x2)*...是关于theta的概率函数，对于已经发生的---发生的条件就是概率大-概率大才能发生--根据小概率事件原理，既然概率大才能发生，那么发生的各个样本的实际概率构成的联合概率--对theta来说值不同取值不同 ，那么theta就不能随机取值，theta的真正值最可能的值概率最大的值就是g函数/联合函数取最大 才是theta的本轮实验的实际值；对g求theta的偏导数,令=0得出的theta值就是theta本轮实验的真实值。总结：样本误差函数(最小),样本同时发生的概率密度函数(最大)，都可以求得两种函数中的参数值。(将未知量当做参数来估计--使用参数估计方法；两大类指标函数：误差函数、联合概率密度函数)
		----使用对象后的反馈作用到需求者：作用到Xj即可：Xj=F(Xj)。也有人调节R中的参数。
		----模型优劣的评测：推荐n次中，每次的推荐结果和每次反馈后的营养要素占有程度，分别是多少。优劣标准函数：G(Q[],X[],R,F)
		
		
	
	>问题4：推荐系统第二模型：相似用户和评分
		>用户：本身用户基本信息。Uj
		>物品：产品基本信息、标签、关键词。Pi
		---选择物品的依据：物品来源:相似用户R3(Uj,Uk)购买的也是当前用户需要的，这些产品的相似产品R4(Pi,Pk)也是需要的，一次购买的所有物品认为是相似的，pro_list(Uj,Pi)。物品排序：按评分高低排序。R(Si, Ni,...).评分已经有，不用计算；或者使用新的实时的计算方法得出---即评分矩阵S2(i,j)中其他用户的所有评分作为计算的参数--得出本次推荐的综合评分R2(S2)。
		---使用物品后的反馈到消费记录：新增消费：各个物品的个数Ni、评分(反馈)(产品体验)Si。add_list(Ni,Si)；或者用户对商品的评分S2(Uj,Pi)矩阵。更新物品相似度Akl矩阵=R1(Akl,plist,...)，用户相似度Ymn矩阵=R2(Akl,plist1,plist2,Uj1,Uj2,...)(购买的物品重合度高则相似度要增加一点)。
		---模型优劣的评测：查看推荐后的反馈。//模拟一个真实的用户。
		
	>问题5：推荐系统第三模型：基于内容的相似物品--类似第一模型。以内容尺度推荐文章。
		>用户：对各个主题、关键字、类别有一个需求度向量。Xj
		>物品：每个物品有一个 各关键字、各内容角度、主题类别角度的内容信息供应量向量。Qi
		---选择物品的根据：各个物品对该用户的综合满足量大小R(Xj,Qi)
		---使用物品后的反馈：将物品的信息+用户的体验信息 作为因素，用来更新用户对各内容点的喜好/缺乏/满意/需求向量Qi
		---模型优劣的评判：推荐的结果分布。
	
	>问题6：推荐系统中计算真值矩阵R的深度学习方法：
		>AE方法：AutoEncoder利用反向传播算法: 进行数据的降维和特征的抽取，--用来确定权重矩阵的初始值----即采用一种保留数据初始特征的编码方式：：同时解码之后可以较好的恢复。一次加权是取一个特征(可以用[1,0,0],[1/3,1/3,1/3]两个向量来解释)
			>损失函数：
			>单层神经网络：对向量分类(相当于将一个向量输入而输出一个单值；不同的向量输出值不同；先进行一次加权得出一个值，然后进行函数映射得到另一个值--更形象的值)。从而一次加权(连带剩下的函数映射)得出的值代表一次特征提取/一次计算属于x类的属于度/相似度，属于度高则属于这个类，；；自然，如果有多个输出节点----那么就有向量属于多个类的程度的判断。同样，如果再加一层节点即再进行一次特征提取，就是对属于n个类的程度值进行加权选择---结果就是属于一个新类也就是更高层更抽象的类的概率(比如加权设置为既属于a又属于bc的类就属于这个新的类---那么只要属于a,b,c的概率大那么就极可能就属于这个新的类)
				>如果把逻辑运算当做向量分类：与，或，两种运算都有两个输入一个输出，那么同样的“二入一出”模式，线性变换/算术运算/加权也是“二入一出”模式，那么理论上就可以用算术运算类型的“加权组合”来等价表示逻辑运算的“与”/"或"/"非"
					>与：算术运算来模拟：输入x1,x2，输出y,  y = f(x1,x2) = g(w1x1 + w2x2 + b1) 。现在根据逻辑“与” 的定义得出有：00 0 ,10 0,01 0, 11 1 四种映射约束关系，可以直接的发现两个类别的输入集合之间的差异---比如和<2就是0类，=2就是1类。那么这个f的两个权重就是w1=1,w2=1, b1=-1 ，激活函数g=sigmod(x)函数, <=0是0，>0是y=x曲线。(输入直接相乘也可以，但是不是加权组合方式)
					>非：算术运算模拟： y = -x1 + 1  g仍然可以取sigmod()
					>或：算术运算模拟： y = sigmod( -x1 -x2 + 1) 然后再接一级“非”运算。或者直接的y = x1 + x2 前提是可以识别>1都是和=1是同一类
					>异或：在已知上述三种基本运算条件下，通过 x异或y 等于 (x|y) & !(x&y) 从而可以得出，这个运算表达式需要进行二级加权映射(自然的，如果表达式层次更多，比如无限连分数，也是多级加权映射来等价表示)。
					>运算与分类的关系：加权函数与分类的关系，以一次加权为例。自变量空间为平面上的点，加权函数形如z= w1x + w2y 或者z=w1x1 + w2x2 看做超平面，那么此时对向量/平面点的二分类就是以0=w1x+w2x2为分界线，含义就是一次加权一次线性分类，又有“二输入的与运算分类/多输入的与运算分类”，那么对两次线性分类的结果，进行一次与运算分类，得出同时是这两个类才是新的类的结果，从平面上看就是两条分界线的某个小区域。
		>VAE方法：  
		
		>GAN方法：
		
		
		
		