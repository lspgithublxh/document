1.问题描述：
	>预知：
		>spark可以运行在hadoop（通过hadoop yarn 连接到hdfs）上、cloud上，独立运行。Apache Mesos上也可以。
		
	>理论：

	>启动spark集群、编写执行任务：
		>Master-Worker结构启动：主节点上：./start-all.sh即可。
					测试：spark集群情况：http://192.168.130.132:8080/
										
		>任务的执行：实例任务--集群上的执行方式： ./bin/spark-submit --class org.apache.spark.examples.SparkPi --master yarn --deploy-mode cluster --driver-memory 1G --executor-cores 1 examples/jars/spark-examples_2.11-2.1.1.jar 40
			     >另一种执行方式：./bin/run-example SparkPi 10
			     >自定义任务执行：需要maven打包。./bin/spark-submit --class com.construct.spark.SparkTask --master yarn --deploy-mode cluster --driver-memory 1G --executor-cores 1 ../bigData.jar 40
			     >本地执行方式：--master local[4] 参数配置的不同

	>java api开发：
		>RDDS:弹性分布式数据集：
			>创建、使用、持久化：在内存中。可以被并行的操作。
					     >数据来源：文件、内存、数据库。
			>RDD操作：transform和actions:
				>transform: 将一个RDD转换为新的RDD,且只有有action时才会执行。
					   目前有三种类型：一是
					  > map:
					  > reduceByKey:
				>action: 计算这个RDD的一个度量量
					  > reduce:
			>持久化RDD在内存中、到磁盘上、到其他节点上：
				>可以在action方法执行前先执行持久化的方法，这样在第一次计算之后，生成的JavaRDD就会被持久化，而相应可以被直接访问到了，再次被访问到了，即在后面的代码中可以访问了。

			>spark的文件处理模式：处理招式、处理类型。观念认为，通过这几种动作构成的模式，流程，可以解决一般的文件处理的问题。满足一般文件处理的需求。
				>a.层层映射：以行为单位，一行为最初的输入元素-即RDD的元素，输出元素类型开始变化，经过一次又一次的转换映射，可以为一个复杂的对象（综合所有行，就是一个RDD集合），这个对象可以是基本的三种：迭代器(flatMap)、元组(mapToPair)、一般Object对象(map)。。这种转换为泛map方式.这是招式1：层层转换
						所谓平坦化处理，就是在对任意一个RDD元素处理时，由这个RDD元素可以产生若干个元素，而我希望这些生产的元素是新的RDD的最小元素，flatMap方法就可以做到---注入函数返回的是一个集合迭代器，而这个集合中的元素就是新RDD的元素。即新RDD的元素是注入函数的返回值（集合）解散（平坦化）后的值，或说解散集合将全部元素加入到新的RDD中。
					     #推论1:要注意注入函数的返回值，和新RDD的元素的关系。
				>b.两两运算：以RDD的元素，两两输入，运算返回一个元素(reduce)，如果是PairRDD，则还可以是同一key下的values两两输入,运算返回一个元素（reduceByKey）
				>c.排序和收集：对于一般RDD，对其中元素排序，需要专门定义比较函数，对于PairRDD,可以直接用key排序(sortedByKey)。收集结果：collect()则从各个节点上读取当前RDD元素回来-到driver program。
				>d.过滤器filter：过滤器模式于RDD的元素，过滤函数。
				>e.统计和持久化：countByKey,count按元素或者按pair进行。持久化RDD在内存中、磁盘中。
				>f.纵横联合：union,join，从而可以将不同的RDD按键Key而链接起来，对于pairRDD处理非常有意义。

			>spark的数据库处理模式：
			>广播变量和计数器：广播变量给每个node发一份。计数器只写，在每个node上。

		>广播变量和变量：变量分发到worker
		>分片：最小单位是Block,即128M的内容---对于分布式文件来说。
		>driver program: 负责将计算分为task任务，而分发到集群中各个节点上去计算运行，而节点将最终计算的结果返回给driver program。即主节点。
				 这里，分发时刻，就是执行到action动作在JavaRDD的方法时候，在此之前，不会分发任务的。因为之前分发没有必要，浪费资源，不是lazy方式。

		>本地执行模式：--master=local[n]
			 >

		>变量和方法的作用域和生命周期：
		>闭包：就是对excutor可见的若干变量和方法。--一个大括号里的内容。像是一个JSON对象，一个对象。
			闭包发给excutor。序列化后的方式发的。
			driver program将RDD操作任务分成若干个tasks，每个任务又有一个excutor来执行。每个excutor又有一个闭包。一个序列化传给executor的闭包就是一个任务。
			推论1：序列化后的闭包里的变量，不会再影响到闭包外面的同一个变量的值，因为已经不在一个虚拟机JVM上了。而且worker也不会将闭包里的非最终结果变量返回给driver program 
			推论2: 即便是一个对象被传到序列化后的闭包里了，因为引用在新的JVM里了，所以在worker上的变化也不会影响到driver program上的对象了。
			推论3：如果需要worker影响到driver program里的对象，那么需要Accumulator，这个可以反传给driver。
			推论4：driver收集worker里println的结果：collect().foreach(println)或者take(100).foreach(println)
				带回来的方式还可以是：rdd.collect()
		>键值对形式的RDD:rdd of key-value
			:		
		>Shuffle:洗牌，比如reduceByKey，是一个耗费资源的过程，需要重新汇集结果。

		>filter:过滤器:
		>DataFrames：将数据集和数据容器关联起来的一个整体，整体提供了一系列像sql的查询操作方法。
			  >过滤：filter
			  >分组：groupBy
			  >排序：
			  >统计：count
			  >联合：横向联合：union,纵向联合：join。对于javaRDD同样可以。
			  >select：选列，和对列处理（列是一个类，有方法和属性）
		>PageRank：是一种重要性排名。一个url在其他每个url下的页面中出现的比例（次数/总次数 * 分数）之和，再线性映射化，再将这个结果作为分数，进行下一轮的分数计算，次数越多，区分度就会越大，从而把各个页面都区分开来。
		>Spark sql:创举：对象用sql来查。从数据库查出来的结果直接可以再用sql在本地查。RDD转换为DataSet
			  >RDD和对象，RDD和StructType都可以转化为Dataset
				>Dataset构造方式：json文件，数据库表，RDD转换（加StructType对象，或者加类.class），对象+Encoder
				>Dataset本身用5种基本动作来查找：过滤、分组、排序、统计、联合、选列
				>Dataset创建临时视图而用sql来查：
				>Dataset的map-reduce处理：
			----推论1：什么都可以转换为Dataset(集合，对象，不管存储形式是什么样子，存在哪里)
			    推论2：Dataset可以进行一般的sql操作（存为视图后，可以用sql进行操作）

			  >自定义函数：
			  >直接查文件：parquet文件格式的文件，可以直接用sql来查。

			  >Bucket和Parquet：桶
				>parquet:列式存储而不是行式存储的一种数据库。
					>列式存储：对query查询和过滤非常有用，但是对于scan浏览整行这种则不那么擅长：但是列过滤和行键rowkey就可以取得很好的效果。
							因为可以并行进行，而且存储区域连续查找方便--直接顺序下去就可以。数据量越大和越需要精确查询，效果越明显。
						   >实际存储：一列一列的序列化，而存储。对每一列序列化时-都和rowid关联：且rowid是值不是键。
								且列会压缩存储---因为值索引了。在事务存储数据时，则要对每列加事务，从而效率不够。
					>表在磁盘上的实际存储方式：序列化为同一种格式。
					>效率问题：硬盘操作最耗时的是seeks:查找。因为机械硬盘转动速度始终是慢的。磁头通过机械装置（操作臂）在磁盘上运动（相对运动），找到存储位置扇区(sector)，找到目标磁道(track)。从最外层磁道到最里层磁道，耗时最长--毕竟距离最远。4-15ms。音圈直线电机。相邻磁道：0.2-0.8ms。
							固态硬盘：0.08-0.16ms。只是电路的准备时间。
							磁道受限：限制从某磁道到其他磁道，从而避免大幅度运动，减少了存储量，但是提高了访问时间。
							特性调整：越快噪声越大震动越大（磁盘加速和减速，旋转而空气流动气压差而上下运动）。
							操作过程：磁盘旋转将扇区带到磁头下-->磁头移动到目标磁道--->磁头读写数据(3us)
							数据移动速度：磁盘表面到驱动的控制器，驱动的控制器到主机系统。
									buffer-to-system:3Gbig/s,而disk-to-buffer:1Gbig/s(7200rpm)
									其他影响因素：文件系统碎片--重组、文件布局。数据存储密度---一个磁道中一个分区的数据量bit。。定位缓存：即认为当前访问的磁盘位置可能以后也会访问----这个与程序相关--如循环语句-数组操作、矩阵操作。
							磁盘重要概念：磁盘、柱面、磁道、扇区。
									磁盘-盘片(5个最多)-盘面(一个盘片2个)-同心圆磁粉构成磁道（上万个）-每个盘面上有磁头---一个磁道上分若干个弧段每个弧度是一个扇区512字节--读写数据以扇区为单位
									柱面-磁头-扇区：确定一个磁盘上的区域。0-0-0，1-1-1
									Dos经典扇区：MBR扇区（磁盘分区表）、DBR扇区（dos引导程序）、FAT扇区（文件分配表-簇记录）、BD扇区(根目录)：均在0盘面外磁道
					>音圈直线电机：
					>行式存储：每row序列化，存到block,临近存储临近行。
						   缺点根本在于：定位每个列麻烦,所以列过滤麻烦。--磁盘定位耗时多。增加索引：则rowid是键-索引列-索引会排序，这样简略存储，但是插入数据要更新到索引，所以插入速度收影响。
						   >使用：内存数据库。--不需要索引？--因为查找速度一样？
				
					>基本概念：分布式文件块-->磁盘文件（也是mapreduce单位）-->行组-->列块(也是IO单位)-->页(也是编码压缩单位)
			  >输出结果Bucket化和Partition化：
			  >Hive metastore:数据持久化，将Dataset存为Derby下的表。

2.小知识：
	>使用匿名内部类，不如使用lamda表达式：(a,b) -> {return a * a + b * b}。lamda表达式消除了匿名内部类。且该匿名类只有一个方法
	>java8特性2：方法引用：lamda表达式中右侧实现体仅仅为方法调用，且输入参数是左边的平行移动，则可以使用方法引用，直接用：类：方法名，实例名：方法名
参考资料：
1.http://spark.apache.org/docs/latest/（官方参考资料）
2.http://spark.apache.org/docs/latest/quick-start.html（官方参考资料，开始编程java api，伯克利大学）
3.http://spark.apache.org/docs/latest/rdd-programming-guide.html（java编程起步，和原理讲解）
4.http://spark.apache.org/docs/latest/api/java/index.html(开发文档)
5.https://repository.cloudera.com/content/repositories/releases/org/apache/spark/spark-assembly_2.10/(目录jar仓库)
6.http://blog.csdn.net/u012429555/article/details/51346328(一个完整的小哥的安装过程)
7.https://my.oschina.net/wangzilong/blog/910157(本地独立运行spark任务)
8.http://www.cnblogs.com/JohnTsai/p/5806194.html（java8方法引用）
9.http://spark.apache.org/examples.html（编程实例）
10.https://github.com/apache/spark/tree/master/examples/src/main/java/org/apache/spark/examples/sql（官方实例，可以看github）
11.https://spark.apache.org/docs/latest/sql-programming-guide.html#dataframes（极其重要的spark-sql,hive参考资料）
12.https://en.wikipedia.org/wiki/Column-oriented_DBMS（列式数据库和行式数据库优劣比较）
12.http://bbs.mydigit.cn/read.php?tid=331754（磁盘参考资料）