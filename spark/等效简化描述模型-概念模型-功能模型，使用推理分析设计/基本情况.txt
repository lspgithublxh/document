参考资料：http://www.infoq.com/cn/articles/apache-spark-introduction
		http://spark.apache.org/
1.如何在内存中计算的？


2.编写的程序如何运行的？java\scala\python

3.高阶操作符


4.shell操作：交互式查询数据（python和scala可以）
  》scala:运行在JVM上，但是用自己的编译器生成.class文件。因为它是另一种语言。
  》启动shell脚本： ./bin/spark-shell --master spark://S1PA11:7077
  

5.map\reduce操作：


6.sql查询操作：


7.流数据处理


8.机器学习

9.图表数据处理

10.多路计算

11.有向无环图：多步数据管道

12.比hadoop中mapreduce好的地方？
   》首先，spark依赖与hdfs分布式文件系统。所以上传文件是必须的。
   》但是，hadoop的mapreduce的一路map\reduce直到输出结果到文件里的方式，比较固定不灵活。比如想数据来源不一定是文件，而是数据库，同样输出地也不是文件而是数据库。
     而且如果希望一个任务在执行中执行多轮map/reduce是不行的，因为只有一轮，一轮就结束了。多轮只能多个job。
   》从而关心一个问题：中间数据存储在哪里？可不可以利用到上次处理的结果？
     I:内存中，而不是磁盘中。但是可以利用磁盘---当内存不够的时候将数据集存入磁盘。
         

13.Shuffle洗牌。数据就是牌，洗者就是spark。


14.RDD  弹性分布式数据集
   》等效模型：数据库中的表。上层概念:分区。各个RDD在各个分区里。
   》容错：RDD可以重新创建和计算数据集
   》不可变：RDD像字符串，不可变；变换RDD后返回的是新的RDD，旧RDD仍然不变和存在。
   》对RDD的操作：变换（transformation）型:这种操作（函数）：输入的是RDD，输出的是另一个RDD，内部是利用就RDD生产新RDD的过程。典型函数：map,filter,flatMap,groupByKey,reduceByKey,
		  			   aggregateByKey, pipe, coalesce
		  行动（Action）型:这种操作（函数）：输入RDD，返回一个新的值，内部就是处理计算这个RDD的某种量度、指标。典型函数:reduce,collect,count, first, take, countByKey, foreach
   》RDD在语言实现中是一个对象，那么它就有自己的若干方法和属性。而这些方法就是上述的变换方法和行动方法。
   》产生和存入内存时机：
     当用SparkContext上下文的textFile生成一个RDD对象时，没有真正把RDD数据加入内存中，而只是在内存中建立了一个抽象结构，当执行行动函数时，才会把数据存储到内存中。
   
			
   ----存在一个可以调用执行各个变换型类和行动型类的主类。

15.spark streaming
  处理实时的流数据  

16.Spark Sql
   将数据（JSON、数据库、Spark数据集）转化，用户可以进行特定的类似SQL的查询。
 
17.Spark MLlib
   实现了通用学习算法和工具。

18.Spark GraphX

19.JAVA API
   参考资料：http://spark.apache.org/docs/latest/api/java/index.html
   》一个具体的某种行动型方法，还分具体的行动函数对象（统一实现某种接口），即该种行动型方法实际上就是调用的这个具体行动函数对象的方法。
			或者说JAVARDD的某种行动方法，不是叫开发者去实现，而是已经开发好了，开发者需要的是传入一个具体行动对象（统一要求实现某种接口）,JAVARDD的该种行动型方法只负责管理、文件处理、遍历文本行（对于数据库，则是数据库行）--将每行交给具体的行动函数对象去执行，收取结果，怎么收取（把每次行动结果组合到什么结构），怎么遍历就是这种行动型方法的内容（行动型方法不同，组合方式差别是很大的），只是它不负责实现对每一行的具体的操作。
	-----所以一个JAVARDD基本上是一个文件的全部内容的集合，只是内容格式、容器是JAVARDD专门的。同理，一个JAVARDD可以是一个具体的表数据的包装体（包含整个表的数据）。
            （不像hadoop mapreduce中,用户只知道一行，而不知道其他行-如上一行下一行全部是什么样）
       -----比如： flatMap型转换方法，它调用传入的具体行动对象，是在它读取了文件后，遍历每一行时调用具体行动对象的方法来处理行，并将集合式结果的每个元素都单独放到一个新RDD的一行中
             （所以，必须明确，一个JAVARDD的行是什么，一行存的是什么）
	         又：mapToPair型转换方法，也是直接遍历JAVARDD的行时，就开始调用用户的具体处理行函数对象，用户处理结果是一个元组()Tuple2,组合方式：这个元组作为一个新的JAVARDD的一行内容。
                  又：reduceByKey型转换方法：先遍历完一遍JAVARDD的每一行，生成一个key -集合 这样的map，即干了combine的事情，后遍历每个key的集合，在遍历中调用用户的函数对象，并传入两个集合的元素给用户函数对象，将用户对象处理的结果和key构成一个元组（）Tuple2，作为新JAVARDD的每一行。
		  又：foreachPartition型行动方法：行动型方法，内部是直接调用用户的行动函数对象，将整个JAVARDD的每一行构成的一个行集合都作为参数直接传给用户函数对象，用户函数对象的结果（如果有的话，可以没有）就是这个行动型方法/函数的结果。
20.共享变量：
    》广播变量：在每台机器上缓存只读变量
    》累加器：可以获取一个累加器，并将它增值，但是任务无法读取变量的值，而需要驱动程序。


21.内核使用scale语言编写。



