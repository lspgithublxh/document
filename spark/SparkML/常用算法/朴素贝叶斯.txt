1.问题描述
  >预知1：贝叶斯定理
	>类别项、待分类项、分类映射方法。其中分类映射方法不是一来就可以知道的，是根据样本数据--经验数据而构造的、学习、训练、调整出来的，与数据特征、训练方法有关。
	>条件概率：P(A|B)----即事件B发生后事件A发生的概率。
		   >条件概率就是在因事件发生的情况下，果事件发生的概率，即两个事件是相关的，前一个影响后一个。（必须是相关的，否则是无关事件--条件概率等于AB两个事件的概率的乘积）
			且因果事件，相当于事物的因果情况，事物的A种事情，可能会发生多种情况，而事物在每种情况下可以再发生B种事情的多种情况中的某种情况。
			澄清：即1）事物会发生A类事情和B类事情。
				2）A类事情和B类事情都有多种情况。
				3）A类事情发生后，B类事情才能发生。
				4）对于A类事情可能的每种情况，B类事情发生的每种情况的概率是不同的（即A类的每种情况对应的B类事情的情况分布是不同的）。
				5) A类事情的每种情况都有一定的发生概率（和为1），B类事情的每种情况也是。
			--------可以用从左到右为从A到B的树延展来表示这个概率的对应关系---------------
			
	>经典问题：已知袋子里n个白球m个黑球，求摸一次摸出黑球的概率。反过来，袋子里有若干个球，摸了100次，每次摸一个并放回去，统计每次摸到的颜色，最后统计各个颜色的球出现的概率，求袋子里各颜色球的概率。
   			（逆向概率问题:已知概率求情况。而概率问题是已知情况求概率。）
		  >两个独立的未来事件（即现在还没发生,可能将来一前一后发生，或者同时发生）都发生的概率：概率相乘
		  > 一个事件可能会变成多种事件中的某一种（现在还不知道），求是某两种独立事件中的任一种的概率：概率相加
		  >历史事件：事件的统计：已经发生的n个事件，对将发生的那个同类事件，是有影响的，即我们计算概率是以知道的信息为根据的，这信息包括现实事件本身所属于的事物情况本身也包括事物情况最近发生的各个事件（统计来量化说明的问题，说明的事实），但是如果事物情况本身已经在多次事件种暴露了更多的性质、更多的事实，从而我们对事物情况了解更深更精确，那么事物将发生什么事件，我们必然有更精确的计算更精确的概率肯定----即更加接近真实的概率:而不应该和之前对事物情况毫不了解时作的概率估计一样。
		  