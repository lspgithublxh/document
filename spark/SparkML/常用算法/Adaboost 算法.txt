1.问题表述：
  >条件：
  >预知：
	>bagging算法：是一种投票算法，即n个人投票，取投票最多的那种结果。
			如果给每个投票加上权重，得到的投票结果就是更正确的结果了。（或许可以先再归一化）
	>方法具体：
		>样本权重：初始样本集合的每个样本权重一样；
			   从上一个样本集合训练出一个弱分类器后（具体什么分类器：），用来分类这些样本，分类正确的降低权重，分类不正确的增加权重，构成下一次训练新弱分类器的样本集合。
		>弱分类器的权重：随着弱分类器在一轮又一轮的训练下产生，用来分类其分类的正确率的计算出来，则正确率高的弱分类器的投票决策所占的权重当更高，反之当更低。开始时，每个样本的权重值都是1/m,m就是样本的总数。
				 对应正确率，就是误差率。而误差率体现一个分类器的好坏，从而可以作为弱分类器的权重因子--因变量，这个在0 - 1之间的数，这个通过一个对数函数映射到正负无穷区间上去，作为弱分类器的权重系数。
				 而这个弱分类器权重应当还要计算出下一轮的训练样本集合的权重系数，而下一轮的权重系数应该是这一轮的权重乘以一个因子：这个因子具体显然与分类器对每个样本处理后的值相关，将这个值再次透过一个指数函数，来得出都是正值---值越大那么其实也表明该样本的误差率小，而这个值在0到正无穷，所以还要归一化，将所有样本的这个值算出来求和，看每个样本的这个值占总值的比例。这个比例就是旧样本权重计算新样本权重的系数。
				 ----上述即是弱分类器的权重计算新样本权重的方法。
				 >推论1：最终分类器：先组合各个弱分类器，即是弱分类器与权重的线性组合，而这个结果是在正负无穷区间的，且正则表明若干个弱分类器的线性组合表明分类应该为1类，为负则表明分类为-1类。通过一个符号函数，可以映射到[-1,1]之间，从而得到最终的分类器。
					
		>弱分类器：就是样本集合---到---类别集合的映射（函数）。
			   这个函数，通常是非常简单的：区间-正负1 这样的连续不可导函数（在分界点的导数为无穷大）。每个弱分类器的区别就是区间不同、分界点不同而已。
			   
		>误差率：就是分类器分类错误的样本的权重值之和。
		         
  
    












http://www.360doc.com/content/14/1109/12/20290918_423780183.shtml（循序有理，有度量）	