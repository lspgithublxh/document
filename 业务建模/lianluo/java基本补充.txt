>任何事情都有层次体系：追求层次体系，找到层次体系明确表达 出来 是 当前 做事情的重点。
>等待开发的一些框架和工具。
>进行面面俱到的描述。
>疑神疑鬼太累(已经发生的没做好的当吃亏,以后要注意)：减轻办法：不要装逼、不要装高尚、要重视信息安全(信息要加密要包装)(不要无所谓)、要确定性的办事(不要草率)。
>所有的愤怒都是别人的故意的计策和阴谋：别有用心、见不得别人好、见不得别人发展得更好 才会激怒和贬低和打击 来 摧毁对方/毁灭对方。不能让它得逞。(也谨慎打击别人:不是所有人都会越打击越强,但打击之后都会怀恨在心)
>规范的训练自己：所以要看技术书。
>连续关联、每个环节步骤都细化：可扩展可替换可新增可删除(方法和入参和局部变量和甚至属性)
>蔓延式关联。
>引用：每个引用都有一个值(要么是null/要么是指向对象的地址)
	>
	>引用类型：
		>弱引用：
			>将一个引用标记为弱引用：new WeakReference(T re)
			>GC时对一个弱引用标记的引用的处理：如果一个对象的所有引用都是弱引用，没有强引用，则直接将这个对象的空间回收了，而把弱引用标记的引用设置为null, 即re=null；而不是这个WeakReference对象为空。
			>运行中的问题：
				>内存泄露问题：无法回收的对象：为 当前没有结束的Thread的threadLocalMap里的Entry: key=null但是value还是有值的。这个value就不会被回收。原因：key指向的本来是一个ThreadLocal对象的引用，但是 引用key被标记为了弱引用，导致GC时如果 这个ThreadLocal对象只有这个key引用它 则就会直接回收它 而将key=null处理。
					>原因：没有其他强引用指针引用。
					>解法：key=null的entry需要被擦除。---threadLocal已经做了：但是不会自动做---有个触发条件--调用ThreadLocal的set/get方法：正是threadLocal在ThreadLocalMap之上封装的目的功能之一。
						>解法2：手动删除 不需要的 Entry对。remove()方法可以置null value引用 和 置空 entry引用。
						
>方法拦截器的使用：任何方法是否都可以拦截。
	>controller上的用户自定义方法拦截器的使用：而不是对controller的所有方法都应用--即专门对某个方法应用拦截器。
		>利用springmvc的controller拦截器 + 用户自定义的方法注解：检测到 方法上有这个注解，那么就 执行特定的逻辑。
>通信机制：
	>调用： 基本元素/角色/概念：主线程、工作线程；产生数据的方法、消费数据的方法；
		>同步异步：主线程上下文 和 获取处理 工作线程产生的结果 的方法 是否 是 同步进行的。 
			>理解2：触发生成数据的方法 和 消费处理产生的结果数据的方法 如果都是 主线程做，即先后做，则是 同步的-生产和消费是同步的。如果这两个方法第一个是主线程做，而第二个则是工作线程做/回调，则称 这两个方法 是 异步的。(生产和消费 是 异步的)
		>阻塞非阻塞：主线程调用某个方法，这个方法返回的结果 依赖其他线程跑的结果，则主线程 是 阻塞等待结果出来 还是 不等出来直接先返回。
			>阻塞：调用一个方法开始后一段时间到返回结果时：当前线程处于阻塞状态(需要阻塞等待 其他线程跑出结果)。(调用时纯主线程执行 和 调用中出现阻塞 有什么区别？表象上看 都返回了结果)
				>接着：1.使用结果进行处理，显然 是 和 上下文 是 同步进行的。2.如果调用方法时传递一个回调函数，让阻塞等待获取到结果后调回调函数处理结果，然后返回，显然 也是和主线程 上下文 同步的；或者 回调函数先交给工作线程，而阻塞等待工作线程得到结果并调回调函数处理结果之后，再返回主进程，那么本次调用还是和主线程上下文同步的。
			>非阻塞：同样的场景，调用一个方法开始后通知其他线程跑结果后，不阻塞等待这个工作线程跑出结果 而直接返回。
				>接着：1.如果用户定时去取，则是和上下文 同步 的 获取和处理结果；2.如果用户调方法时传递一个回调函数-让工作线程得到结果后直接回调这个函数来处理结果，则是和上下文 异步的 获取和处理结果(上下文调用后可以做其他事)。
			>理解2：主线程 等待结果 的 方式： 阻塞 地 等待 工作线程产生的结果， 或者 不断查询 来等待结果(不直接阻塞等待 工作线程如何一步步构造产生结果)(不望着一动不动)。
			>理解3：产生 数据的方法 需要主线程(调用线程) 阻塞等待后才得到 还是 需要主线程 不断查询后 得到。
			>理解4: 产生 事件的线程 和 消费事件的线程。调用 要求 数据源 产生事件的线程。
			>理解5：产生数据的方法 在工作线程1上运行，消费数据的方法在工作线程2上运行，要求 数据源 调用产生 数据的方法的方法 在 主线程 上运行。
				>把产生数据、消费数据 都 做成 和 主线程异步：
				
>java基本：new的时候初始化：可以使用构造方法级别的代码块 方式：{add(x);}  。 如 new A(){{xxx;}};
>线程池的使用：增加钩子函数 关闭。第二：应用里使用 需要在 runnable里手动记录开始的任务和判断当前是否已经被主线程结束了。。
>信息结构和信息关联：				
>Observable 实现异步的方式：
	>subscribleOn()则是异步向上订阅/请求:即准备向上订阅时，放在另一个线程里执行向上订阅/请求。
	>observeOn()则是异步的向订阅者onNext发送数据： 即收到数据时，先放到内部的一个队列里，然后异步的查询队列里的内容然后发送给下一个订阅者/child;
>结构化网络：
	>DHT算法：Kadmelia
>非结构化网络：网络节点为对等节点。
	>bitcoin 副本同步数据算法：gossip协议
		>gossip协议： 必须进行 面面俱到的描述。redis cluster , consul,apache cassandra 使用。
			>概念定义：抽象、封装。
				>被感染节点：
				>临近节点：
			>行为定义：抽象、封装。总结、概括。统一、通用、复用。
				>散播消息：
					>通信方式：异步发送，不等待响应(不关心是否收到/不处理响应?)
			>目标定义：	
				>目标效果：
					>扩展性：新增加的节点 要和 其他节点状态一致。
					>容错性：任何节点的宕机和重启 都不会影响 gossip 消息的传播。
					>去中心化：无需 一个中心节点 知道 和记录 整个网络的 状况。
				>必然效果：顶层思路。顶层想法。
					>任何节点可以把消息散播到全网：通过相邻传播。最终一致。
						>消息传播数量按级增长速率：2的级数 次方 。
						>对应的状态不一致收敛速率：开始很大，初期不一致减少也慢，但收敛速度越来越快。经过 logN步 就全部收敛了。
					>散播速率还是太慢：因为需要多步骤：最终一致的速率太慢；延迟太高。
					>消息冗余：重复的消息 会收到。
			>策略定义：
				>随机选择：
			>路径定义：
			>规则定义：对行为的限制、约束。对路径的约束。对目标的约束。
				>限制每次向后散播节点的数量：3
				>且这些散播节点尚未被自己发送过：
				>如果对方向自己发送过 则 自己不向它发送：即是无向边。
				>定时散播: 每隔1s
			>模型定义：整个协议过程的图像化展示元素。	
>codis: redis实例 的 前端代理 服务器。但是 官方有 自己支持的：redis-cluster。
	>目标：1.将 key分配到不同机器上。2.自身多实例部署 且进行slot数据同步来保证 实例接收的key都会被分派到正确的redis上。
	>思路：
		>对key的分配 环节：引进slot概念，共1024个，并且 一个redis绑定若干个 slot;
		>slot在dashboard上人工重新分配并同步给 codis实例 环节： dashbord发送给 zk, zk再同步给 订阅了 slot目录的codis;。且同步期间 codis进入 同步状态，不对外提供读写服务。
>redis集群方案：
	>客户端分片：key-->hash-->选择redis实例
		>优点：部署简单。只需要部署redis实例即可。
		>缺点：节点数量变更，导致 数据的迁入迁出。
	>服务段分片：	
		>痛点：开发人员只关注业务逻辑即可--只需要get/set即可，不用关心如何 hash 如何分片、新增节点、数据迁移 等等 统一的问题。
		>目标： 提供 给 开发人员 就像 操作一个无限大容量 redis节点一样 来操作的 API操作接口。
		>条件-思路: 像请求一个，则只能发送一个请求，而 数据必然存在 多个redis节点上，所以这个请求必须 能够 再次 分辨应该找哪个节点，则这个逻辑必须 要跑在另一个独立的机器上，这就是 服务端代理。
			>思路细化：代理层的具体功能、指标：1.实现具体的请求转发规则。2.数据的聚合和分解。3.redis server节点的在线扩展、扩容。4.redis server节点上的数据的异步迁移(对业务无损)。
				>缺点：增加了中间层 中心节点单点问题、流量瓶颈问题 、单次处理性能损耗问题。
			>集群化方案1：codis 具备丰富功能且完备的方案。
			>集群化方案2：twemproxy
				>主干功能：请求的路由转发。缺点：不能在线扩容缩容、没有友好的运维UI。
	>混合分片：请求转发逻辑一部分放在客户端，一部分放在服务端。			
		>集群化方案3：redis cluster 
			>请求转发逻辑：smart client 客户端自己完成。
				>数据迁移、扩缩容时的请求转发：
			>在线扩缩容：
			>在线数据迁移：迁移性能不高(所以二次开发)
			>故障自动恢复：哨兵
>架构设计：
	>mybatis 领域模型：
		>BoundSql: 封装了三个属性： sql:sql、sql列值占位符:parameterMappings、参数对象值:parameterObject。提供了几个服务：
			>数据结构：
			>算法：
		>TypeHandlerRegistry: 参数值的类类型处理器 仓库。	
>spring-aop核心：
	>调用时：
		>核心入口：JdkDynamicAopProxy .invoke()调用开始： 会获取targetClass的这个method 的所有的匹配的 MethodInterceptor： 然后形成chain 逐个 procced: 即拦截器链的执行。
			>这些方法拦截器来自：
				>advisor 是 PointcutAdvisor    类型: 方法需要满足切点表达式，Advisor 直接得出的 Advice 强转为 MethodInterceptor ---这种常见于spring-aop-aspectj的AspectJAroundAdvice， 或者 AdvisorAdapter 处理Advisor后得出的 Advice封装到 MethodInterceptor ---这种方式常见为spring-aop中的 前后环绕通知AfterReturningAdvice/MethodBeforeAdvice 
				>advisor 是 IntroductionAdvisor类型：类匹配就可以了。同上。
		>获取targetClass: AopUtils.getTargetClass(invocation.getThis())
		>获取原方法：ClassUtils.getMostSpecificMethod(invocation.getMethod(), targetClass)	
		>核心执行过程：方法实际调用 封装到 Callable里， 再看方法的返回类型：来选择是 executor.submitListenable()还是.submit(), 还是 CompletableFuture.supplyAsync()
	>@Async 注解方法后 对 方法的影响：
		>调用该方法时：走专门拦截器 AnnotationAsyncExecutionInterceptor
			>这个拦截器里记录了所有bean中有这个@Async注解的方法：并已经对应指定了一个 ThreadPoolTaskExecutor --内部新建一个 ThreadPoolExecutor()--具体配置：拒绝策略：抛运行时异常；线程工厂：线程组+名递增+优先级+后台运行；队列：LinkedBlockingQueue/无长度则同步队列SynchronousQueue； 且覆盖execute()方法--来包装装饰Runnable任务:TaskDecorator; 同时允许核心线程超时：allowCoreThreadTimeOut。
				>ThreadPoolTaskExecutor来源：bean ,用户提供。
		>构造AnnotationAsyncExecutionInterceptor的时间地点：bean化时候执行 AsyncAnnotationBeanPostProcessor/AbstractAdvisingBeanPostProcessor 创建动态代理 -->	创建advisor:AsyncAnnotationAdvisor--->创建Advice:AnnotationAsyncExecutionInterceptor,Pointcut:AnnotationMatchingPointcut (匹配方法的标准：有@Async注解/或者@javax.ejb.Asynchronous注解)
			>注意这个拦截器的 executor的来源： 从配置类 ProxyAsyncConfiguration： 获取 用户自己的自动配置类 AsyncConfiguration/AsyncConfigurer 调用方法产生的执行器 都是 null。 所以 还是运行时 产生的：AsyncExecutionAspectSupport.determineAsyncExecutor() -->通过 方法的 @Async注解的value, 然后 从bf 里 找 有这个 qulifier的 Executor类型的bean， 这个就是用户自己配置的bean了。
>linux下功能：
	>查看java应用启动命令：ps
	>spring-boot应用的端口占用：netstat -anp | grep pid
>线程池中的线程抛出异常后怎么处理？
	>worker 运行中Runnable突然抛出异常：则 worker会退出：
		>退出前做的事情：
			>1.这个worker.completedTaskCount++ 即认为这个worker完成了这个task, 然后加到全局的completedTaskCount上。
			>2.然后整体worker数-1， 将worker从workers队列里移除。
			>3.尝试终止线程池：一般没用，因为此时线程池状态running.
			>4.如果线程池state<stop则添加一个worker: 这个新的worker 没有 firstTask, 也不是coreTask; 这样添加成功率更高；
	>对主线程的影响：没有？只是抛出了一个异常；	
	>线程池在execute了一个任务到队列后：会复检recheck, 看是否还有worker,如果此时worker数为0，则添加一个空初始任务的worker。(很明显，添加之前需要检查线程池状态是否还在running-不在running则需要从队列移除这个task)	
>mybatis 中的KeyGenerator功能：
	>在执行更新：PreparedStatementHandler.update(Statement statement)方法的时候，在execute语句之后，先从mappedStatement获取了 KeyGenerator, 然后执行它的处理方法keyGenerator.processAfter()，这里就会转到tkmybatis里的实现了。
>mybatis: 
	>如何进行扫包的：形式上 增加了注解@MapperScan
		>启动阶段有效行为：注册了一个bean:MapperScannerConfigurer 它实现了BeanFactoryPostProcessors的方法，从而这个bean在被实例化时 会调用实现的post方法：有效动作就是 实例化一个new ClassPathMapperScanner()对象来扫包.scan("basePackages") 并注册扫到的合理的类到 仓库:beanFactory
			>扫的类：1.先候选类：先盲选 路径下所有的 没有被filter排除的、没有Conditional关系的 所有 .class --->再过滤：因为这个Scanner有自己定制的TypeFilter:excludeFilters:规则很简单：类名不是package-info结尾即可。而定制的TypeFilter:includeFilters则 只要没有@Conditional注解 就始终可以--->进一步过滤：定制的ClassPathMapperScanner 要求 必须是接口类型 且独立。。(因此Service接口也会被代理，所以这是引起问题的地方)
	>普通的ComponentScan: 是确定的包下有@Component/@ComponentScan注解的。所以Controller/ServiceImpl可以，而接口/Dto/Entity不可以。
>resilience4j：架构和使用。	

>spring-security: 顶级想法和认识。
	>封装过程：过程拆分为了多少个环节，每个环节由哪个类负责。
		>启动配置的封装过程： 用户定义配置类使用 @EnableWebSecurity 该注解@Import了 配置类 WebSecurityConfiguration ---这个配置类定义了名为"springSecurityFilterChain"的javax.servlet.Filter:
			>这个Filter的构建过程/真实内容：WebSecurity 主导构建：1.初始化-->2.配置-->3.构建 
				>初始化：SecurityConfigurer.init() 这个SecurityConfigurer就是用户自己定义的继承了WebSecurityConfigurerAdapter的配置类。
					>认证管理器：配置和构建。调用户配置类可能覆盖的配置方法@configure(AuthenticationManagerBuilder auth) 否则父类默认。
					>直接构建：new HttpSecurity()
					>直接配置这个 HttpSecurity： http.csrf().headers()...  根本就是 每个方法的返回值都是AbstractHttpConfigurer:SecurityConfigurer类型。
						>配置的效果：1.新建一个配置对象 加到 了HttpSecurity:AbstractConfiguredSecurityBuilder 内部的map:configurers: LinkedHashMap<SecurityConfigurer, List<SecurityConfigurer>>  2.新建一个Filter加到HttpSecurity 内部的 List<Filter>
							>配置对象如：CsrfConfigurer/ExceptionHandlingConfigurer/HeadersConfigurer/SessionManagementConfigurer/SecurityContextConfigurer/RequestCacheConfigurer/AnonymousConfigurer/ServletApiConfigurer/LogoutConfigurer
					>补充配置 HttpSecurity: 从 spring.factories里加载 AbstractHttpConfigurer类型的 实现类 来实例化后 apply应用到 httpSecurity。
					>继续补充配置 HttpSecurity:	调 用户定义配置类 的 configure(HttpSecurity http) 来实现。此时如 ExpressionUrlAuthorizationConfigurer/RequestMatcherConfigurer 也加进来了。
					>将 HttpSecurity 加入到 WebSecurity对象securityFilterChainBuilders属性里: 并 给WebSecurity配置一个 FilterSecurityInterceptor。
				>配置：SecurityConfigurer.config()
				>构建：WebSecurity.performBuild()
					>遍历所有的安全过滤器链构建器来获取过滤器并封装到一个DefaultSecurityFilterChain对象里：如 HttpSecurity: 执行它的build()返回的就是所有的Filter 。由于方法是统一的，build过程：init->config->performBuild
						>init: 就是将 HttpSecurity 里的 SecurityConfigurer map:configurers 的所有values都合并起来，然后逐个执行它的init()方法
						>config: 什么也没做
						>performBuild: 将 HttpSecurity的 filters:List<Filter> 排序后 封装到 一个 DefaultSecurityFilterChain对象 返回。这里的过滤器 包括：UsernamePasswordAuthenticationFilter/LogoutFilter/AnonymousAuthenticationFilter
					>将获取的所有DefaultSecurityFilterChain封装到FilterChainProxy对象：这个FilterChainProxy 作为 Filter返回。
		>配置的封装包括全局配置：GlobalMethodSecurityConfiguration 这个配置类。也构建认证管理器。	
	>运行流程：
		>从tomcat的ApplicationFilterChain.internalDoFilter()开始：内部执行它的若干个Filter: .doFilter()这些过滤器：OrderedCharacterEncodingFilter/WsFilter/DelegatingFilterProxyRegistrationBean$1(这个的名称为springSecurityFilterChain)
			>进入到过滤链代理：FilterChainProxy.doFilter(ApplicationFilterChain)-->FilterChainProxy.doFilterInternal(ApplicationFilterChain) 内部构造new VirtualFilterChain()对象.doFilter()开始。
				>过滤器链代理开始 过滤：FilterChainProxy 内部有一个 Filter 列表：doFilter() 包括的过滤器：LogoutFilter，，这些过滤器doFilter()方法的最后都是chain.doFilter(request, response): 这个Chain就是FilterChainProxy。
					>执行通用的认证控制流程模板方法：尝试认证-->认证结果实体用于 会话Session --> 认证成功后应该做的事情。
						>认证过滤器尝试认证：UsernamePasswordAuthenticationFilter.attemptAuthentication() 开始。
							>生成 认证实体 ：从httpRequest里获取username和password参数 封装到 UsernamePasswordAuthenticationToken()对象。
							>验证 认证实体：AuthenticationManager.authenticate() 入口，调一系列的 AuthenticationProvider.authenticate() 实例 迭代 进行。
								>认证过程：输入 认证实体 输出 认证实体。
									>从认证实体里获取 username：
									>获取UserDetails： 一般要用UserDetailsService.loadUserByUsername(username) 来 获取。 对 InMemoryUserDetailsManager 实现: 则是 内部 一个map 保存了username-UserDetails 映射。
									>检查UserDetails: 1.账户状态检查(是否可用/证书是否过期/是否锁住/账户是否无效) 、2.证书匹配检查(对于用户名密码方式：将 从认证实体里获取的证书字符串 和 UserDetails里的编码后的密码字符串 匹配-用PasswordEncoder密码编码器匹配 (后者作为salt和前者生成一个编码来和后者逐字节比较))
									>构建新的认证实体：将 username + 认证实体中的证书字符串 + 认证实体中的权限集合(字符串统一upper/lower) 封装到新的认证实体如UsernamePasswordAuthenticationToken对象。
								>自身认证未通过：则parent来认证：	AuthenticationManager.authenticate() 
								>成功则返回这个认证实体。
						>认证结果实体用于 会话Session: 在 request上 增加几个 token 属性：1.对CsrfAuthenticationStrategy 这个策略，则 "CsrfToken":"xxx"。。2.ConcurrentSessionControlAuthenticationStrategy让session过期。
						>认证成功后应该做的事情： 1.设置认证结果实体 到 SecurityContextHolder。2.调RememberMeServices服务登录成功：loginSuccess().3.认证成功处理器的调用：AuthenticationSuccessHandler.onAuthenticationSuccess()
					
>elasticJob: 架构和使用。
	>架构： 
	>使用： 
		>准备过程：
			>名称空间的解析：RegNamespaceHandler.init() -->注册ZookeeperBeanDefinitionParser这个bean--->注册ZookeeperRegistryCenter这个bean:构造方法则注入ZookeeperConfiguration解析对象。
			>Bean的构建：构建bean:ZookeeperRegistryCenter 且注入 ZookeeperConfiguration 配置--> 对每个任务Job: 构建 配置对象 SimpleJobConfiguration/DataflowJobConfiguration/ScriptJobConfiguration ,封装到工厂方式创建的SpringJobScheduler里，然后对这个调度器初始化init()
				>调度器初始化：使用quartz的StdSchedulerFactory创建一个Scheduler:QuartzScheduler:StdScheduler对象(内部就新建了QuartzSchedulerThread对象并用ThreadExecutor:SimpleThreadPool运行了起来)和JobDetail对象并封装到 JobScheduleController 里 -->使用quartz开始调度：scheduler.scheduleJob(jobDetail, createTrigger(cron))它内部的实现方式：计算下一次执行时间，然后wait到那个时候唤醒notify任务线程；
		>时间到触发过程：
			>线路1：当当的JobScheduler创建了这个-->StdSchedulerFactory.getScheduler():instantiate()创建了QuartzScheduler-->QuartzScheduler 创建QuartzSchedulerThread对象--> QuartzSchedulerThread 创建JobRunShell对象，然后用内部的QuartzSchedulerResources对象获取线程池而运行这个shell对象。-> 使用quartz 执行 Job.execute(jec);
			>线路2：在Bean的初始化中：QuartzScheduler:scheduler.scheduleJob()时-->notifySchedulerThread()里最后就调用了QuartzSchedulerThread:schedThread.signalSchedulingChange()--->内部唤醒了sigLock.notifyAll()这个锁；而等待这个锁的方法就是这个类里的@run()方法-这个方法在上述的SimpleThreadPool里已运行起来了，等待之后就 执行 创建JobRunShell对象，初始化后放到线程池中异步运行。
>zookeeper: 架构和使用。
>curatorFramework: 架构和使用流程设计。自顶向下的塑造和 自底向上的封装。
	>客户端架构：
		>重试策略 继承 结构 设计：泛化策略/塑造过程/j。
	>使用流程设计：1.配置和构建zk连接客户端 实例 -->2.启动客户端实例-->3.阻塞式连接直到成功,失败则关闭客户端。
		>配置信息封装：1.连接信息+认证信息。 2.连接超时+会话超时时间。
		>构建zk连接客户端：CuratorFrameworkImpl <-- CuratorZookeeperClient <-- 工厂方式创建ZooKeeper对象的工厂
		>启动客户端实例：
			>连接状态管理器 启动：内部异步拉取消费 事件队列 里的 事件。
			>增加连接状态监听器 记录 错误的连接：
			>在已经启动的情况下 启动 “连接状态“对象：ConnectionState
				>启动监控工具：Exhibitor 内部自己异步 处理 。
				>重建zk客户端：Zookeeper
			>异步执行后端循环操作事务：已启动状态下，不断 从后台操作 队列 里 取出操作，然后实际执行 操作 要求做的内容。
				>操作的实际执行内容：如删除 节点等。
			>	
>函数式编程：Observable 可以看做是 二分树 分支编程(每个分支：正常则执行/异常则执行  转换 到 方法中 模式化 实现；开发更简单，更有层次化、且保证执行先后顺序、逻辑顺序)		
	>也可以看做是 一种 事件 传递式编程：
	
>超时机制：Watchdog-AsyncTimeout: com.squareup.okio.okio.jar
	>AsyncTimeout:  
		>scheduleTimeout()执行内容：设定node.timeoutAt = now+等待时间; 或者直接=截至时间。采用头插法，将节点插入队列--剩余时间从小到大的排序所在位置；如果刚好插在head后，则需要nofity()看门狗AsyncTimeout.class.notify()---表示有节点插入了且在头部--不能在idle。
			>如果队列head=null则启动一个看门狗WatchDog:new Watchdog().start() ： 并且 head = new AsyncTimeout()对象。
		>awaitTimeout()执行内容：取队列 第一个 AsyncTimeout ，查看它剩余时间(timeoutAt-now) ,>0则等待这么长时间Object.wait() 返回空；如果剩余时间<=0 ,则remove这个节点：让head.next指向下下一个节点,返回被移除的节点。如果队列本身就是空的，则idle 60s, 之后如果发现head.next=null依然，则WatchDog会退出无限循环。
		>exit()执行内容：退出检查。如果被检查节点在队列中，说明还没有超时，移除节点，且返回false； 如果不在队列中，则已经被超时移除，返回true。
	>Watchdog: 继承了 Thread  在run()里：就是在无限循环中：AsyncTimeout.class来同步 来 调用 awaitTimeout()方法；

>okio的架构设计：
	>缓存对象：Buffer 
		>内部属性：head:Segment 段		
	>段-内存资源池：SegmentPool
		>池内部属性: 
			>next:Segment:属性 
				>段属性：
					>data: 数据数组
					>pos: 当前读取位置
					>limit: 数据结束位置 
					>SIZE: 段的总大小；即data数组的长度。值=8192=1024*8 即 8kB, 最小使用单位1kB
				>段方法：
					>pop(): 弹出next指向的段，同时将这个头移除，即next更新为next.next
		>池方法：
			>recycle(Segment): 回收段, 即用头插法，将这个Segment插入到 next链表的头部。
	>超时检查机制：Timeout 
		>throwIfReached(): 检查截至时间 是否到了 -- 即和 现在比较 是否超过现在。		
	>设计的写数据接口Sink： write(Buffer, long): 第一个参数即数据源，第二个参数是可用的字节数。	
	>主类Okio: 
		>提供方法1：封装出一个含"写数据到指定流"方法的对象Sink：okio.Okio#sink(java.io.OutputStream, okio.Timeout) 一般为了后续写。
		>
>okhttp的架构设计：
	>Http2Stream: 
		>属性： 
			>receiveBuffer: 即接收缓存。
	>Http2Connection: 
		>方法： 
			>Http2Connection(Builder builder): 构造方法。做的事情：1.封装一个线程池writerExecutor:ScheduledThreadPoolExecutor, 以固定速率调用PingRunnable任务 来检查链接状态。
				>ping不通：则关闭writer、流、socket、写线程池, 优雅停 而不影响 已经建立的流。
				>发送ping: writer:Http2Writer.ping(isAck,payload1,payload2) ：具体过程：调sink.writeInt() 发送6个整数标记位作为 header, 然后 发送2个payload整数，然后sink.flush()
			>writeSynReply(): 调 writer:writer.synReply.synReply()
		>属性： 
			>streams:Map<Integer,Http2Stream> 即持有的所有的流。
			>peerSettings: Settings 即对端发送过来的设置帧里的内容。
	>Http2Writer: 
		>方法： 
			>synReply(): 调 buffer:Buffer.writeByte(b)写 或者 调 sink:BufferedSink:RealBufferedSink.write()写。
	>BufferedSink: 	
		>方法： 
			>write(Buffer,long): 调内部buffer:Buffer.write()写。
			>writeInt(): 调 Buffer.writeInt()发送 。
	>Buffer: 
		>方法： 
			>writeInt(int): 就是 将 int拆分为4个byte写到内部 的 段 Segment里。 
	>Builder: 
		>方法： 
			>Builder()： 构造方法。创建了 连接池、socket工厂
	>RealConnection: 
		>方法： 
		>属性： 
			>Route:		

>jsse.jar的架构设计：	
	>ssl过程：三步。目的：实现交换对称加密密钥。
		>协商 密码套件： 客户端发起 提供自己的，服务端从中选择 合适的 密码套件。密码套件包括：公钥算法/对称密钥算法/数据哈希算法。例如：RSA/AES/HMAC
		>密传 对称密钥： 客户端发起 查询 服务端的 公钥证书，验证坚固后，用其公钥 来加密 一个 根据协商的对称密钥算法 而 自己生成的对应的一个 对称密钥 ，发送给服务端。服务端收到 则 知道了对称密钥。
		>密传 数据及其哈希：客户端 先 用 对称密钥+对称加密算法 对 原始数据 和 对原始数据进行协商的hash算法生成的hash 一并加密 ， 然后发送 给服务器。服务器 也这样 发送给 客户端。 
			>第二种方法：客户端 先 用 对称密钥+对称加密算法 对 原始数据 和 对原始数据进行协商的hash算法生成的hash 一并加密 ，然后 还用 服务端的公钥 对 消息摘要hash加密。
	>非对称密钥算法：
		>RSA：
		>DH: 证书没有完全包括。
			>双方都互发部分信息：然后双方同时用部分信息 来 构造出完整的加密密钥---这样，完整的加密密钥其实没有 出现在网络上。
	>证书链：后一个证书 签发 前一个证书	的公钥。即 前一个证书中的 公钥 的签名 部分 是 用后一个 证书的私钥加密后生成的。
		
>java ssl证书的生成：
	>keytool.exe -genkey -validity 36000 -alias www.lsp.org -keyalg RSA -keystore D:\kkk.keystore
	>keytool.exe -export -keystore D:\kkk.keystore -alias www.lsp.org -file D:\kkk.cer -rfc
	>keytool -genkey -v -alias client -keyalg RSA -storetype PKCS12 -keystore D:\p12.p12
	>keytool -export -alias client -keystore  D:\p12.p12 -storetype PKCS12 -storepass 123456 -rfc -file D:\p12.cer
	

>jvm: 
	>jmap -histo 89961 | sort -k 2 -g -r | head -n 10 按个数排序。
	>jmap -histo:live 89961 | head -n 10 按 字节排序。
	
>linux: 
	>
参考资料：
1.https://docs.oracle.com/javase/8/docs/technotes/guides/security/jsse/tls.html#the_tls_1.2_handshake tls过程。		
2.https://www.jianshu.com/p/738b341df10b java ssl api		
		